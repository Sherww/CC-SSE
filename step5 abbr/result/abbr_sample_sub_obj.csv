before inlining happens remove unused code sees one use of inner c @$ which prevents its <PLACE_HOLDER> . after inlining it sees ` this instanceof inner c ` as the only use of inner c. make sure remove unused code recognizes that the value of inner c escapes .,test ( options @$ lines ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) @$ lines ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ;,which prevents removal,success,obj,options <SEP> lines <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> lines <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
use local <PLACE_HOLDER> for embedded spark <PLACE_HOLDER> when spark.master is not found,conf . set if missing ( __str__ @$ __str__ ) ; this . inner interpreter = load spark scala interpreter ( conf ) ; this . inner interpreter . open ( ) ; sc = this . inner interpreter . get spark context ( ) ; jsc = java spark context . from spark context ( sc ) ; spark version = spark version . from version string ( sc . version ( ) ) ; if ( enable supported version check && spark version . is unsupported version ( ) ) { throw new exception ( __str__ + spark version + __str__ + __str__ ) ; } sql context = this . inner interpreter . get sql context ( ) ; spark session = this . inner,mode spark context,fail,obj,conf <SEP> str <SEP> str <SEP> scala <SEP> conf <SEP> sc <SEP> sc <SEP> sc <SEP> supported <SEP> str <SEP> str <SEP> str <SEP> sql <SEP> sql
verify <PLACE_HOLDER> called or not,verify ( wal @$ expect append ? times ( __num__ ) : never ( ) ) . append data ( ( h region info ) any ( ) @$ ( wal key impl ) any ( ) @$ ( wal edit ) any ( ) ) ;,append called not,success,sub,wal <SEP> num <SEP> wal <SEP> impl <SEP> wal
use <PLACE_HOLDER> file attribute,use properties file = false ; properties file = __str__ ;,properties file attribute,success,sub,properties <SEP> properties <SEP> str
src inode and its subtree can not contain snapshottable <PLACE_HOLDER> with snapshots,fs dir snapshot op . check snapshot ( fsd @$ srciip @$ snapshottable dirs ) ;,inode contain directories,success,obj,fs <SEP> dir <SEP> fsd <SEP> srciip <SEP> snapshottable <SEP> dirs
the <PLACE_HOLDER> should have logging.properties,deque < property > result address = new array deque < > ( operations . get operation address ( logging configuration ) . as property list ( ) ) ; assert . assert true ( __str__ @$ result address . get last ( ) . get value ( ) . as string ( ) . contains ( __str__ ) ) ; model node handler = logging configuration . get ( __str__ @$ __str__ ) ; assert . assert true ( __str__ @$ handler . is defined ( ) ) ; assert . assert true ( handler . has defined ( __str__ ) ) ; string file name = null ;,address have logging.properties,success,sub,deque <SEP> deque <SEP> operations <SEP> str <SEP> last <SEP> contains <SEP> str <SEP> str <SEP> str <SEP> str <SEP> defined <SEP> defined <SEP> str
this statement can not be reached since the above method always throws an <PLACE_HOLDER> this is only here to silence the compiler and any warnings,return consumer records . empty ( ) ;,method throws exception,success,obj,records
throws obsolete version exception if another process has created a new <PLACE_HOLDER> already,store client . put ( new key . map value ( ) @$ new node ) ;,process created node,success,obj,None
param <PLACE_HOLDER> will not include 'this ',std type list param types = desc . get parameter types ( ) ; int sz param types = param types . size ( ) ;,"types include ""this""",success,sub,param <SEP> types <SEP> desc <SEP> types <SEP> int <SEP> sz <SEP> param <SEP> types <SEP> param <SEP> types
current <PLACE_HOLDER> already performs cleanup .,return ;,node performs cleanup,success,sub,None
test that the second parse build file <PLACE_HOLDER> repopulated the cache .,assert equals ( __str__ @$ __num__ @$ counter . calls ) ;,call repopulated cache,success,sub,equals <SEP> str <SEP> num <SEP> calls
check that slave satisfies min <PLACE_HOLDER> .,if ( cpus < cluster props . min cpu per node ( ) || mem < cluster props . min memory per node ( ) ) { log . log ( level . fine @$ __str__ @$ offer . get resources list ( ) ) ; return null ; } double total cpus = __num__ ; double total mem = __num__ ; double total disk = __num__ ;,slave satisfies requirements,success,obj,cpus <SEP> mem <SEP> str <SEP> resources <SEP> cpus <SEP> num <SEP> mem <SEP> num <SEP> num
if the receiver is not included in the contract @$ unfreeze frozen balance for this <PLACE_HOLDER> . otherwise @$ unfreeze delegated frozen balance provided this <PLACE_HOLDER> .,if ( ! array utils . is empty ( receiver address ) && dynamic store . supportdr ( ) ) { if ( arrays . equals ( receiver address @$ owner address ) ) { throw new contract validate exception ( __str__ ) ; } if ( ! decode util . address valid ( receiver address ) ) { throw new contract validate exception ( __str__ ) ; } account capsule receiver capsule = account store . get ( receiver address ) ; if ( dynamic store . get allow tvm constantinople ( ) == __num__ && receiver capsule == null ) { string readable receiver address = string util . create readable string ( receiver address ) ; throw new contract validate exception ( __str__ + readable,balance provided address,fail,obj,utils <SEP> supportdr <SEP> arrays <SEP> equals <SEP> str <SEP> util <SEP> str <SEP> tvm <SEP> constantinople <SEP> num <SEP> util <SEP> str
for every time when a user has not selected a <PLACE_HOLDER> but a basic block this breaks . as it does throw a null pointer exception .,first function . load ( ) ; second function . load ( ) ; final creation thread creation thread = new creation thread ( module @$ source block @$ target block @$ first function @$ second function ) ; progress dialog . show ( plugin interface . get main window ( ) . get frame ( ) @$ __str__ @$ creation thread ) ; if ( ( ! ( creation thread . threw exception ( ) ) ) && ( creation thread . get created view ( ) == null ) ) { message box . show information ( plugin interface . get main window ( ) . get frame ( ) @$ __str__ ) ; } else { new thread ( ) { @ override public void,user selected function,success,obj,second <SEP> second <SEP> dialog <SEP> plugin <SEP> str <SEP> created <SEP> plugin <SEP> str
collator.get keyword <PLACE_HOLDER> return the same contents for both commonly used true and false .,== all . length ) { match all = true ; for ( int j = __num__ ; j < pref . length ; j ++ ) { boolean found match = false ; for ( int k = __num__ ; k < all . length ; k ++ ) { if ( pref [ j ] . equals ( all [ k ] ) ) { found match = true ; break ; } } if ( ,key return contents,fail,sub,int <SEP> num <SEP> pref <SEP> int <SEP> num <SEP> pref <SEP> equals <SEP> errln <SEP> str <SEP> loc <SEP> str <SEP> arrays <SEP> str <SEP> arrays <SEP> pref
<PLACE_HOLDER> contains an object from another thread .,list . add ( obj from another thread . get ( ) ) ;,list contains object,success,sub,obj
the aws region provider chain that is used by default throws an <PLACE_HOLDER> instead of returning null when the region is not defined . for that reason @$ we have to support both throwing an <PLACE_HOLDER> and returning null as the region not being defined .,return null ;,chain throws exception,success,obj,None
if bolt has not finished <PLACE_HOLDER> or was not exactly once mode @$ just process the tuple immediately,if ( ! init || ( batch cache != null && ! batch cache . is exactly once mode ( ) ) ) { } else { pending batch batch = batch cache . get next pending batch ( last successful batch ) ; if ( batch != null ) { list < byte [ ] > pending msgs = batch . get tuples ( ) ; while ( pending msgs != null ) { for ( byte [ ] msg : pending msgs ) { receiver . deserialize tuple ( deserializer @$ msg @$ queue ) ; } pending msgs = batch . get tuples ( ) ; } } kryo input . set buffer ( data ) ; kryo input . set position ( __num__ ),bolt finished initialization,success,obj,init <SEP> last <SEP> msgs <SEP> tuples <SEP> msgs <SEP> msgs <SEP> deserialize <SEP> tuple <SEP> deserializer <SEP> msgs <SEP> tuples <SEP> kryo <SEP> kryo <SEP> num
this is tough for hotspot @$ but graal eliminates all <PLACE_HOLDER> .,consume ( el ) ;,graal eliminates calls,fail,obj,el
make sure the subject has a <PLACE_HOLDER>,assert false ( client principals . is empty ( ) ) ;,subject has principal,success,obj,principals
<PLACE_HOLDER> to the old behavior @$ allowing implementations to override .,map to map from id ( data @$ obj ) ;,objects allowing implementations,fail,sub,obj
the map reduce tokens are provided so that <PLACE_HOLDER> can spawn jobs if they wish to . the <PLACE_HOLDER> authenticate to the job tracker via the map reduce delegation tokens .,if ( system . getenv ( __str__ ) != null ) { conf . set ( __str__ @$ system . getenv ( __str__ ) ) ; } return conf ;,client spawn jobs,fail,sub,getenv <SEP> str <SEP> conf <SEP> str <SEP> getenv <SEP> str <SEP> conf
bad value prevents <PLACE_HOLDER> to next .,trigger action in cell editor ( key event . vk_tab ) ; assert is editing field ( __num__ @$ dt col num ) ;,value prevents move,success,obj,vktab <SEP> editing <SEP> num <SEP> num
turn the screen off . a black surface is already hiding the <PLACE_HOLDER> of the screen .,if ( m power state . get color fade level ( ) == __num__ ) { set screen state ( display . state_off ) ; m pending screen off = false ; m power state . dismiss color fade resources ( ) ; } else if ( perform screen off transition && m power state . prepare color fade ( m context @$ m color fade fades config ? color fade . mode_fade : color fade . mode_cool_down ) && m power state . get screen state ( ) != display . state_off ) { m color fade off animator . start ( ) ; } else { m color fade off animator . end ( ) ; },surface hiding area,fail,obj,num <SEP> stateoff <SEP> resources <SEP> fades <SEP> config <SEP> modefade <SEP> modecooldown <SEP> stateoff
get object can return <PLACE_HOLDER> if constraints were specified but not met,if ( s3 object == null ) return null ; output stream output stream = null ; try { output stream = new buffered output stream ( new file output stream ( destination file ) ) ; byte [ ] buffer = new byte [ __num__ * __num__ ] ; int bytes read ; while ( ( bytes read = s3 object . get object content ( ) . read ( buffer ) ) > - __num__ ) { output stream . write ( buffer @$ __num__ @$ bytes read ) ; } } catch ( io exception e ) { throw new sdk client exception ( __str__ + e . get message ( ) @$ e ) ; } finally { close quietly ( output stream @$,object return null,success,obj,s3 <SEP> buffered <SEP> num <SEP> num <SEP> int <SEP> bytes <SEP> bytes <SEP> s3 <SEP> content <SEP> num <SEP> num <SEP> bytes <SEP> io <SEP> sdk <SEP> str <SEP> close
<PLACE_HOLDER> means requery the adapter for this @$ it does n't have a valid width .,if ( ! lp . is decor && lp . height factor == __num__ ) { final item info ii = info for child ( child ) ; if ( ii != null ) { lp . height factor = ii . height factor ; lp . position = ii . position ; } },0 means adapter,success,sub,num <SEP> ii <SEP> ii <SEP> ii <SEP> ii
zero <PLACE_HOLDER> means a run,offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } while ( ip < ip bound ) { if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } } break ; } },address means run,fail,sub,ip <SEP> ip <SEP> ip <SEP> ip <SEP> ip <SEP> ip <SEP> ip
localized <PLACE_HOLDER> file name,args . filtered resources provider = new resources filter ( aapt target . with flavors ( internal flavor . of ( __str__ ) ) @$ filesystem @$ immutable sorted set . of ( resource1 @$ resource2 ) @$ immutable sorted set . of ( resource1 @$ resource2 ) @$ graph builder @$ immutable list . of ( resource1 . get res ( ) @$ resource2 . get res ( ) ) @$ immutable set . of ( ) @$ immutable set . of ( ) @$ null @$ resources filter . resource compression mode . disabled @$ filter resources steps . resource filter . empty_filter @$ optional . empty ( ) ) ;,string file name,success,sub,args <SEP> filtered <SEP> resources <SEP> resources <SEP> aapt <SEP> flavors <SEP> flavor <SEP> str <SEP> filesystem <SEP> resource1 <SEP> resource2 <SEP> resource1 <SEP> resource2 <SEP> resource1 <SEP> res <SEP> resource2 <SEP> res <SEP> resources <SEP> resources <SEP> steps <SEP> emptyfilter
clear references to <PLACE_HOLDER> @$ this should orphan the <PLACE_HOLDER> which should in turn trigger orphan removal logic .,team . set one vone player ( null ) ; team2 . set one vone player ( null ) ; tx . commit ( ) ; s . close ( ) ; s = open session ( ) ; tx = s . begin transaction ( ) ; count = ( ( long ) s . create query ( __str__ ) . iterate ( ) . next ( ) ) . int value ( ) ; assert equals ( __str__ + count @$ count @$ __num__ ) ; tx . commit ( ) ; s . close ( ) ;,references orphan players,success,obj,vone <SEP> team2 <SEP> vone <SEP> tx <SEP> close <SEP> tx <SEP> str <SEP> int <SEP> equals <SEP> str <SEP> num <SEP> tx <SEP> close
<PLACE_HOLDER> 1 sends a message to the bare jid of <PLACE_HOLDER> 0,chat chat = get connection ( __num__ ) . get chat manager ( ) . create chat ( get barejid ( __num__ ) @$ null ) ; chat . send message ( __str__ ) ; chat . send message ( __str__ ) ;,user sends message,success,sub,num <SEP> barejid <SEP> num <SEP> str <SEP> str
<PLACE_HOLDER> @$ for each set of paths that have a common input format @$ build a map of mappers to the paths they 're used for,for ( path path : paths ) { class < ? extends mapper > mapper class = mapper map . get ( path ) ; if ( ! mapper paths . contains key ( mapper class ) ) { mapper paths . put ( mapper class @$ new linked list < path > ( ) ) ; } mapper paths . get ( mapper class ) . add ( path ) ; },now build map,success,sub,paths <SEP> extends <SEP> mapper <SEP> mapper <SEP> mapper <SEP> mapper <SEP> paths <SEP> contains <SEP> mapper <SEP> mapper <SEP> paths <SEP> mapper <SEP> linked <SEP> mapper <SEP> paths <SEP> mapper
the text lines total height is larger than this view @$ snap <PLACE_HOLDER> to the top and bottom of the view .,if ( line1 height + line2 height > height ) { if ( child != m text line1 ) { vertical offset = height - line2 height ; } } else { vertical offset = ( height - line1 height - line2 height ) / __num__ ; if ( child == m text line2 ) { vertical offset += line1 height ; if ( m suggestion . has answer ( ) && m suggestion . get answer ( ) . get second line ( ) . has image ( ) ) { vertical offset += get resources ( ) . get dimension pixel offset ( r . dimen . omnibox_suggestion_answer_line2_vertical_spacing ) ; } } if ( line1 height != line2 height ) { vertical offset += ( line2,lines snap them,success,obj,line1 <SEP> line2 <SEP> line1 <SEP> line2 <SEP> line1 <SEP> line2 <SEP> num <SEP> line2 <SEP> line1 <SEP> second <SEP> resources <SEP> dimen <SEP> omniboxsuggestionanswerline2verticalspacing <SEP> line1 <SEP> line2 <SEP> line2
delete <PLACE_HOLDER> is complete before <PLACE_HOLDER> so not relevant @$ get next delete <PLACE_HOLDER>,delete range = delete range it . has next ( ) ? delete range it . next ( ) : null ; break ; case range1_completely_after_range2 :,range get range,success,sub,range1completelyafterrange2
using <PLACE_HOLDER> get an instance of document builder,from attribute ( el @$ __str__ ) ; throw new configuration changed exception ( __str__ + config version ) ; } } catch ( sax exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; } catch ( io exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; } catch ( parser configuration exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; },factory get instance,success,sub,el <SEP> str <SEP> str <SEP> config <SEP> notificationsxml <SEP> io <SEP> notificationsxml <SEP> parser <SEP> notificationsxml
validate inode tree <PLACE_HOLDER> match given <PLACE_HOLDER> .,for ( mutable inode < ? > node : journaled ) { assert true ( tree entries . contains ( node . to journal entry ( ) ) ) ; },entries match entries,success,obj,inode <SEP> journaled <SEP> entries <SEP> contains
req.get remote host returns ip <PLACE_HOLDER> @$ try to resolve hostname to be consistent with raw protocol .,try { final inet address client address = inet address . get by name ( client host name ) ; client host name = client address . get host name ( ) ; } catch ( unknown host exception e ) { logger . info ( __str__ @$ client host name @$ e . get message ( ) ) ; },returns ip address,success,obj,inet <SEP> inet <SEP> str
in theory node name ca n't be null but better be careful who knows <PLACE_HOLDER> other implementations may be doing ? ...,if ( get node name ( ) == null ) { if ( arg . get node name ( ) != null ) { return false ; } } else if ( ! get node name ( ) . equals ( arg . get node name ( ) ) ) { return false ; } if ( get local name ( ) == null ) { if ( arg . get local name ( ) != null ) { return false ; } } else if ( ! get local name ( ) . equals ( arg . get local name ( ) ) ) { return false ; } if ( get namespaceuri ( ) == null ) { if ( arg . get namespaceuri ( ),implementations doing what,success,obj,arg <SEP> equals <SEP> arg <SEP> arg <SEP> equals <SEP> arg <SEP> namespaceuri <SEP> arg <SEP> namespaceuri
set timestamp before moving to <PLACE_HOLDER>root @$ so we can avoid race condition <PLACE_HOLDER> remove the file before setting timestamp,sum . equals ignore case ( checksum for ( cm path @$ fs ) ) ) { success = false ; } else { switch ( type ) { case move : { log . info ( __str__ @$ path . to string ( ) @$ cm path . to string ( ) ) ; success = fs . rename ( path @$ cm path ) ; break ; } case copy : { log . info ( __str__ @$ path . to string ( ) @$ cm path . to string ( ) ) ; success = file utils . copy ( fs @$ path @$ fs @$ cm path @$ false @$ true @$ conf ) ; break ; } default : break ; } },exception remove file,fail,sub,equals <SEP> fs <SEP> str <SEP> fs <SEP> str <SEP> utils <SEP> fs <SEP> fs <SEP> conf
export the data @$ <PLACE_HOLDER> causes a file chooser to be shown,execute on swing without blocking ( ( ) -> key binding utils . export key bindings ( options ) ) ; file selected file = find and test file chooser ( null @$ test_filename ) ; return selected file ;,which causes chooser,success,sub,blocking <SEP> utils <SEP> bindings <SEP> options <SEP> selected <SEP> testfilename <SEP> selected
<PLACE_HOLDER> should not impact result,current min = double min kudaf . aggregate ( null @$ current min ) ; assert that ( __num__ @$ equal to ( current min ) ) ;,null impact result,success,sub,kudaf <SEP> num
starting the job master should have read the <PLACE_HOLDER>,try { final completed checkpoint savepoint checkpoint = completed checkpoint store . get latest checkpoint ( false ) ; assert that ( savepoint checkpoint @$ matchers . not null value ( ) ) ; assert that ( savepoint checkpoint . get checkpointid ( ) @$ is ( savepoint id ) ) ; } finally { rpc utils . terminate rpc endpoint ( job master @$ testing timeout ) ; },master read savepoint,success,obj,completed <SEP> savepoint <SEP> completed <SEP> savepoint <SEP> matchers <SEP> savepoint <SEP> checkpointid <SEP> savepoint <SEP> rpc <SEP> utils <SEP> rpc <SEP> endpoint
verify that the archive rule has the correct <PLACE_HOLDER> : the object files from our sources .,rule . get native linkable input ( cxx platform @$ linker . linkable dep type . static @$ graph builder @$ unconfigured target configuration . instance ) ; build rule static rule = graph builder . get rule ( cxx description enhancer . create static library build target ( target @$ cxx platform . get flavor ( ) @$ pic type . pdc ) ) ; assert not null ( static rule ) ; assert equals ( immutable set . of ( cxx source rule factorypdc . create compile build target ( __str__ ) @$ cxx source rule factorypdc . create compile build target ( gen source name ) ) @$ static rule . get build deps ( ) . stream ( ) . map ( build rule,rule has deps,success,obj,linkable <SEP> cxx <SEP> linker <SEP> linkable <SEP> unconfigured <SEP> cxx <SEP> cxx <SEP> flavor <SEP> pdc <SEP> equals <SEP> cxx <SEP> factorypdc <SEP> str <SEP> cxx <SEP> factorypdc <SEP> deps
only the main task stack change notification requires a <PLACE_HOLDER> .,m handler . send message delayed ( msg @$ notify_task_stack_change_listeners_delay ) ;,notification requires delivery,fail,obj,delayed <SEP> notifytaskstackchangelistenersdelay
do abc tag <PLACE_HOLDER> does not have name,continue ;,abc tag plugin,fail,obj,None
our randomly generated <PLACE_HOLDER> significantly .,return name . length ( ) == __num__ ;,our generated name,fail,obj,num
no context class <PLACE_HOLDER> @$ try the current class <PLACE_HOLDER>,in = ss . get resource as stream ( cl @$ service ) ;,loader try loader,success,sub,None
this call does the right <PLACE_HOLDER> with a null transaction task queue,if ( ! m_complete msg . is restart ( ) ) { do commonspi complete actions ( ) ; log todr ( site connection . getdr gateway ( ) ) ; } else { m_txn state . set begin undo token ( site . k invalid undo token ) ; },call does thing,success,obj,mcomplete <SEP> commonspi <SEP> actions <SEP> todr <SEP> getdr <SEP> mtxn
add parameters from the configuration in the job trace the reason why the job configuration parameters @$ as seen in the jobconf file @$ are added first because the specialized <PLACE_HOLDER> obtained from rumen should override the job conf <PLACE_HOLDER> .,for ( map . entry < object @$ object > entry : job . get job properties ( ) . get value ( ) . entry set ( ) ) { job conf . set ( entry . get key ( ) . to string ( ) @$ entry . get value ( ) . to string ( ) ) ; },parameters override values,fail,sub,properties <SEP> conf
no more room to display the comments below ; do n't process <PLACE_HOLDER>,if ( total comments found > max display lines ) { return ; },comments process them,success,obj,comments <SEP> lines
let the hash builder <PLACE_HOLDER> reduce their accounted memory,partitions no longer needed . set ( null ) ; lock . write lock ( ) . lock ( ) ; try { arrays . fill ( partitions @$ null ) ; lookup source supplier = null ; close cached lookup sources ( ) ; } finally { lock . write lock ( ) . unlock ( ) ; },partitions reduce memory,fail,sub,partitions <SEP> longer <SEP> needed <SEP> arrays <SEP> partitions <SEP> close <SEP> cached <SEP> sources
illegal access error is expected note : <PLACE_HOLDER> stops context right after shutdown initiated . it is problematic to see log output system out could help,logger . warn ( __str__ + e . get message ( ) ) ;,user stops right,fail,sub,str
some binary files have <PLACE_HOLDER>,while ( c != __str__ ) { if ( c != __str__ ) sb . append ( c ) ; c = ( char ) buffer . get ( ) ; },files have newline,success,obj,str <SEP> str <SEP> sb
explicit <PLACE_HOLDER> provider implies <PLACE_HOLDER>,config . get ( key_authorizer ) . as string ( ) . if present ( value -> { if ( ! config . get ( key_authorize ) . exists ( ) ) { builder . authorize ( true ) ; } } ) ; return builder . build ( ) ;,provider implies atz,success,obj,config <SEP> keyauthorizer <SEP> config <SEP> keyauthorize <SEP> exists
bean may have acquired new weak <PLACE_HOLDER>,target = result . get node ( ) ; assert . assert equals ( count ++ @$ result . get value ( ) . int value ( ) ) ;,bean acquired affinity,success,obj,equals <SEP> int
<PLACE_HOLDER> must have the same type,if ( node1 . get class ( ) != node2 . get class ( ) ) { return false ; } string image1 = node1 . get image ( ) ; string image2 = node2 . get image ( ) ;,image have type,fail,sub,node1 <SEP> node2 <SEP> image1 <SEP> node1 <SEP> image2 <SEP> node2
iterate through all source <PLACE_HOLDER> to make sure we are generating a complete set of source folders for the source <PLACE_HOLDER> .,) . get parent ( ) ; if ( path elements . is empty ( ) ) { continue ; } while ( directory != null && directory . get file name ( ) != null && ! path elements . contains ( directory . get file name ( ) . to string ( ) ) ) { directory = directory . get parent ( ) ; } if ( directory == null || directory . get file name ( ) == null ) { continue ; } string directory path = directory . to string ( ) ; if ( ! directory path . ends with ( __str__ ) ) { directory path += __str__ ; } src folders . add ( directory path ) ; },paths generating set,success,sub,elements <SEP> elements <SEP> contains <SEP> ends <SEP> str <SEP> str <SEP> src <SEP> folders
quick exit : if the <PLACE_HOLDER> does not support encryption @$ we can exit early .,if ( ! is encryption supported ( ) ) { return device policy manager . encryption_status_unsupported ; },device support encryption,fail,sub,supported <SEP> encryptionstatusunsupported
make sure that the pattern matches a <PLACE_HOLDER> by one .,if ( ! b . is java constant ( ) ) { return null ; } java constant b cst = b . as java constant ( ) ; long b value ; if ( b cst . get java kind ( ) == java kind . int ) { b value = b cst . as int ( ) ; } else if ( b cst . get java kind ( ) == java kind . long ) { b value = b cst . as long ( ) ; } else { return null ; } if ( b value == - __num__ ) { return builder -> get arithmeticlir generator ( ) . emit get mask up to lowest set bit ( operand ( a,pattern matches subtraction,success,obj,int <SEP> int <SEP> num <SEP> arithmeticlir <SEP> lowest
some <PLACE_HOLDER> to not crash the chartbuilding with emtpy data,if ( m max elements == __num__ ) { m max elements = __num__ ; } if ( m mcount == __num__ ) { m mcount = __num__ ; } if ( m first element == m last element ) { m first element = __num__ ; m last element = __num__ ; } if ( m max cards == __num__ ) { m max cards = __num__ ; } return list . size ( ) > __num__ ;,adjustments crash chartbuilding,success,sub,elements <SEP> num <SEP> elements <SEP> num <SEP> mcount <SEP> num <SEP> mcount <SEP> num <SEP> last <SEP> num <SEP> last <SEP> num <SEP> cards <SEP> num <SEP> cards <SEP> num <SEP> num
1 st root <PLACE_HOLDER>,if ( parent == null ) { long next = ( ( long ) phase << phase_shift ) | adj ; if ( state . compare and set ( this @$ s @$ next ) ) break ; } else { main lock . lock ( ) ; try { if ( state == s ) { parent . do register ( __num__ ) ; do { phase = ( int ) ( root . state > > > phase_shift ) ; } while ( ! state . compare and set ( this @$ state @$ ( ( long ) phase << phase_shift ) | adj ) ) ; break ; } } finally { main lock . unlock ( ) ; } },st root registration,success,obj,phaseshift <SEP> adj <SEP> num <SEP> int <SEP> phaseshift <SEP> phaseshift <SEP> adj
bypass pe <PLACE_HOLDER> @$ but permit p es to complete ... valid docs wo n't care .,try { for ( ; ; ) { int c = getc ( ) ; if ( c == __str__ ) { c = getc ( ) ; if ( c != __str__ ) { if ( save comment text ) str tmp . append ( __str__ ) ; ungetc ( ) ; continue ; } next char ( __str__ @$ __str__ @$ null ) ; break one comment ; } if ( save comment text ) str tmp . append ( ( char ) c ) ; } } catch ( end of input exception e ) { if ( in . is internal ( ) ) { error ( __str__ @$ null ) ; } fatal ( __str__ ) ; },bypass pe tests,fail,obj,int <SEP> getc <SEP> str <SEP> getc <SEP> str <SEP> str <SEP> tmp <SEP> str <SEP> ungetc <SEP> str <SEP> str <SEP> str <SEP> tmp <SEP> str <SEP> str
setting volume on ui sounds stream <PLACE_HOLDER> also controls silent mode,if ( ( ( flags & audio manager . flag_allow_ringer_modes ) != __num__ ) || ( stream == get ui sounds stream type ( ) ) ) { set ringer mode ( get new ringer mode ( stream @$ index @$ flags ) @$ tag + __str__ @$ false ) ; },type controls mode,success,sub,flags <SEP> flagallowringermodes <SEP> num <SEP> sounds <SEP> flags <SEP> str
sequence <PLACE_HOLDER> compress writer,( fs @$ count @$ seed @$ block compressed file ) ; sort test ( fs @$ count @$ megabytes @$ factor @$ true @$ block compressed file ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; merge test ( fs @$ count @$ seed @$ block compressed file @$ compression type . block @$ false @$ factor @$ megabytes ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; merge test ( fs @$ count @$ seed @$ block compressed file @$ compression type . block @$ true @$ factor @$ megabytes ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; fs . close ( ) ;,block . file compress writer,fail,sub,fs <SEP> compressed <SEP> fs <SEP> megabytes <SEP> compressed <SEP> fs <SEP> compressed <SEP> fs <SEP> compressed <SEP> megabytes <SEP> fs <SEP> compressed <SEP> fs <SEP> compressed <SEP> megabytes <SEP> fs <SEP> compressed <SEP> fs <SEP> close
note that we can not do any size checking here @$ as the correct component count depends on the drawing step . gl should catch such <PLACE_HOLDER> then @$ and we will report them to the user .,if ( m values != null ) { gles20 . gl bind buffer ( gles20 . gl_array_buffer @$ __num__ ) ; gles20 . gl vertex attrib pointer ( m index @$ m components @$ m type @$ m should normalize @$ m stride @$ m values ) ; } else { gles20 . gl bind buffer ( gles20 . gl_array_buffer @$ m vbo ) ; gles20 . gl vertex attrib pointer ( m index @$ m components @$ m type @$ m should normalize @$ m stride @$ m offset ) ; },note catch exceptions,fail,obj,values <SEP> gles20 <SEP> gl <SEP> gles20 <SEP> glarraybuffer <SEP> num <SEP> gles20 <SEP> gl <SEP> attrib <SEP> components <SEP> values <SEP> gles20 <SEP> gl <SEP> gles20 <SEP> glarraybuffer <SEP> vbo <SEP> gles20 <SEP> gl <SEP> attrib <SEP> components
model name can not use reserved <PLACE_HOLDER> @$ e.g . return,if ( is reserved word ( camelized name ) ) { final string model name = __str__ + camelized name ; logger . warn ( camelized name + __str__ + model name ) ; return model name ; },name use keyword,success,obj,camelized <SEP> str <SEP> camelized <SEP> camelized <SEP> str
copy local variables to event scope execution by value . this way @$ the event scope execution references a <PLACE_HOLDER> ' of the local variables,new sub process variable snapshotter ( ) . set variables snapshots ( sub process execution @$ event scope execution ) ;,execution references ' snapshot,fail,obj,process <SEP> snapshotter <SEP> variables <SEP> snapshots <SEP> process
the input method <PLACE_HOLDER> only throws security exceptions @$ so let 's log all others .,if ( ! ( e instanceof security exception ) ) { slog . wtf ( tag @$ __str__ @$ e ) ; } throw e ;,method throws exceptions,fail,sub,instanceof <SEP> str
<PLACE_HOLDER> account type,m ams . add account as user ( m mock account manager response @$ null @$ __str__ @$ null @$ true @$ null @$ user handle . user_system ) ;,response account type,success,sub,ams <SEP> str <SEP> usersystem
expression has n't nested <PLACE_HOLDER>,if ( tail == null ) { if ( field type instanceof composite type ) { ( ( composite type ) field type ) . get flat fields ( __str__ @$ offset @$ result ) ; } else { result . add ( new flat field descriptor ( offset @$ field type ) ) ; } } else { if ( field type instanceof composite type ) { ( ( composite type ) field type ) . get flat fields ( tail @$ offset @$ result ) ; } else { throw new invalid field reference exception ( __str__ + tail + __str__ + field type + __str__ ) ; } },expression nested field,success,obj,instanceof <SEP> fields <SEP> str <SEP> instanceof <SEP> fields <SEP> str <SEP> str <SEP> str
we need something that will measure the amount of time since our <PLACE_HOLDER> has seen a record ...,time since time since last record = threads . time since ( clock . system ) ;,thread seen record,fail,sub,last <SEP> threads
try to move focus to the next visible <PLACE_HOLDER> with a running activity if this <PLACE_HOLDER> is not covering the entire screen or is on a secondary display with no home <PLACE_HOLDER> .,if ( next focused stack != null ) { return m root activity container . resume focused stacks top activities ( next focused stack @$ prev @$ null ) ; },stack covering screen,success,sub,stacks <SEP> activities <SEP> prev
copy is necessary since the instance info builder just uses the original <PLACE_HOLDER> @$ and we do n't want to corrupt the global eureka copy of the object which may be used by other clients in our system,instance info copy = new instance info ( ii ) ; if ( is secure ) { ii = new instance info . builder ( copy ) . set secure port ( override port ) . build ( ) ; } else { ii = new instance info . builder ( copy ) . set port ( override port ) . build ( ) ; },builder uses one,fail,obj,ii <SEP> ii <SEP> ii
if declaration does not provide <PLACE_HOLDER> @$ there is no connection to make,if ( usage == null || declaration == null || declaration . length == __num__ ) return ; if ( usage . length != declaration . length ) return ;,declaration provide generics,success,obj,num
show that <PLACE_HOLDER> does work,do in hibernate ( this :: session factory @$ session -> { query query = session . create query ( __str__ @$ foo . class ) ; list < foo > list = query . get result list ( ) ; assert equals ( __num__ @$ list . size ( ) ) ; } ) ;,scan does work,fail,sub,str <SEP> foo <SEP> foo <SEP> equals <SEP> num
if event has this <PLACE_HOLDER> to filter on,if ( event dimension transformed . contains ( filter dimension transformed ) || filter dimension transformed . contains ( event dimension transformed ) ) { set < string > event dimension values set = new hash set < > ( event dimension values transformed ) ; event dimension values set . retain all ( filtered dimension values transformed ) ; if ( ! event dimension values set . is empty ( ) ) { filtered events . add ( event ) ; event added = true ; break ; } },event has dimension,success,obj,transformed <SEP> contains <SEP> transformed <SEP> transformed <SEP> contains <SEP> transformed <SEP> values <SEP> values <SEP> transformed <SEP> values <SEP> filtered <SEP> values <SEP> transformed <SEP> values <SEP> filtered <SEP> events <SEP> added
since hot swap <PLACE_HOLDER> run one file at a time @$ namespaces seen will not include any provides earlier than this current file .,if ( ! in hot swap && import type . must be ordered ( ) && ! namespaces seen . contains ( namespace ) ) { t . report ( call @$ late_provide_error @$ namespace ) ; },plugins run file,fail,sub,namespaces <SEP> contains <SEP> namespace <SEP> lateprovideerror <SEP> namespace
this test verifies the baseline <PLACE_HOLDER> used in subsequent tests . if this fails @$ the rest will fail .,project dependency graph graph = three projects depending ona single ( ) ; final list < maven project > sorted projects = graph . get sorted projects ( ) ; assert equals ( a project @$ sorted projects . get ( __num__ ) ) ; assert equals ( depender1 @$ sorted projects . get ( __num__ ) ) ; assert equals ( depender2 @$ sorted projects . get ( __num__ ) ) ; assert equals ( depender3 @$ sorted projects . get ( __num__ ) ) ;,test verifies values,fail,obj,projects <SEP> depending <SEP> ona <SEP> projects <SEP> projects <SEP> equals <SEP> projects <SEP> num <SEP> equals <SEP> depender1 <SEP> projects <SEP> num <SEP> equals <SEP> depender2 <SEP> projects <SEP> num <SEP> equals <SEP> depender3 <SEP> projects <SEP> num
check:3 compare the key <PLACE_HOLDER>,for ( int i = __num__ ; i < prev count ; i ++ ) { value meta interface pre value = null ; for ( int j = __num__ ; j < rows . length ; j ++ ) { value meta interface v = rows [ j ] . search value meta ( key list . get ( j ) [ i ] ) ; if ( v == null ) { return false ; } if ( j != __num__ && v . get type ( ) != pre value . get type ( ) ) { log error ( __str__ ) ; return false ; } else { pre value = v ; } } },check:3 compare list,fail,obj,int <SEP> num <SEP> prev <SEP> int <SEP> num <SEP> rows <SEP> rows <SEP> num <SEP> str
backslash and double quote need double the <PLACE_HOLDER> for both java and haskell,special char replacements . remove ( __str__ ) ; special char replacements . remove ( __str__ ) ; special char replacements . put ( __str__ @$ __str__ ) ; special char replacements . put ( __str__ @$ __str__ ) ;,backslash double handling,fail,obj,replacements <SEP> str <SEP> replacements <SEP> str <SEP> replacements <SEP> str <SEP> str <SEP> replacements <SEP> str <SEP> str
record the sequence of seeks and reads which trigger a <PLACE_HOLDER> .,int [ ] seeks = new int [ __num__ ] ; int [ ] reads = new int [ __num__ ] ; try ( fs data input stream stm = get file system ( ) . open ( random seek file ) ) { for ( int i = __num__ ; i < limit ; i ++ ) { int seek off = r . next int ( buf . length ) ; int to read = r . next int ( math . min ( buf . length - seek off @$ __num__ ) ) ; seeks [ i % seeks . length ] = seek off ; reads [ i % reads . length ] = to read ; verify read ( stm @$ buf @$,which trigger split,fail,obj,int <SEP> seeks <SEP> int <SEP> num <SEP> int <SEP> reads <SEP> int <SEP> num <SEP> fs <SEP> stm <SEP> int <SEP> num <SEP> int <SEP> int <SEP> buf <SEP> int <SEP> int <SEP> buf <SEP> num <SEP> seeks <SEP> seeks <SEP> reads <SEP> reads <SEP> stm <SEP> buf
<PLACE_HOLDER> 3 items and ensure that <PLACE_HOLDER> pulls 2 from the database & 1 from the cache .,return of deleted entities ( true ) . multi load ( ids ( __num__ ) ) ; assert equals ( __num__ @$ entities . size ( ) ) ; simple entity deleted entity = entities . get ( __num__ ) ; assert not null ( deleted entity ) ; final entity entry entry = ( ( shared session contract implementor ) session ) . get persistence context ( ) . get entry ( deleted entity ) ; assert true ( entry . get status ( ) == status . deleted || entry . get status ( ) == status . gone ) ; assert true ( sql statement interceptor . get sql queries ( ) . get first ( ) . ends with ( __str__ ) ) ;,multiload pulls 2,success,sub,deleted <SEP> entities <SEP> ids <SEP> num <SEP> equals <SEP> num <SEP> entities <SEP> deleted <SEP> entities <SEP> num <SEP> deleted <SEP> shared <SEP> implementor <SEP> deleted <SEP> deleted <SEP> sql <SEP> sql <SEP> queries <SEP> ends <SEP> str
at normal playback speed @$ we stop <PLACE_HOLDER>ing when the <PLACE_HOLDER> reaches the minimum .,assert that ( load control . should continue loading ( min_buffer_us @$ speed ) ) . is false ( ) ;,load reaches minimum,fail,sub,minbufferus
test contents using contains element set <PLACE_HOLDER>,int size2 = __num__ ; int previous element = - __num__ ; for ( int element : set ) { assert true ( bs . get ( element ) ) ; size2 ++ ; assert true ( previous element < __num__ || ( ascending ? element - previous element > __num__ : element - previous element < __num__ ) ) ; previous element = element ; } assert equals ( size2 @$ size ) ;,contents contains iterator,success,obj,int <SEP> size2 <SEP> num <SEP> int <SEP> num <SEP> int <SEP> size2 <SEP> num <SEP> ascending <SEP> num <SEP> num <SEP> equals <SEP> size2
if the size of bloom filter is smaller than 1 mb @$ use <PLACE_HOLDER> max false positive probability,if ( num bits required <= max num bits ) { return default max false pos probability ; },value max probability,fail,sub,num <SEP> bits <SEP> required <SEP> num <SEP> bits <SEP> pos
transfer send some asset issue to default account @$ to test if this transaction use the creator <PLACE_HOLDER> .,assert . assert true ( public methed . transfer asset ( to address @$ asset account id . to byte array ( ) @$ __num__ @$ transfer asset address @$ transfer asset create key @$ blocking stub full ) ) ; public methed . wait produce next block ( blocking stub full ) ; asset creator net = public methed . get account net ( asset012 address @$ blocking stub full ) ; asset transfer net = public methed . get account net ( transfer asset address @$ blocking stub full ) ; long creator after net used = asset creator net . get net used ( ) ; long transfer after free net used = asset transfer net . get free net used ( ) ; logger,transaction use net,success,obj,methed <SEP> num <SEP> blocking <SEP> methed <SEP> blocking <SEP> methed <SEP> asset012 <SEP> blocking <SEP> methed <SEP> blocking <SEP> used <SEP> used <SEP> used <SEP> used
close <PLACE_HOLDER> 2 and pause so <PLACE_HOLDER> has a chance to close,close server ( server2 ) ; wait . pause ( __num__ * __num__ ) ; wait for cqs disconnected ( client @$ __str__ @$ __num__ ) ;,server has chance,success,sub,close <SEP> server2 <SEP> num <SEP> num <SEP> cqs <SEP> str <SEP> num
add view <PLACE_HOLDER> add view end,skeleton models . add ( new skeleton model builder ( ) . set start view ( btn3 ) . set end view ( btn4 ) . build ( ) ) ;,bottom add end,fail,sub,models <SEP> btn3 <SEP> btn4
<PLACE_HOLDER> write options to use in <PLACE_HOLDER> states .,write options write options = null ; linked hash map < string @$ rocksdb keyed state backend . rocks db kv state info > kv state information = new linked hash map < > ( ) ; rocksdb db = null ; abstract rocksdb restore operation restore operation = null ; rocks db ttl compact filters manager ttl compact filters manager = new rocks db ttl compact filters manager ( enable ttl compaction filter @$ ttl time provider ) ; resource guard rocksdb resource guard = new resource guard ( ) ; snapshot strategy < k > snapshot strategy ; priority queue set factory priority queue factory ; rocksdb serialized composite key builder < k > shared rocks key builder ;,the write options,success,sub,options <SEP> options <SEP> linked <SEP> rocksdb <SEP> keyed <SEP> backend <SEP> rocks <SEP> db <SEP> kv <SEP> kv <SEP> linked <SEP> rocksdb <SEP> db <SEP> rocksdb <SEP> rocks <SEP> db <SEP> ttl <SEP> filters <SEP> ttl <SEP> filters <SEP> rocks <SEP> db <SEP> ttl <SEP> filters <SEP> ttl <SEP> compaction <SEP> ttl <SEP> rocksdb <SEP> rocksdb <SEP> serialized <SEP> shared <SEP> rocks
ensure comments are stripped . <PLACE_HOLDER> cause syntax errors if not stripped .,final source file src file1 = source file . from code ( __str__ @$ line_joiner . join ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ;,these cause errors,success,sub,src <SEP> file1 <SEP> str <SEP> linejoiner <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
if the incoming uri matches a single note <PLACE_HOLDER> @$ does the delete based on the incoming data @$ but modifies the where clause to restrict it to the particular note <PLACE_HOLDER> .,case main_id :,uri matches id,success,obj,mainid
pipeline should have ssl <PLACE_HOLDER> and server tls <PLACE_HOLDER>,iterator < map . entry < string @$ channel handler > > iterator = pipeline . iterator ( ) ; assert that ( iterator . next ( ) . get value ( ) ) . is instance of ( ssl handler . class ) ;,pipeline have handler,success,obj,iterator <SEP> iterator <SEP> iterator <SEP> iterator <SEP> ssl
unknown host exception happens if we ca n't resolve host<PLACE_HOLDER> into ip address . unknown host exception 's get message method returns just the host<PLACE_HOLDER> which is a useless message @$ so log the exception class <PLACE_HOLDER> to provide more info .,log . debug ( e . to string ( ) ) ; throw new helios exception ( __str__ + uri @$ e ) ; throw new helios exception ( __str__ + uri @$ e ) ;,hostname log name,success,obj,helios <SEP> str <SEP> helios <SEP> str
let 's not store 'raw ' <PLACE_HOLDER> but nodes,if ( value == null ) { value = null node ( ) ; },s store nulls,success,obj,None
get new display metrics based on the display adjustments given to the resources impl . update a <PLACE_HOLDER> if the compatibility info changed @$ because the resources impl object will handle the update internally .,display adjustments daj = r . get display adjustments ( ) ; if ( compat != null ) { daj = new display adjustments ( daj ) ; daj . set compatibility info ( compat ) ; } dm = get display metrics ( display id @$ daj ) ; if ( ! is default display ) { apply non default display metrics to configuration ( dm @$ tmp config ) ; } if ( has override configuration ) { tmp config . update from ( key . m override configuration ) ; } r . update configuration ( tmp config @$ dm @$ compat ) ; r . update configuration ( config @$ dm @$ compat ) ;,metrics update configuration,fail,obj,adjustments <SEP> daj <SEP> adjustments <SEP> compat <SEP> daj <SEP> adjustments <SEP> daj <SEP> daj <SEP> compat <SEP> metrics <SEP> daj <SEP> metrics <SEP> tmp <SEP> config <SEP> tmp <SEP> config <SEP> tmp <SEP> config <SEP> compat <SEP> config <SEP> compat
while visit the <PLACE_HOLDER> build elements @$ the probe element is null @$ and the <PLACE_HOLDER> build iterator would iterate all the <PLACE_HOLDER> build elements @$ so we return false during the second calling of this method .,this . unmatched build visited = true ; return true ;,unmatched build elements,success,sub,visited
the <PLACE_HOLDER> should contain just 1 character :,assert equals ( __num__ @$ straus . get len ( ) ) ; har file system . close ( ) ; local fs . delete ( tmp path @$ true ) ;,directory contain character,fail,sub,equals <SEP> num <SEP> straus <SEP> har <SEP> close <SEP> fs <SEP> tmp
start the two trigger <PLACE_HOLDER> . they will wait at the barrier,t1 . start ( ) ; t2 . start ( ) ;,two trigger threads,success,obj,t1 <SEP> t2
create calendar which omits <PLACE_HOLDER>,for ( action . handler action handler : action handlers ) { gregorian calendar cal = new gregorian calendar ( get time zone ( ) @$ get locale ( ) ) ; cal . clear ( ) ; cal . set ( current calendar . get ( java . util . calendar . year ) @$ current calendar . get ( java . util . calendar . month ) @$ current calendar . get ( java . util . calendar . date ) ) ; date start = cal . get time ( ) ; cal . add ( java . util . calendar . date @$ __num__ ) ; cal . add ( java . util . calendar . second @$ - __num__ ) ; date end,which omits keys,fail,obj,handlers <SEP> gregorian <SEP> gregorian <SEP> util <SEP> util <SEP> util <SEP> util <SEP> num <SEP> util <SEP> second <SEP> num
a filter with a start date of now should not accept the <PLACE_HOLDER>,filter = new log filter ( level . info @$ local date time . now ( ) @$ null ) ; assert that ( filter . accepts file ( path ) ) . is false ( ) ;,filter accept file,success,obj,accepts
method reports <PLACE_HOLDER> in nanoseconds across all processors .,cpu time /= __num__ * os . get available processors ( ) ; double cpu = __num__ ; if ( prev cpu time > __num__ ) { long cpu time diff = cpu time - prev cpu time ; cpu = math . min ( __num__ @$ ( double ) cpu time diff / metrics_update_freq ) ; },method reports cpu,fail,obj,num <SEP> processors <SEP> num <SEP> prev <SEP> num <SEP> diff <SEP> prev <SEP> num <SEP> diff <SEP> metricsupdatefreq
log a warning if the <PLACE_HOLDER> uses an unnecessary service error definition annotation,if ( service error def annotation != null && ! resource model . is any service error list defined ( ) ) { log . warn ( string . format ( __str__ + __str__ + __str__ @$ resource class . get name ( ) @$ service error def . class . get simple name ( ) @$ service errors . class . get simple name ( ) @$ param error . class . get simple name ( ) ) ) ; },user uses annotation,fail,sub,defined <SEP> str <SEP> str <SEP> str <SEP> errors <SEP> param
required <PLACE_HOLDER> expect activity launch options in,fail ( __str__ ) ;,features expect options,success,sub,str
2 range conditions are used on different columns @$ but not all sql <PLACE_HOLDER> properly optimize it . some <PLACE_HOLDER> can only use an index on one of the columns . an additional condition provides explicit knowledge that 'start ' can not be greater than 'end ' .,start ( ) . to string ( ) ) . bind ( __str__ @$ interval . get end ( ) . to string ( ) ) . map ( byte array mapper . first ) . fold ( new array list < > ( ) @$ new folder3 < list < data segment > @$ byte [ ] > ( ) { @ override public list < data segment > fold ( list < data segment > accumulator @$ byte [ ] payload @$ fold controller fold controller @$ statement context statement context ) { accumulator . add ( jackson utils . read value ( json mapper @$ payload @$ data segment . class ) ) ; return accumulator ; } } ) ; } } ) ;,databases use index,success,sub,str <SEP> mapper <SEP> folder3 <SEP> utils <SEP> json <SEP> mapper
these credentials must match <PLACE_HOLDER> in the default password file,string [ ] credentials = new string [ ] { __str__ @$ __str__ } ; cli_env . put ( __str__ @$ credentials ) ; jmxc = jmx connector factory . connect ( url @$ cli_env ) ; m bean server connection mbsc = jmxc . getm bean server connection ( ) ;,credentials match those,success,obj,str <SEP> str <SEP> clienv <SEP> str <SEP> jmxc <SEP> jmx <SEP> clienv <SEP> mbsc <SEP> jmxc <SEP> getm
update <PLACE_HOLDER> should not update any caches since they are both unregistered,m network score service . update scores ( new scored network [ ] { scored_network } ) ;,scores update caches,success,sub,scores <SEP> scored <SEP> scorednetwork
first copy the children as the call to copy.add will modify the <PLACE_HOLDER> we 're iterating on,enumeration < ? > enum from = node . children ( ) ; list < j meter tree node > tmp = new array list < > ( ) ; while ( enum from . has more elements ( ) ) { j meter tree node child = ( j meter tree node ) enum from . next element ( ) ; tmp . add ( child ) ; } for ( j meter tree node j meter tree node : tmp ) { copy . add ( j meter tree node ) ; } tree model . insert node into ( copy @$ target @$ index ++ ) ; nodes for removal . add ( node ) ; paths to select [ path position ++ ] =,call modify order,fail,obj,enum <SEP> children <SEP> tmp <SEP> enum <SEP> elements <SEP> enum <SEP> tmp <SEP> tmp <SEP> nodes <SEP> paths
<PLACE_HOLDER> url must match <PLACE_HOLDER> url must not match <PLACE_HOLDER> ip must match <PLACE_HOLDER> ip must not match <PLACE_HOLDER> country must match <PLACE_HOLDER> no depth limit match index url must match index url must not match index content must match index content must not match,this . default remote profile = new crawl profile ( crawl_profile_remote @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ __num__ @$ false @$ null @$ - __num__ @$ true @$ true @$ true @$ false @$ true @$ true @$ false @$ false @$ - __num__ @$ false @$ true @$ crawl profile . match_never_string @$ cache strategy . iffresh @$ __str__ + crawl_profile_remote @$ client identification . yacy internet crawler agent name @$ null @$ null @$ __num__ ) ;,ip match crawler,success,obj,crawlprofileremote <SEP> matchallstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> matchneverstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> num <SEP> num <SEP> num <SEP> matchneverstring <SEP> iffresh <SEP> str <SEP> crawlprofileremote <SEP> yacy <SEP> num
evaluate any karate <PLACE_HOLDER> even on lhs will throw exception if variable does not exist,actual = eval karate expression ( expression @$ context ) ; if ( actual . is json like ( ) ) { path = var_root ; },expression throw exception,success,sub,eval <SEP> json <SEP> varroot
this needs to do a binary search @$ but a binary search is somewhat tough because the sequence <PLACE_HOLDER> involves two nodes .,int size = vec . size ( ) @$ i ; for ( i = size - __num__ ; i >= __num__ ; i -- ) { int child = vec . element at ( i ) ; if ( child == node ) { i = - __num__ ; break ; } dtm dtm = m_dtm mgr . getdtm ( node ) ; if ( ! dtm . is node after ( node @$ child ) ) { break ; } },test involves nodes,success,sub,int <SEP> vec <SEP> num <SEP> num <SEP> int <SEP> vec <SEP> num <SEP> dtm <SEP> dtm <SEP> mdtm <SEP> getdtm <SEP> dtm
box drawings light horizontal @$ so box drawings light <PLACE_HOLDER> @$ so box drawings light down and right @$ so box drawings light down and left @$ so box drawings light up and left @$ so box drawings light up and right @$ so box drawings light <PLACE_HOLDER> and right @$ so box drawings light down and horizontal @$ so box drawings light <PLACE_HOLDER>,return new object [ ] [ ] { { __str__ @$ __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__ + __str__,drawings light vertical,success,obj,str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
<PLACE_HOLDER> ls exception .,throw lse ; throw ( ls exception ) createls exception ( ls exception . serialize_err @$ e ) . fill in stack trace ( ) ; if ( fdom error handler != null ) { fdom error handler . handle error ( new dom error impl ( dom error . severity_fatal_error @$ e . get message ( ) @$ null @$ e ) ) ; } throw ( ls exception ) createls exception ( ls exception . serialize_err @$ e ) . fill in stack trace ( ) ;,rethrow ls exception,success,sub,ls <SEP> createls <SEP> ls <SEP> serializeerr <SEP> fdom <SEP> fdom <SEP> impl <SEP> severityfatalerror <SEP> ls <SEP> createls <SEP> ls <SEP> serializeerr
if we have <PLACE_HOLDER> combine their transforms,while ( parent node != null ) { if ( parent == current spatial ) { transform trans = new transform ( ) ; trans . set scale ( current spatial . get local scale ( ) ) ; shape transform . combine with parent ( trans ) ; parent node = null ; } else { shape transform . combine with parent ( current spatial . get local transform ( ) ) ; parent node = current spatial . get parent ( ) ; current spatial = parent node ; } },them combine transforms,fail,sub,None
<PLACE_HOLDER> added global foo,check symbol ( symbols [ __num__ ] @$ __str__ @$ true ) ;,both added foo,success,sub,symbols <SEP> num <SEP> str
create a table with a primary key named 'name ' @$ <PLACE_HOLDER> holds a string,new condition ( ) . with comparison operator ( comparison operator . gt . to string ( ) ) . with attribute value list ( new attribute value ( ) . withn ( __str__ ) ) ; scan filter . put ( __str__ @$ condition ) ; scan request scan request = new scan request ( tablename ) . with scan filter ( scan filter ) ; scan result scan result = dynamodb client . scan ( scan request ) ; logger . info ( __str__ + scan result ) ; } catch ( amazon service exception ase ) { logger . error ( __str__ + ase ) ; } catch ( amazon client exception ace ) { logger . error ( __str__ + ace ) ; },which holds string,success,sub,withn <SEP> str <SEP> str <SEP> tablename <SEP> dynamodb <SEP> str <SEP> ase <SEP> str <SEP> ase <SEP> str
most <PLACE_HOLDER> use the object number for p 2 @$ nut not all,area ) config . get device ( ) ; int mode = area . get mode for string ( command . to string ( ) ) ; if ( mode >= __num__ ) { cmd = omni link cmd . cmd_security_omni_disarm . get number ( ) + mode ; param1 = __num__ ; commands . add ( new omni link controller command ( cmd @$ param1 @$ param2 ) ) ; } } } break ; case button : { if ( command instanceof string type ) { cmd = omni link cmd . cmd_button . get number ( ) ; commands . add ( new omni link controller command ( cmd @$ param1 @$ param2 ) ) ; } } break ; default : break ; },commands use number,success,sub,config <SEP> int <SEP> num <SEP> cmd <SEP> cmd <SEP> cmdsecurityomnidisarm <SEP> param1 <SEP> num <SEP> commands <SEP> cmd <SEP> param1 <SEP> param2 <SEP> instanceof <SEP> cmd <SEP> cmd <SEP> cmdbutton <SEP> commands <SEP> cmd <SEP> param1 <SEP> param2
check that above <PLACE_HOLDER> did not change internal state of the policy qualifier info instance,assert true ( arrays . equals ( encoding @$ encoding ret1 ) ) ;,modification change state,success,sub,arrays <SEP> equals <SEP> encoding <SEP> encoding <SEP> ret1
the list of relational values should contain 2 or more values : the first represents the <PLACE_HOLDER> the rest represent the fk,if ( relational value sources . size ( ) < __num__ ) { throw new mapping exception ( string . format ( locale . english @$ __str__ @$ jaxb any mapping . get name ( ) ) @$ origin ( ) ) ; } this . discriminator source = new any discriminator source ( ) { private final hibernate type source type source = new hibernate type source impl ( jaxb any mapping . get meta type ( ) ) ; private final relational value source relational value source = relational value sources . get ( __num__ ) ; private final map < string @$ string > value mappings = new hash map < string @$ string > ( ) ; { for ( jaxb hbm any value,first represents discriminator,success,obj,sources <SEP> num <SEP> str <SEP> jaxb <SEP> discriminator <SEP> discriminator <SEP> impl <SEP> jaxb <SEP> sources <SEP> num <SEP> mappings <SEP> jaxb <SEP> hbm
in this case first call to end <PLACE_HOLDER> returns correct value @$ but a second thread has updated the source topic but since it 's a source topic @$ the second check should not fire hence no exception,consumer . add end offsets ( collections . singleton map ( topic partition @$ __num__ ) ) ; changelog reader . register ( new state restorer ( topic partition @$ restore listener @$ null @$ __num__ @$ true @$ __str__ @$ identity ( ) ) ) ; expect ( active . restoring task for ( topic partition ) ) . and return ( task ) ; replay ( active ) ; changelog reader . restore ( active ) ;,offsets returns value,success,sub,offsets <SEP> collections <SEP> num <SEP> changelog <SEP> num <SEP> str <SEP> restoring <SEP> changelog
metadata <PLACE_HOLDER> have no entropy,assert that ( handle . get metadata handle ( ) . get file path ( ) . to string ( ) @$ not ( contains string ( entropy_marker ) ) ) ; assert that ( handle . get metadata handle ( ) . get file path ( ) . to string ( ) @$ not ( contains string ( resolved_marker ) ) ) ;,streams have entropy,fail,sub,contains <SEP> entropymarker <SEP> contains <SEP> resolvedmarker
change resolutions and check that the selected date is not lost and that the <PLACE_HOLDER> has the correct resolution .,click ( resolution hour ) ; check header and body ( date time resolution . hour @$ false ) ; click ( resolution year ) ; check header and body ( date time resolution . year @$ false ) ; click ( resolution minute ) ; check header and body ( date time resolution . minute @$ false ) ;,day has resolution,fail,sub,minute <SEP> minute
<PLACE_HOLDER> map local work,local work = mrwork . get map red local work ( ) ; exec context . set local work ( local work ) ; mapred context . init ( true @$ new job conf ( jc ) ) ; mo . pass exec context ( exec context ) ; mo . initialize local work ( jc ) ; mo . initialize map operator ( jc ) ; if ( local work == null ) { return ; },initialize map work,success,sub,mrwork <SEP> mapred <SEP> init <SEP> conf <SEP> jc <SEP> jc <SEP> jc
the processor does n't taint the consumer <PLACE_HOLDER> which has already finished,span processor span = take span ( consumer spans ) ; assert that ( processor span . id ( ) ) . is not equal to ( consumer span . id ( ) ) ;,processor taint span,success,obj,spans
<PLACE_HOLDER> asked build interruption @$ let stop the build before trying to run another build step,if ( executor != null && executor . is interrupted ( ) ) { throw new interrupted exception ( ) ; },someone build interruption,success,sub,interrupted <SEP> interrupted
rather than fight it @$ let root have an <PLACE_HOLDER>,nodes . put ( __str__ @$ root ) ; nodes . put ( root zookeeper @$ root ) ; root . add child ( proc child zookeeper ) ; nodes . put ( proc zookeeper @$ proc data node ) ; proc data node . add child ( quota child zookeeper ) ; nodes . put ( quota zookeeper @$ quota data node ) ;,root have effect,fail,obj,nodes <SEP> str <SEP> nodes <SEP> proc <SEP> nodes <SEP> proc <SEP> proc <SEP> proc <SEP> nodes
test case of child filling its <PLACE_HOLDER> @$ but its <PLACE_HOLDER> is n't filling its own <PLACE_HOLDER> .,builder . set layer ( __num__ ) . set is visible ( true ) ; final test window container visible unspecified root child child fills parent = visible unspecified root child . add child window ( builder ) ; visible unspecified root child child fills parent . set orientation ( screen_orientation_portrait ) ; assert equals ( screen_orientation_portrait @$ visible unspecified root child child fills parent . get orientation ( ) ) ; assert equals ( screen_orientation_unset @$ visible unspecified root child . get orientation ( ) ) ; assert equals ( screen_orientation_behind @$ root . get orientation ( ) ) ; visible unspecified root child . set fills parent ( true ) ; assert equals ( screen_orientation_portrait @$ visible unspecified root child . get orientation ( ) ),parent filling parent,success,obj,num <SEP> fills <SEP> fills <SEP> screenorientationportrait <SEP> equals <SEP> screenorientationportrait <SEP> fills <SEP> equals <SEP> screenorientationunset <SEP> equals <SEP> screenorientationbehind <SEP> fills <SEP> equals <SEP> screenorientationportrait
dispatching to empty <PLACE_HOLDER> will not call back visitor @$ must call our visit empty <PLACE_HOLDER> explicitly,if ( finally statement instanceof empty statement ) { visit empty statement ( ( empty statement ) finally statement ) ; } else { finally statement . visit ( this ) ; },statement call visitor,success,sub,instanceof
<PLACE_HOLDER> does n't throw interrupted exception @$ but may return some bytes geq 0 or throw an exception,while ( ! thread . current thread ( ) . is interrupted ( ) || closed ) { if ( closed ) { throw new io exception ( __str__ ) ; } },connection throw exception,success,sub,interrupted <SEP> io <SEP> str
updates the port when the <PLACE_HOLDER> changes the security type . this allows us to show a reasonable default which the <PLACE_HOLDER> can change .,m security type view . set on item selected listener ( new adapter view . on item selected listener ( ) { @ override public void on item selected ( adapter view < ? > parent @$ view view @$ int position @$ long id ) { if ( m current security type view position != position ) { update port from security type ( ) ; validate fields ( ) ; } } @ override public void on nothing selected ( adapter view < ? > parent ) { } } ) ;,user changes type,success,sub,selected <SEP> selected <SEP> selected <SEP> int <SEP> fields <SEP> selected
we capture and set the context once the <PLACE_HOLDER> provided observable emits,assert true ( results . is context initialized observe on . get ( ) ) ;,user provided emits,success,sub,results <SEP> initialized
do n't let the <PLACE_HOLDER> intercept our events .,src . get parent ( ) . request disallow intercept touch event ( true ) ; return true ;,parent intercept events,success,sub,src
the final thread that should n't execute releases the latch once it has run so it is deterministic that the other two fill the thread <PLACE_HOLDER> until this one rejects,if ( ! should execute ) { success latch . count down ( ) ; },two fill pool,success,obj,None
required features expect activity launch <PLACE_HOLDER> in,fail ( __str__ ) ;,features expect options,success,obj,str
if this mapping has a valid file <PLACE_HOLDER> then we close it,if ( fd . valid ( ) ) { try { nd . close ( fd ) ; } catch ( io exception ignore ) { } },mapping has descriptor,success,obj,fd <SEP> nd <SEP> close <SEP> fd <SEP> io
if we do n't have an mx record @$ try the machine <PLACE_HOLDER>,if ( ( attr == null ) || ( attr . size ( ) == __num__ ) ) { attrs = ictx . get attributes ( host name @$ new string [ ] { __str__ } ) ; attr = attrs . get ( __str__ ) ; if ( attr == null ) { throw new naming exception ( base messages . get string ( pkg @$ __str__ @$ host name ) ) ; } },attributes try machine,fail,sub,attr <SEP> attr <SEP> num <SEP> attrs <SEP> ictx <SEP> attributes <SEP> str <SEP> attr <SEP> attrs <SEP> str <SEP> attr <SEP> naming <SEP> messages <SEP> str
not sure which thread gets the <PLACE_HOLDER> first so we add them to a map and verify that some thread had 4 threads waiting @$ 3 threads @$ etc .,assert that ( map . size ( ) @$ equal to ( __num__ ) ) ; assert that ( map @$ has key ( __num__ ) ) ; assert that ( map @$ has key ( __num__ ) ) ; assert that ( map @$ has key ( __num__ ) ) ; assert that ( map @$ has key ( __num__ ) ) ; assert that ( map @$ has key ( __num__ ) ) ;,thread gets keys,fail,obj,num <SEP> num <SEP> num <SEP> num <SEP> num <SEP> num
for any <PLACE_HOLDER>s in the controller callback @$ test browser callback should have overridden the <PLACE_HOLDER> and call matching api in the callback proxy .,for ( int i = __num__ ; i < methods . length ; i ++ ) { assert not equals ( __str__ + methods [ i ] + __str__ @$ browser callback . class @$ methods [ i ] . get declaring class ( ) ) ; assert not equals ( __str__ + methods [ i ] + __str__ @$ controller callback . class @$ methods [ i ] . get declaring class ( ) ) ; },callback overridden method,success,obj,int <SEP> num <SEP> methods <SEP> equals <SEP> str <SEP> methods <SEP> str <SEP> methods <SEP> declaring <SEP> equals <SEP> str <SEP> methods <SEP> str <SEP> methods <SEP> declaring
crawler <PLACE_HOLDER> must match crawler <PLACE_HOLDER> must not match crawler ip must match crawler ip must not match crawler country must match crawler no depth limit match index <PLACE_HOLDER> must match index <PLACE_HOLDER> must not match index content must match index content must not match,profile = new crawl profile ( crawl_profile_snippet_global_text @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ __num__ @$ false @$ crawl profile . get recrawl date ( crawl_profile_snippet_global_text_recrawl_cycle ) @$ - __num__ @$ true @$ true @$ true @$ false @$ true @$ true @$ true @$ false @$ - __num__ @$ false @$ true @$ crawl profile . match_never_string @$ cache strategy . ifexist @$ __str__ + crawl_profile_snippet_global_text @$ client identification . yacy intranet crawler agent name @$ null @$ null @$ __num__ ) ;,url match crawler,success,sub,crawlprofilesnippetglobaltext <SEP> matchallstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> matchneverstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> matchallstring <SEP> matchneverstring <SEP> num <SEP> recrawl <SEP> crawlprofilesnippetglobaltextrecrawlcycle <SEP> num <SEP> num <SEP> matchneverstring <SEP> ifexist <SEP> str <SEP> crawlprofilesnippetglobaltext <SEP> yacy <SEP> num
create a walker <PLACE_HOLDER> walks the tree in a dfs manner while maintaining the operator stack . the dispatcher generates the plan from the operator tree,put ( hive parser . tok_interval_day_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_hour_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_minute_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_second_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_table_or_col @$ tf . get column expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_subquery_expr @$ tf . get sub query expr processor ( ) ) ;,which walks tree,success,sub,parser <SEP> tokintervaldayliteral <SEP> tf <SEP> expr <SEP> parser <SEP> tokintervalhourliteral <SEP> tf <SEP> expr <SEP> parser <SEP> tokintervalminuteliteral <SEP> tf <SEP> expr <SEP> parser <SEP> tokintervalsecondliteral <SEP> tf <SEP> expr <SEP> parser <SEP> toktableorcol <SEP> tf <SEP> expr <SEP> parser <SEP> toksubqueryexpr <SEP> tf <SEP> expr
if a component specifies the file with a bad font @$ the corresponding <PLACE_HOLDER> will be initialized by default physical font . in such case find font 2 d may return composite font which can not be casted to physical font .,if ( ! component names [ slot ] . equals ignore case ( name ) ) { try { components [ slot ] = ( physical font ) fm . find font2d ( component names [ slot ] @$ style @$ font manager . physical_fallback ) ; } catch ( class cast exception cce ) { components [ slot ] = fm . get default physical font ( ) ; } },component find font,fail,sub,names <SEP> equals <SEP> components <SEP> font2d <SEP> names <SEP> physicalfallback <SEP> cce <SEP> components
how many header <PLACE_HOLDER> ?,int argnr = rep . count nr job entry attributes ( id_jobentry @$ __str__ ) ; allocate ( argnr ) ; for ( int a = __num__ ; a < argnr ; a ++ ) { header name [ a ] = rep . get job entry attribute string ( id_jobentry @$ a @$ __str__ ) ; header value [ a ] = rep . get job entry attribute string ( id_jobentry @$ a @$ __str__ ) ; },many header name,success,obj,int <SEP> argnr <SEP> attributes <SEP> idjobentry <SEP> str <SEP> argnr <SEP> int <SEP> num <SEP> argnr <SEP> idjobentry <SEP> str <SEP> idjobentry <SEP> str
because entries <PLACE_HOLDER> is empty @$ remove and decrement value,if ( entries . is empty ( ) ) { synchronized ( entries ) { if ( entries . is empty ( ) ) { if ( value to entries map . remove ( new key @$ entries ) ) { num index keys . decrement and get ( ) ; internal index stats . inc num keys ( - __num__ ) ; } } } },map empty value,fail,sub,entries <SEP> synchronized <SEP> entries <SEP> entries <SEP> entries <SEP> entries <SEP> num <SEP> keys <SEP> decrement <SEP> num <SEP> keys <SEP> num
assume properties contain <PLACE_HOLDER>,if ( property value == null ) { if ( require property ) { throw new illegal argument exception ( __str__ + property key + __str__ + property key + __str__ ) ; } else { return null ; } } property value = get slashy path ( property value ) ; property value = correct double slash ( property value @$ property index end @$ str ) ; result += property value ; property index end ++ ; property index start = property index end ;,properties contain paths,success,obj,str <SEP> str <SEP> str <SEP> slashy <SEP> str
each <PLACE_HOLDER> will have a unique consumer group id . in this case we have two queries and 3 consumers . so we should expect two results from the current consumption rate by <PLACE_HOLDER> call .,assert equals ( __num__ @$ consumption by query . size ( ) ) ;,query have group,success,sub,equals <SEP> num
the second line has a ' <PLACE_HOLDER> ' @$ so it needs more ascent and descent .,if ( m enabled ) { assert equals ( - __num__ * em @$ layout . get line ascent ( __num__ ) ) ; assert equals ( __num__ * em @$ layout . get line descent ( __num__ ) ) ; } else { assert equals ( - em @$ layout . get line ascent ( __num__ ) ) ; assert equals ( __num__ * em @$ layout . get line descent ( __num__ ) ) ; },line has b,success,obj,equals <SEP> num <SEP> num <SEP> equals <SEP> num <SEP> num <SEP> equals <SEP> num <SEP> equals <SEP> num <SEP> num
<PLACE_HOLDER> on parent would have precedence,attribute conversion info conversion = locate attribute conversion info ( property name ) ; if ( conversion != null ) { return conversion ; } return null ;,conversion have precedence,fail,sub,None
loading child elements modifies the <PLACE_HOLDER> of the attribute set 's underlying parser @$ so it needs to happen after obtaining attributes and extracting <PLACE_HOLDER>s .,if ( dr == null ) { int type ; while ( ( type = parser . next ( ) ) == xml pull parser . text ) { } if ( type != xml pull parser . start_tag ) { throw new xml pull parser exception ( parser . get position description ( ) + item_missing_drawable_error ) ; } if ( parser . get name ( ) . equals ( __str__ ) ) { dr = vector drawable compat . create from xml inner ( resources @$ parser @$ attrs @$ theme ) ; } else if ( sdk_int >= lollipop ) { dr = drawable . create from xml inner ( resources @$ parser @$ attrs @$ theme ) ; } else { dr = drawable,elements modifies state,success,obj,int <SEP> parser <SEP> parser <SEP> parser <SEP> starttag <SEP> parser <SEP> parser <SEP> itemmissingdrawableerror <SEP> parser <SEP> equals <SEP> str <SEP> drawable <SEP> compat <SEP> resources <SEP> parser <SEP> attrs <SEP> sdkint <SEP> drawable <SEP> resources <SEP> parser <SEP> attrs <SEP> drawable
whether device <PLACE_HOLDER> enforces camera restriction .,boolean disallow camera globally = false ; if ( is device owner ) { final active admin device owner = get device owner admin locked ( ) ; if ( device owner == null ) { return ; } user restrictions = device owner . user restrictions ; disallow camera globally = device owner . disable camera ; } else { final active admin profile owner = get profile owner admin locked ( user id ) ; user restrictions = profile owner != null ? profile owner . user restrictions : null ; },owner enforces restriction,success,sub,locked <SEP> restrictions <SEP> restrictions <SEP> locked <SEP> restrictions <SEP> restrictions
<PLACE_HOLDER> what cloud we think we are in . publish our health as well .,udp heartbeat . build_and_multicast ( cloud @$ hb ) ;,test publish health,fail,sub,udp <SEP> buildandmulticast <SEP> hb
extension registry may be either extension registry or extension registry lite . since the type we are parsing is a full message @$ only a full extension registry could possibly contain <PLACE_HOLDER> of it . otherwise we will treat the registry as if it were empty .,if ( type . is extension number ( field number ) ) { if ( extension registry instanceof extension registry ) { final extension registry . extension info extension = target . find extension by number ( ( extension registry ) extension registry @$ type @$ field number ) ; if ( extension == null ) { field = null ; } else { field = extension . descriptor ; default instance = extension . default instance ; if ( default instance == null && field . get java type ( ) == descriptors . field descriptor . java type . message ) { throw new illegal state exception ( __str__ + field . get full name ( ) ) ; } } } else { field =,registry contain extensions,success,obj,instanceof <SEP> descriptors <SEP> str
and that local <PLACE_HOLDER> always takes preference over remote <PLACE_HOLDER> .,) ) ; differencer . inject ( metadata to inject ) ; evaluation context evaluation context = evaluation context . new builder ( ) . set keep going ( false ) . set num threads ( __num__ ) . set event hander ( null event handler . instance ) . build ( ) ; assert that ( driver . evaluate ( immutable list . of ( action key1 @$ action key2 ) @$ evaluation context ) . has error ( ) ) . is false ( ) ; assert that ( new filesystem value checker ( null @$ null ) . get dirty action values ( evaluator . get values ( ) @$ null @$ modified file set . everything_modified ) ) . is empty ( ) ;,storage takes preference,fail,sub,differencer <SEP> num <SEP> threads <SEP> num <SEP> hander <SEP> key1 <SEP> key2 <SEP> filesystem <SEP> values <SEP> evaluator <SEP> values <SEP> modified <SEP> everythingmodified
this dead <PLACE_HOLDER> hushes warnings .,return ;,code hushes warnings,success,sub,None
no <PLACE_HOLDER> left so close the actual server the done handler needs to be executed on the context that calls close @$ not the context of the actual server,actual server . actual close ( context @$ completion ) ;,error left server,fail,sub,close
all locks clients should be stopped at this point @$ and all all locks should be released because none of the clients entered the prepare <PLACE_HOLDER>,lock count visitor lock count visitor = new lock count visitor ( ) ; locks . accept ( lock count visitor ) ; assert equals ( __num__ @$ lock count visitor . get lock count ( ) ) ;,none entered phase,success,obj,locks <SEP> equals <SEP> num
<PLACE_HOLDER> uses total duration ms locked @$ while total uses total time locked,dump timer ( proto @$ uid proto . sync . total @$ timer @$ raw realtime us @$ which ) ; dump timer ( proto @$ uid proto . sync . background @$ bg timer @$ raw realtime us @$ which ) ; proto . end ( sy token ) ;,background uses time,success,sub,uid <SEP> realtime <SEP> uid <SEP> bg <SEP> realtime <SEP> sy
not seen yet ; must add an entry @$ return it . for that @$ we need <PLACE_HOLDER>,object id generator < ? > generator = null ; if ( _object id generators == null ) { _object id generators = new array list < object id generator < ? > > ( __num__ ) ; } else { for ( int i = __num__ @$ len = _object id generators . size ( ) ; i < len ; ++ i ) { object id generator < ? > gen = _object id generators . get ( i ) ; if ( gen . can use for ( generator type ) ) { generator = gen ; break ; } } } if ( generator == null ) { generator = generator type . new for serialization ( this ) ; _object id generators .,not need none,fail,obj,generators <SEP> generators <SEP> num <SEP> int <SEP> num <SEP> generators <SEP> generators <SEP> can <SEP> generators
more complicated . vh 2 has a higher version @$ but has some <PLACE_HOLDER> that vh 1 does not have .,region version holder vh1 = new region version holder ( member ) ; region version holder vh2 = new region version holder ( member ) ; bit set bs1 = new bit set ( ) ; bs1 . set ( __num__ @$ __num__ ) ; bs1 . set ( __num__ @$ __num__ ) ; record versions ( vh1 @$ bs1 ) ; bit set bs2 = new bit set ( ) ; bs2 . set ( __num__ @$ __num__ ) ; bs2 . set ( __num__ @$ __num__ ) ; record versions ( vh2 @$ bs2 ) ;,vh has exceptions,success,obj,vh1 <SEP> vh2 <SEP> bs1 <SEP> bs1 <SEP> num <SEP> num <SEP> bs1 <SEP> num <SEP> num <SEP> versions <SEP> vh1 <SEP> bs1 <SEP> bs2 <SEP> bs2 <SEP> num <SEP> num <SEP> bs2 <SEP> num <SEP> num <SEP> versions <SEP> vh2 <SEP> bs2
assertion on auto onboard another dummy data <PLACE_HOLDER>,metadata source config another dummymd source = ds to onboards map . get ( __str__ ) . get ( __num__ ) . get metadata source config ( ) ; assert . assert equals ( another dummymd source . get class name ( ) @$ __str__ ) ; assert . assert equals ( another dummymd source . get properties ( ) . size ( ) @$ __num__ ) ; assert . assert equals ( another dummymd source . get properties ( ) . get ( __str__ ) @$ __str__ ) ; assert . assert equals ( another dummymd source . get properties ( ) . get ( __str__ ) @$ __num__ ) ;,assertion onboard source,success,obj,config <SEP> dummymd <SEP> ds <SEP> onboards <SEP> str <SEP> num <SEP> config <SEP> equals <SEP> dummymd <SEP> str <SEP> equals <SEP> dummymd <SEP> properties <SEP> num <SEP> equals <SEP> dummymd <SEP> properties <SEP> str <SEP> str <SEP> equals <SEP> dummymd <SEP> properties <SEP> str <SEP> num
if the scope has no <PLACE_HOLDER> try to remove it,if ( ! ( ( basic scope ) broadcast scope ) . has event listeners ( ) ) { if ( log . is debug enabled ( ) ) { log . debug ( __str__ ) ; } scope . remove child scope ( broadcast scope ) ; } log . debug ( __str__ @$ name ) ;,scope has listeners,success,obj,listeners <SEP> str <SEP> str
if the final number of <PLACE_HOLDER>s to scroll ends up being 0 @$ the view should still scroll at least one <PLACE_HOLDER> .,return capped scroll step != __num__ ? capped scroll step : direction ;,view scroll step,fail,obj,capped <SEP> num <SEP> capped
the keys of probe and build <PLACE_HOLDER> are overlapped @$ so there would be none unmatched build elements after probe phase @$ make sure build side outer join works well in this case .,final int probe vals per key = __num__ ;,keys build sides,success,obj,int <SEP> vals <SEP> num
we capture and set the context once the <PLACE_HOLDER> provided observable emits,assert true ( results . is context initialized observe on . get ( ) ) ;,user provided emits,success,sub,results <SEP> initialized
start <PLACE_HOLDER> root element,not empty ( prefix ) ) xtw . write namespace ( prefix @$ model . get namespaces ( ) . get ( prefix ) ) ; } xtw . write attribute ( type_language_attribute @$ schema_namespace ) ; xtw . write attribute ( expression_language_attribute @$ xpath_namespace ) ; if ( string utils . is not empty ( model . get target namespace ( ) ) ) { xtw . write attribute ( target_namespace_attribute @$ model . get target namespace ( ) ) ; } else { xtw . write attribute ( target_namespace_attribute @$ process_namespace ) ; } bpmnxml util . write custom attributes ( model . get definitions attributes ( ) . values ( ) @$ xtw @$ model . get namespaces ( ) @$ default attributes ) ;,definitions root element,success,sub,xtw <SEP> namespace <SEP> namespaces <SEP> xtw <SEP> typelanguageattribute <SEP> schemanamespace <SEP> xtw <SEP> expressionlanguageattribute <SEP> xpathnamespace <SEP> utils <SEP> namespace <SEP> xtw <SEP> targetnamespaceattribute <SEP> namespace <SEP> xtw <SEP> targetnamespaceattribute <SEP> processnamespace <SEP> bpmnxml <SEP> util <SEP> attributes <SEP> definitions <SEP> attributes <SEP> values <SEP> xtw <SEP> namespaces <SEP> attributes
this <PLACE_HOLDER> has a bad acl @$ so we are dismissing it early .,if ( err != keeper exception . code . ok . int value ( ) ) { dec in process ( ) ; reply header rh = new reply header ( request . cxid @$ __num__ @$ err ) ; try { request . cnxn . send response ( rh @$ null @$ null ) ; } catch ( io exception e ) { log . error ( __str__ @$ e ) ; } },request has acl,success,sub,int <SEP> process <SEP> rh <SEP> cxid <SEP> num <SEP> cnxn <SEP> rh <SEP> io <SEP> str
special <PLACE_HOLDER> : if there were no files to measure @$ use the containing j scroll pane 's width,if ( d . width == __num__ && get parent ( ) != null ) { if ( get parent ( ) . get parent ( ) instanceof j scroll pane ) { j scroll pane parent = ( j scroll pane ) get parent ( ) . get parent ( ) ; dimension parent size = parent . get size ( ) ; insets insets = parent . get insets ( ) ; d . width = parent size . width - ( insets != null ? insets . right + insets . left : __num__ ) ; } } else { d . width += default_icon_size + width_padding ; },case use width,success,sub,num <SEP> instanceof <SEP> insets <SEP> insets <SEP> insets <SEP> insets <SEP> insets <SEP> insets <SEP> num <SEP> defaulticonsize <SEP> widthpadding
equal class with one maybe a primitive @$ the later explicit cast arguments will solve this <PLACE_HOLDER>,continue ;,class solve case,success,obj,None
the finally clause will send an <PLACE_HOLDER> .,remove decoder ( imgd ) ; if ( thread . current thread ( ) . is interrupted ( ) || ! thread . current thread ( ) . is alive ( ) ) { error all consumers ( imgd . queue @$ true ) ; } else { error all consumers ( imgd . queue @$ false ) ; },clause send error,success,obj,imgd <SEP> interrupted <SEP> consumers <SEP> imgd <SEP> consumers <SEP> imgd
0 x 1002346 : p 1 repeatable <PLACE_HOLDER> contains p 2 repeatable <PLACE_HOLDER> .,program builder1 . create comment ( __str__ @$ __str__ @$ code unit . repeatable_comment ) ; program builder2 . create comment ( __str__ @$ __str__ @$ code unit . repeatable_comment ) ;,comment contains comment,success,sub,builder1 <SEP> str <SEP> str <SEP> repeatablecomment <SEP> builder2 <SEP> str <SEP> str <SEP> repeatablecomment
we wo n't compare the candidate display name against the current item . this is to prevent an validation warning if the <PLACE_HOLDER> sets the display name to what the existing display name is,if ( item . get name ( ) . equals ( current job name ) ) { continue ; } else if ( display name . equals ( item . get display name ( ) ) ) { return false ; },user sets name,success,sub,equals <SEP> equals
<PLACE_HOLDER> set image drawable internally,super . set image bitmap ( bitmap ) ;,constructor set drawable,fail,sub,None
components commonly have conditional <PLACE_HOLDER>s assigned . using the click <PLACE_HOLDER> matcher we can assert whether or not a given component has a <PLACE_HOLDER> attached to them . noinspection unchecked,assert that ( c @$ component ) . extracting sub component at ( __num__ ) . has ( sub component with ( c @$ test footer component . matcher ( c ) . click handler ( is null . < event handler < click event > > null value ( null ) ) . build ( ) ) ) ;,component has event,fail,obj,extracting <SEP> num <SEP> matcher
report all volumes as unmounted until we 've recorded that user 0 has <PLACE_HOLDER> . there are no guarantees that callers will see a consistent view of the volume before that point,final boolean system user unlocked = is system unlocked ( user handle . user_system ) ; final boolean user key unlocked ; final boolean storage permission ; final long token = binder . clear calling identity ( ) ; try { user key unlocked = is user key unlocked ( user id ) ; storage permission = m storage manager internal . has external storage ( uid @$ package name ) ; } finally { binder . restore calling identity ( token ) ; } boolean found primary = false ; final array list < storage volume > res = new array list < > ( ) ; synchronized ( m lock ) { for ( int i = __num__ ; i < m volumes . size (,user has access,fail,obj,usersystem <SEP> uid <SEP> res <SEP> synchronized <SEP> int <SEP> num <SEP> volumes
the <PLACE_HOLDER> can specify the hadoop memory,map < string @$ string > variables = new hash map < string @$ string > ( system . getenv ( ) ) ;,environment specify memory,fail,sub,variables <SEP> getenv
since the calling <PLACE_HOLDER> will push the type again @$ we better remove it here,os . remove ( __num__ ) ;,code push type,success,sub,num
as the annotation is legal on fields and methods only @$ javac <PLACE_HOLDER> will take care of printing an error message for this .,return ;,processing take care,fail,sub,None
<PLACE_HOLDER> @$ like all package groups @$ does n't have a configuration,) { package group package group = ( package group ) target ; target context target context = new target context ( analysis environment @$ target @$ config @$ prerequisite map . get ( dependency resolver . visibility_dependency ) @$ visibility ) ; return new package group configured target ( target context @$ package group ) ; } else if ( target instanceof environment group ) { target context target context = new target context ( analysis environment @$ target @$ config @$ immutable set . of ( ) @$ visibility ) ; return new environment group configured target ( target context ) ; } else { throw new assertion error ( __str__ + target . get class ( ) . get name ( ) ) ; },looks have configuration,fail,sub,config <SEP> resolver <SEP> visibilitydependency <SEP> configured <SEP> instanceof <SEP> config <SEP> configured <SEP> str
x attr exists @$ and replace it using <PLACE_HOLDER> replace flag .,fs . setx attr ( path @$ name1 @$ value1 @$ enum set . of ( x attr set flag . create ) ) ; fs . setx attr ( path @$ name1 @$ new value1 @$ enum set . of ( x attr set flag . create @$ x attr set flag . replace ) ) ; xattrs = fs . getx attrs ( path ) ; assert . assert equals ( xattrs . size ( ) @$ __num__ ) ; assert . assert array equals ( new value1 @$ xattrs . get ( name1 ) ) ; fs . removex attr ( path @$ name1 ) ;,attrs replace flag,fail,sub,fs <SEP> setx <SEP> attr <SEP> name1 <SEP> value1 <SEP> enum <SEP> attr <SEP> fs <SEP> setx <SEP> attr <SEP> name1 <SEP> value1 <SEP> enum <SEP> attr <SEP> attr <SEP> xattrs <SEP> fs <SEP> getx <SEP> attrs <SEP> equals <SEP> xattrs <SEP> num <SEP> equals <SEP> value1 <SEP> xattrs <SEP> name1 <SEP> fs <SEP> removex <SEP> attr <SEP> name1
user should not see anything so give unsatisfiable <PLACE_HOLDER>,return process payload builder . process definitions ( ) . with process definition key ( __str__ + uuid . randomuuid ( ) . to string ( ) ) . build ( ) ;,anything give condition,success,obj,process <SEP> process <SEP> definitions <SEP> process <SEP> str <SEP> uuid <SEP> randomuuid
synchronously end the animation @$ jumping to the end state . animator <PLACE_HOLDER> has synchronous listener behavior on all supported ap is .,if ( ! animated ) { current animation . end ( ) ; },animation has behavior,fail,sub,None
the <PLACE_HOLDER> will require scrolling to get to all the items . extend the height so that part of the hidden items is displayed .,if ( actual size < m overflow panel . get count ( ) ) { extension = ( int ) ( m line height * __num__ ) ; },overflow extend height,success,sub,int <SEP> num
relative paths have no <PLACE_HOLDER> .,return new gcs path ( fs @$ __str__ @$ component ) ;,paths have symbols,fail,obj,gcs <SEP> fs <SEP> str
verify exit <PLACE_HOLDER> matches exit state of script,assert . assert equals ( exit code @$ container status . get exit status ( ) ) ;,code matches state,fail,sub,equals
then : '' collected must remove <PLACE_HOLDER> '',assert that ( tap . block ( ) ) . contains exactly ( __num__ @$ __num__ @$ __num__ ) ;,collected remove duplicates,success,obj,contains <SEP> num <SEP> num <SEP> num
fire should not purge <PLACE_HOLDER>,assert equals ( __num__ @$ test harness . num keyed state entries ( ) ) ;,fire purge contents,success,obj,equals <SEP> num <SEP> num <SEP> keyed <SEP> entries
assert the package tracker triggered an <PLACE_HOLDER> .,check update check triggered ( new package versions ) ; check token token2 = m fake intent helper . capture and reset last token ( ) ;,tracker triggered update,success,obj,triggered <SEP> versions <SEP> token2 <SEP> last
lcn type need connection <PLACE_HOLDER>,dtx local context . make proxy ( ) ;,type need proxy,success,obj,dtx
output node local <PLACE_HOLDER>,local properties lp = p . get local properties ( ) ; writer . print ( __str__ ) ; if ( lp . get ordering ( ) != null ) { add property ( writer @$ __str__ @$ lp . get ordering ( ) . to string ( ) @$ true ) ; } else { add property ( writer @$ __str__ @$ __str__ @$ true ) ; } if ( lp . get grouped fields ( ) != null && lp . get grouped fields ( ) . size ( ) > __num__ ) { add property ( writer @$ __str__ @$ lp . get grouped fields ( ) . to string ( ) @$ false ) ; } else { add property ( writer @$ __str__,output node properties,success,obj,properties <SEP> properties <SEP> str <SEP> str <SEP> str <SEP> str <SEP> grouped <SEP> fields <SEP> grouped <SEP> fields <SEP> num <SEP> str <SEP> grouped <SEP> fields <SEP> str
synchronize on scanner read <PLACE_HOLDER>s so that nobody calculates get smallest read <PLACE_HOLDER> @$ before scanner read <PLACE_HOLDER>s is updated .,isolation level isolation level = scan . get isolation level ( ) ; long mvcc read point = package private field accessor . get mvcc read point ( scan ) ; synchronized ( scanner read points ) { if ( mvcc read point > __num__ ) { this . read pt = mvcc read point ; } else if ( nonce == h constants . no_nonce || rs services == null || rs services . get nonce manager ( ) == null ) { this . read pt = get read point ( isolation level ) ; } else { this . read pt = rs services . get nonce manager ( ) . get mvcc from operation context ( nonce group @$ nonce ) ; } scanner,synchronize read point,success,obj,mvcc <SEP> accessor <SEP> mvcc <SEP> synchronized <SEP> points <SEP> mvcc <SEP> num <SEP> mvcc <SEP> constants <SEP> nononce <SEP> rs <SEP> services <SEP> rs <SEP> services <SEP> rs <SEP> services <SEP> mvcc
group the <PLACE_HOLDER> into those that use indexes and those that do n't @$ so we can evaluate all the <PLACE_HOLDER> that do n't use indexes together in one iteration first get filter <PLACE_HOLDER>,filter filter operands = null ;,iteration get operands,success,obj,operands
wait until the connection used by res 1 is returned to the pool @$ so that the next <PLACE_HOLDER> reuses the connection .,while ( ! connection returned to pool ) { condition . await ( ) ; } lock . unlock ( ) ;,callback reuses connection,fail,sub,returned
user already specified schema <PLACE_HOLDER>,if ( vendor extensions . contains key ( codegen_vendor_extension_key ) ) { logger . info ( __str__ + base name + __str__ ) ; return ; },user specified values,success,obj,extensions <SEP> contains <SEP> codegenvendorextensionkey <SEP> str <SEP> str
verify that mock provider 2 contains a new <PLACE_HOLDER> named the same as the parent meta <PLACE_HOLDER> of the contact we just moved,contact group new grpp2 = mcl slick fixture . mock pres op setp2 . get server stored contact list root ( ) . get group ( mcl slick fixture . metap1 grp1 . get group name ( ) ) ; assert not null ( __str__ + mcl slick fixture . emilp2 . get display name ( ) + __str__ @$ new grpp2 ) ;,group named same,success,sub,grpp2 <SEP> mcl <SEP> pres <SEP> setp2 <SEP> stored <SEP> mcl <SEP> metap1 <SEP> grp1 <SEP> str <SEP> mcl <SEP> emilp2 <SEP> str <SEP> grpp2
the test passed @$ so just <PLACE_HOLDER> from main and harness will interepret this <PLACE_HOLDER> as a pass,return ;,return interepret return,success,sub,None
javax mail incorrectly adds the <PLACE_HOLDER> for the first boundary to the end of the preamble @$ so we trim,assert . assert equals ( javax mail multi partmime reader . _preamble != null ? javax mail multi partmime reader . _preamble . trim ( ) : null @$ expected preamble ) ;,mail adds crlf,success,obj,equals <SEP> javax <SEP> partmime <SEP> javax <SEP> partmime
all other operands require a <PLACE_HOLDER>,return register priority . must have register ;,operands require register,success,obj,None
the response object does n't contain any relevant <PLACE_HOLDER> so we have to create a copy of values being sent over the network in case m jp settings is modified while awaiting response,final jetpack settings model sent jp data = new jetpack settings model ( m jp settings ) ; ++ m save request count ; word press . get rest client utilsv1_1 ( ) . set jetpack settings ( m site . get site id ( ) @$ params @$ new rest request . listener ( ) { @ override public void on response ( json object response ) { app log . d ( app log . t . api @$ __str__ ) ; m remote jp settings . monitor active = sent jp data . monitor active ; m remote jp settings . jetpack protect enabled = sent jp data . jetpack protect enabled ; m remote jp settings . jetpack protect whitelist . clear ( ),object contain information,fail,obj,settings <SEP> settings <SEP> settings <SEP> utilsv11 <SEP> settings <SEP> params <SEP> json <SEP> str <SEP> settings <SEP> settings <SEP> settings <SEP> whitelist
override the reporter with our own <PLACE_HOLDER> collates the allocation sites .,close guard . set reporter ( new reporter ( ) { @ override public void report ( string message @$ throwable allocation site ) { close guard allocation sites . add ( allocation site ) ; } } ) ;,which collates sites,success,sub,close <SEP> throwable <SEP> close <SEP> sites
check if no <PLACE_HOLDER> has focus,view view = get current focus ( ) ; if ( view != null ) { input method manager input manager = ( input method manager ) get system service ( context . input_method_service ) ; if ( input manager != null ) input manager . hide soft input from window ( view . get window token ( ) @$ input method manager . hide_not_always ) ; },view has focus,success,sub,inputmethodservice <SEP> hidenotalways
for binary set the response op <PLACE_HOLDER>,if ( this . protocol == protocol . binary ) { reply . rewind ( ) ; reply . put ( position_opcode @$ buffer . get ( position_opcode ) ) ; reply . put int ( position_opaque @$ buffer . get int ( position_opaque ) ) ; if ( connection handler . get logger ( ) . finer enabled ( ) ) { connection handler . get logger ( ) . finer ( __str__ + reply + __str__ + command . bufferto string ( reply ) ) ; } } socket channel channel = this . socket . get channel ( ) ; if ( channel == null || ! channel . is open ( ) ) { throw new illegal state exception ( __str__ ) ; },binary set code,success,obj,positionopcode <SEP> positionopcode <SEP> int <SEP> positionopaque <SEP> int <SEP> positionopaque <SEP> finer <SEP> finer <SEP> str <SEP> str <SEP> bufferto <SEP> str
should use root entity <PLACE_HOLDER> by default,criteria executor criteria executor = new criteria executor ( ) { protected criteria get criteria ( session s ) { return s . create criteria ( enrolment . class @$ __str__ ) . create alias ( __str__ @$ __str__ @$ criteria . left_join ) . set fetch mode ( __str__ @$ fetch mode . join ) . set fetch mode ( __str__ @$ fetch mode . join ) . set projection ( projections . projection list ( ) . add ( projections . property ( __str__ ) ) . add ( projections . property ( __str__ ) ) ) . add order ( order . asc ( __str__ ) ) ; } } ;,use root transformer,success,obj,criteria <SEP> criteria <SEP> criteria <SEP> protected <SEP> criteria <SEP> criteria <SEP> criteria <SEP> str <SEP> str <SEP> str <SEP> criteria <SEP> leftjoin <SEP> str <SEP> str <SEP> projections <SEP> projections <SEP> str <SEP> projections <SEP> str <SEP> asc <SEP> str
<PLACE_HOLDER> can add internal system window,return create window ( parent @$ type @$ token @$ name @$ owner id @$ false ) ;,owner add window,success,sub,None
the first two <PLACE_HOLDER> have the same priority,final task task = noop task . create ( math . min ( __num__ @$ ( i - __num__ ) * __num__ ) ) ;,tasks have priority,success,sub,noop <SEP> num <SEP> num <SEP> num
make sure the master has <PLACE_HOLDER> of the reports,waiter . wait for ( test_util . get configuration ( ) @$ __num__ * __num__ @$ new predicate < exception > ( ) { @ override public boolean evaluate ( ) throws exception { map < region info @$ long > region sizes = quota manager . snapshot region sizes ( ) ; log . trace ( __str__ + region sizes ) ; return num regions == count regions for table ( tn @$ region sizes ) && table size <= get table size ( tn @$ region sizes ) ; } } ) ; map < table name @$ long > sizes = test_util . get admin ( ) . get space quota table sizes ( ) ; long size = sizes . get ( tn ),master has all,success,obj,testutil <SEP> num <SEP> num <SEP> throws <SEP> sizes <SEP> sizes <SEP> str <SEP> sizes <SEP> num <SEP> regions <SEP> regions <SEP> sizes <SEP> sizes <SEP> sizes <SEP> testutil <SEP> sizes <SEP> sizes
test once using the current correct hash function @$ expect no mispartitioned <PLACE_HOLDER>,client response cr = client . call procedure ( __str__ @$ ( object ) null ) ; volt table hashinator matches = cr . get results ( ) [ __num__ ] ; hashinator matches . advance row ( ) ; while ( hashinator matches . advance row ( ) ) { assert equals ( __num__ @$ hashinator matches . get long ( __str__ ) ) ; } volt table validate result = cr . get results ( ) [ __num__ ] ;,test expect rows,success,obj,cr <SEP> str <SEP> hashinator <SEP> matches <SEP> cr <SEP> results <SEP> num <SEP> hashinator <SEP> matches <SEP> row <SEP> hashinator <SEP> matches <SEP> row <SEP> equals <SEP> num <SEP> hashinator <SEP> matches <SEP> str <SEP> cr <SEP> results <SEP> num
make a copy of the graph to avoid concurrency problems . graph manipulations are not thread safe @$ and another thread can concurrently inline this <PLACE_HOLDER> .,final structured graph graph = ( structured graph ) method . compilation info . get graph ( ) . copy ( debug ) ; try ( debug context . scope s = debug . scope ( __str__ @$ graph @$ method @$ this ) ) { try { try ( indent in = debug . log and indent ( __str__ @$ method ) ) { boolean inlined = false ; for ( invoke invoke : graph . get invokes ( ) ) { if ( invoke instanceof invoke node ) { throw vm error . should not reach here ( __str__ + invoke . call target ( ) . target method ( ) . format ( __str__ ) + __str__ + ( graph . method ( ) ==,thread inline method,success,obj,structured <SEP> structured <SEP> str <SEP> str <SEP> inlined <SEP> invokes <SEP> instanceof <SEP> vm <SEP> str <SEP> str <SEP> str
return null since neither dm nor dls are shutting down can not call <PLACE_HOLDER> in progress because it 's abstract,return null ;,null call anything,fail,obj,None
null <PLACE_HOLDER> does n't actually retain the session,assert false ( cache . contains ( __str__ ) ) ;,properties retain session,fail,sub,contains <SEP> str
<PLACE_HOLDER> does n't recover any more the recovered <PLACE_HOLDER> should not call retain assignment @$ as it is not a clean startup .,assert false ( __str__ @$ mock load balancer . retain assign called ) ;,master recover master,success,obj,str <SEP> balancer <SEP> called
make sure the new <PLACE_HOLDER> has the same level as the old one,new comment . level = this . get ( index ) . level ; this . set ( index @$ new comment ) ; return true ;,comment has level,success,sub,None
queue c <PLACE_HOLDER> has sa and aq @$ both from parent,assert true ( c111 . has access ( queueacl . administer_queue @$ user ) ) ; assert true ( has queueacl ( acl infos @$ queueacl . administer_queue @$ __str__ ) ) ; assert true ( c111 . has access ( queueacl . submit_applications @$ user ) ) ; assert true ( has queueacl ( acl infos @$ queueacl . submit_applications @$ __str__ ) ) ; reset ( c ) ;,11 has sa,fail,sub,c111 <SEP> queueacl <SEP> administerqueue <SEP> queueacl <SEP> acl <SEP> infos <SEP> queueacl <SEP> administerqueue <SEP> str <SEP> c111 <SEP> queueacl <SEP> submitapplications <SEP> queueacl <SEP> acl <SEP> infos <SEP> queueacl <SEP> submitapplications <SEP> str
will be null when the feature to use minimized <PLACE_HOLDER> is disabled .,if ( minimized bitcode == null ) { return full bitcode ; } return minimized bitcode ;,feature use bitmap,fail,obj,minimized <SEP> bitcode <SEP> bitcode <SEP> minimized <SEP> bitcode
push twice will fail and temp dir <PLACE_HOLDER>,file out dir = new file ( string utils . format ( __str__ @$ config . get storage directory ( ) @$ segment path ) ) ; out dir . set read only ( ) ; try { pusher . push ( segment dir @$ segments [ i ] @$ false ) ; } catch ( io exception e ) { assert . fail ( __str__ ) ; },push fail cleaned,success,obj,dir <SEP> utils <SEP> str <SEP> config <SEP> dir <SEP> dir <SEP> segments <SEP> io <SEP> str
seek to the end just before the last page of stream to get the <PLACE_HOLDER> .,long last page search position = end position - ogg page header . max_page_size ; if ( last page search position > position before seek to end ) { return last page search position ; },page get duration,success,obj,last <SEP> ogg <SEP> maxpagesize <SEP> last <SEP> last
registers a callback to be invoked whenever a <PLACE_HOLDER> changes a preference .,get preference screen ( ) . get shared preferences ( ) . register on shared preference change listener ( this ) ;,user changes preference,success,sub,shared <SEP> preferences <SEP> shared
now reptable has 2000 <PLACE_HOLDER> and parttable has 252 <PLACE_HOLDER>,thread . sleep ( __num__ ) ; save tables with default nonce and path ( client ) ; wait for snapshot to finish ( client ) ;,reptable has rows,success,obj,num <SEP> tables
<PLACE_HOLDER> should remove visibility .,assert true ( m accounts db . delete de account ( acc id ) ) ;,display remove visibility,fail,sub,accounts <SEP> db <SEP> acc
make sure the <PLACE_HOLDER> outlives the gc,if ( ( flags & ( call_type_callback | call_type_global_value | call_type_struct_member ) ) > __num__ ) { o . retain ( ) ; },object outlives gc,success,sub,flags <SEP> calltypecallback <SEP> calltypeglobalvalue <SEP> calltypestructmember <SEP> num
<PLACE_HOLDER> only represent configuration details of the parent @$ and are not independent entities,return false ;,nodes represent details,fail,sub,None
object has default meta <PLACE_HOLDER> @$ so we need to replace it on demand,object = obj ;,object has class,success,obj,obj
the <PLACE_HOLDER> of relational values should contain 2 or more values : the first represents the discriminator the rest represent the fk,( jaxb many to any mapping . get id type ( ) ) ; private final list < relational value source > fk relational value sources = relational value sources . sub list ( __num__ @$ relational value sources . size ( ) ) ; @ override public hibernate type source get type source ( ) { return fk type source ; } @ override public list < relational value source > get relational value sources ( ) { return fk relational value sources ; } @ override public attribute path get attribute path ( ) { return plural attribute source . get attribute path ( ) ; } @ override public metadata building context get building context ( ) { return mapping document ; } } ;,list contain values,success,sub,jaxb <SEP> fk <SEP> sources <SEP> sources <SEP> num <SEP> sources <SEP> fk <SEP> sources <SEP> fk <SEP> sources
some systems send update <PLACE_HOLDER> before call is established to update call screening @$ if we do not process them and just send 501 we end the dialog and the call will fail to establish @$ so we just send ok,return false ;,systems send codecs,fail,obj,None
release app 2 's am <PLACE_HOLDER> on node 2 .,scheduler . handle ( app removed event2 ) ; assert equals ( __str__ @$ __num__ @$ queue1 . get am resource usage ( ) . get memory size ( ) ) ; scheduler . update ( ) ;,release app container,success,obj,removed <SEP> event2 <SEP> equals <SEP> str <SEP> num <SEP> queue1
no averagers returned <PLACE_HOLDER> . all buckets must be empty . skip this row .,return null ;,averagers returned nulls,fail,obj,None
check if we can use the fast path @$ resuming a session . we can do so iff we have a valid record for that session @$ and the cipher suite for that session was on the list which the <PLACE_HOLDER> requested @$ and if we 're not forgetting any needed authentication on the part of the <PLACE_HOLDER> .,__str__ + session identity alg ) ; } resuming session = false ; } } if ( resuming session ) { cipher suite suite = previous . get suite ( ) ; if ( ( is negotiable ( suite ) == false ) || ( mesg . get cipher suites ( ) . contains ( suite ) == false ) ) { resuming session = false ; } else { set cipher suite ( suite ) ; } } if ( resuming session ) { session = previous ; if ( debug != null && ( debug . is on ( __str__ ) || debug . is on ( __str__ ) ) ) { system . out . println ( __str__ + session ) ; } } },server requested which,fail,sub,str <SEP> alg <SEP> resuming <SEP> resuming <SEP> mesg <SEP> suites <SEP> contains <SEP> resuming <SEP> resuming <SEP> str <SEP> str <SEP> println <SEP> str
if the number of posts on this blog that use this <PLACE_HOLDER> is higher than previous @$ set this as the most popular <PLACE_HOLDER> @$ and set the second most popular <PLACE_HOLDER> to the current most popular <PLACE_HOLDER>,int post count = json this tag . opt int ( __str__ ) ; if ( post count > popular count ) { next most popular tag = most popular tag ; most popular tag = this tag name ; popular count = post count ; } else if ( next most popular tag == null ) { next most popular tag = this tag name ; },number set tag,success,obj,int <SEP> json <SEP> int <SEP> str
check that pause resume wo n't call the end <PLACE_HOLDER> prematurely,resp . pause ( ) ; resp . resume ( ) ;,resume call method,fail,obj,resp <SEP> resp
hint arrow has no <PLACE_HOLDER> @$ and always returns the current <PLACE_HOLDER>,if ( is in agility arena ( ) ) { world point new ticket position = client . get hint arrow point ( ) ; world point old tick position = last arena ticket position ; last arena ticket position = new ticket position ; if ( old tick position != null && new ticket position != null && ( old tick position . getx ( ) != new ticket position . getx ( ) || old tick position . gety ( ) != new ticket position . gety ( ) ) ) { log . debug ( __str__ @$ old tick position @$ new ticket position ) ; if ( config . notify agility arena ( ) ) { notifier . notify ( __str__ ) ; },arrow has position,fail,obj,last <SEP> last <SEP> getx <SEP> getx <SEP> gety <SEP> gety <SEP> str <SEP> config <SEP> notifier <SEP> str
pairs now contains a uniquified <PLACE_HOLDER> of the sorted inputs @$ with counts for how often that item appeared . now sort by how frequently they occur @$ and pick the most frequent . if the first place is tied between two @$ do n't pick any .,collections . sort ( pairs ) ; final pair first pair = pairs . get ( __num__ ) ; if ( pairs . size ( ) == __num__ ) return first pair . item ; final pair second pair = pairs . get ( __num__ ) ; if ( first pair . count > second pair . count ) return first pair . item ; check state ( first pair . count == second pair . count ) ; return __num__ ;,list pick any,success,sub,collections <SEP> pairs <SEP> pairs <SEP> num <SEP> pairs <SEP> num <SEP> second <SEP> pairs <SEP> num <SEP> second <SEP> second <SEP> num
the replica <PLACE_HOLDER> have different names ...,if ( ! this . replica sets by name . key set ( ) . equals ( prior state . replica sets by name . key set ( ) ) ) { return true ; },sets have names,success,sub,sets <SEP> equals <SEP> sets
report if multiple devices are matching the <PLACE_HOLDER> .,if ( ! quiet && devices . size ( ) > __num__ ) { print message ( __str__ + devices . size ( ) + __str__ ) ; },devices matching pattern,fail,obj,devices <SEP> num <SEP> str <SEP> devices <SEP> str
this all could probably be done more elegantly via a group extracted from a more comprehensive regexp . clean up any extra <PLACE_HOLDER> around the remainder of the line @$ which should be a view name .,return statement . substring ( matcher . end ( ) ) . trim ( ) ;,elegantly clean spaces,success,obj,substring <SEP> matcher
different properties means different <PLACE_HOLDER>,assert false ( objects . equals ( empty @$ finger ) ) ; assert false ( objects . equals ( empty @$ finger brand ) ) ; assert false ( objects . equals ( finger @$ finger brand ) ) ;,properties means results,success,obj,objects <SEP> equals <SEP> objects <SEP> equals <SEP> objects <SEP> equals
check <PLACE_HOLDER> reads eof,assert equals ( - __num__ @$ is . read ( ) ) ; assert true ( end point . is output shutdown ( ) ) ;,client reads eof,success,sub,equals <SEP> num
res <PLACE_HOLDER> the first found abstract method,method res = null ; for ( method mi : methods ) { if ( ! modifier . is abstract ( mi . get modifiers ( ) ) ) continue ; if ( mi . get annotation ( traits . implemented . class ) != null ) continue ; try { object . class . get method ( mi . get name ( ) @$ mi . get parameter types ( ) ) ; continue ; } catch ( no such method exception e ) { } if ( res != null ) return null ; res = mi ; },returns found method,fail,sub,res <SEP> methods <SEP> modifiers <SEP> traits <SEP> implemented <SEP> types <SEP> res <SEP> res
note to translators : this message is reported if the stylesheet being processed attempted to construct an xml document with an attribute in a place other than on an element . the substitution <PLACE_HOLDER> specifies the name of the attribute .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,text specifies name,success,sub,compilerwarningkey <SEP> str <SEP> runtimeerrorkey <SEP> str <SEP> invalidqnameerr <SEP> str <SEP> invalidncnameerr <SEP> str <SEP> invalidmethodinoutput <SEP> str <SEP> jaxpgetfeaturenullname <SEP> str <SEP> jaxpsetfeaturenullname <SEP> str <SEP> jaxpunsupportedfeature <SEP> str <SEP> jaxpsecureprocessingfeature <SEP> str <SEP> outlineerrtrycatch <SEP> str <SEP> outlineerrunbalancedmarkers <SEP> str <SEP> outlineerrdeletedtarget <SEP> str <SEP> outlineerrmethodtoobig <SEP> str <SEP> deserializetransleterr <SEP> str
spellcheck <PLACE_HOLDER> contains valencian and general accentuation,assert equals ( __num__ @$ rule . match ( lang tool . get analyzed sentence ( __str__ ) ) . length ) ;,sentence contains valencian,fail,sub,equals <SEP> num <SEP> lang <SEP> analyzed <SEP> str
delete interpret odex for android o @$ directory change . fortunately @$ we do n't need to support android o interpret <PLACE_HOLDER> any more,log . i ( tag @$ __str__ ) ; share patch file util . delete dir ( patch version directory + __str__ + share constants . interpret_dex_optimize_path ) ;,o interpret sudo,fail,obj,str <SEP> util <SEP> dir <SEP> str <SEP> constants <SEP> interpretdexoptimizepath
if the flushed requests has <PLACE_HOLDER> @$ we should propagate it also and fail the checkpoint,check and propagate async error ( ) ;,requests has errors,success,obj,async
if no entry keep skipping rows until we come to the end @$ or find <PLACE_HOLDER> that is populated,while ( this . entry == null && this . row < this . length ) { this . entry = this . table [ this . row ] ; this . row ++ ; } return this . entry ;,entry keep one,success,obj,row <SEP> row <SEP> row
simple <PLACE_HOLDER> can cause troubles here because of how <PLACE_HOLDER> works e.g . between lists and sets .,return collection utils . is equal collection ( state objects @$ that . state objects ) ;,collections works e.g,fail,sub,utils <SEP> objects <SEP> objects
start <PLACE_HOLDER> create <PLACE_HOLDER>,event = ( activiti entity event ) listener . get events received ( ) . get ( __num__ ) ; assert equals ( activiti event type . entity_created @$ event . get type ( ) ) ; assert equals ( process instance . get id ( ) @$ event . get process instance id ( ) ) ; assert not equals ( process instance . get id ( ) @$ event . get execution id ( ) ) ; assert equals ( process instance . get process definition id ( ) @$ event . get process definition id ( ) ) ;,event create event,success,sub,activiti <SEP> events <SEP> num <SEP> equals <SEP> activiti <SEP> entitycreated <SEP> equals <SEP> process <SEP> process <SEP> equals <SEP> process <SEP> equals <SEP> process <SEP> process <SEP> process
the second <PLACE_HOLDER> should only get the newest value and any later values .,live data . observe ( m lifecycle owner @$ new observer < string > ( ) { @ override public void on changed ( @ nullable string s ) { output2 . add ( s ) ; } } ) ; live data . remove observer ( m observer ) ; processor . on next ( __str__ ) ; assert that ( m live data output @$ is ( arrays . as list ( __str__ @$ __str__ ) ) ) ; assert that ( output2 @$ is ( arrays . as list ( __str__ @$ __str__ ) ) ) ;,observer get value,success,sub,live <SEP> lifecycle <SEP> nullable <SEP> output2 <SEP> live <SEP> str <SEP> live <SEP> arrays <SEP> str <SEP> str <SEP> output2 <SEP> arrays <SEP> str <SEP> str
append the work <PLACE_HOLDER> file path to the job input file,throw closer . rethrow ( t ) ;,input file path,fail,sub,closer <SEP> rethrow
<PLACE_HOLDER> to translators : xsltc could not find the stylesheet document with the name specified by the substitution text .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,note find document,success,sub,compilerwarningkey <SEP> str <SEP> runtimeerrorkey <SEP> str <SEP> invalidqnameerr <SEP> str <SEP> invalidncnameerr <SEP> str <SEP> invalidmethodinoutput <SEP> str <SEP> jaxpgetfeaturenullname <SEP> str <SEP> jaxpsetfeaturenullname <SEP> str <SEP> jaxpunsupportedfeature <SEP> str <SEP> jaxpsecureprocessingfeature <SEP> str <SEP> outlineerrtrycatch <SEP> str <SEP> outlineerrunbalancedmarkers <SEP> str <SEP> outlineerrdeletedtarget <SEP> str <SEP> outlineerrmethodtoobig <SEP> str <SEP> deserializetransleterr <SEP> str
this property access would be an unknown property error unless the polymer <PLACE_HOLDER> had successfully parsed the element definition .,compiler compiler = compile ( options @$ new string [ ] { lines ( __str__ ) @$ lines ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) } ) ;,pass parsed definition,success,sub,options <SEP> lines <SEP> str <SEP> lines <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
no previous id @$ always accept this <PLACE_HOLDER>,if ( requested session id == null ) { requested session id = id ; session = s ; } else if ( requested session id . equals ( id ) ) { } else if ( session == null || ! is valid ( session ) ) { requested session id = id ; session = s ; } else { if ( s != null && is valid ( s ) ) throw new bad message exception ( __str__ + requested session id + __str__ + id ) ; },id accept one,success,obj,requested <SEP> requested <SEP> requested <SEP> equals <SEP> requested <SEP> str <SEP> requested <SEP> str
manually specified value takes <PLACE_HOLDER> over settings .,set enabled ( system properties . get boolean ( debug_sys_looper_stats_enabled @$ parser . get boolean ( settings_enabled_key @$ default_enabled ) ) ) ;,value takes precedence,success,obj,properties <SEP> debugsyslooperstatsenabled <SEP> parser <SEP> settingsenabledkey <SEP> defaultenabled
get the app log aggregation impl <PLACE_HOLDER> to crash,local dirs handler service mocked dir svc = mock ( local dirs handler service . class ) ; log aggregation service log aggregation service = new log aggregation service ( dispatcher @$ this . context @$ del srvc @$ mocked dir svc ) ; log aggregation service . init ( this . conf ) ; log aggregation service . start ( ) ; application id application1 = builder utils . new application id ( __num__ @$ __num__ ) ; log aggregation service . handle ( new log handler app started event ( application1 @$ this . user @$ null @$ this . acls ) ) ; log aggregation service . handle ( new log handler app finished event ( application1 ) ) ; dispatcher . await ( ),app log thread,success,obj,dirs <SEP> mocked <SEP> dir <SEP> svc <SEP> dirs <SEP> del <SEP> srvc <SEP> mocked <SEP> dir <SEP> svc <SEP> init <SEP> conf <SEP> application1 <SEP> utils <SEP> num <SEP> num <SEP> started <SEP> application1 <SEP> acls <SEP> application1
can happen if this <PLACE_HOLDER> does not carry forward the previous bucketing columns for e.g . another join <PLACE_HOLDER> which does not carry one of the sides ' key columns,list bucket cols . size ( ) <= col count ) { return false ; } expr node desc expr node desc = col expr map . get ( col name ) ; if ( expr node desc instanceof expr node column desc ) { if ( ( ( expr node column desc ) expr node desc ) . get column ( ) . equals ( list bucket cols . get ( col count ) ) ) { col count ++ ; } else { break ; } } if ( col count == parent col names . get ( __num__ ) . size ( ) ) { return ! strict || ( col count == list bucket cols . size ( ) ) ; } } },operator carry columns,success,sub,cols <SEP> expr <SEP> desc <SEP> expr <SEP> desc <SEP> expr <SEP> expr <SEP> desc <SEP> instanceof <SEP> expr <SEP> desc <SEP> expr <SEP> desc <SEP> expr <SEP> desc <SEP> equals <SEP> cols <SEP> names <SEP> num <SEP> cols
client sent an ack lds <PLACE_HOLDER> .,verify ( request observer ) . on next ( eq ( build discovery request ( node @$ __str__ @$ __str__ @$ xds client impl . ads_type_url_lds @$ __str__ ) ) ) ;,client sent request,success,obj,eq <SEP> str <SEP> str <SEP> xds <SEP> impl <SEP> adstypeurllds <SEP> str
unlike pql @$ <PLACE_HOLDER> expects the group columns in select statements .,string group by columns = string utils . join ( _group columns @$ __str__ ) ;,csv expects columns,fail,sub,columns <SEP> utils <SEP> columns <SEP> str
rotate the queue so that each <PLACE_HOLDER> gets the descriptions in a different order,for ( filter filter : filters ) { mutating descriptions . add last ( mutating descriptions . poll first ( ) ) ; for ( description description : descriptions ) { if ( filter . should run ( description ) ) { add description for filter to map ( descriptions run @$ filter @$ description ) ; } } },aggregator gets descriptions,fail,sub,filters <SEP> mutating <SEP> descriptions <SEP> last <SEP> mutating <SEP> descriptions <SEP> descriptions <SEP> descriptions
this estimate will not take into account the <PLACE_HOLDER> saved by inlining the keys .,return versioned stats disklru region entry off heap object key . class ;,estimate take memory,success,obj,versioned <SEP> disklru
generate dates for selecting audits by date @$ making sure the <PLACE_HOLDER> will not contain the sample audit,string from date = sample_timestamp . minus days ( __num__ ) . format ( formatter ) ; string to date = sample_timestamp . minus days ( __num__ ) . format ( formatter ) ;,period contain audit,success,sub,sampletimestamp <SEP> days <SEP> num <SEP> formatter <SEP> sampletimestamp <SEP> days <SEP> num <SEP> formatter
if both <PLACE_HOLDER> finished already @$ assert that both <PLACE_HOLDER> throw exception,assert that ( ai1 . get exception ( ) instanceof unsupported operation exception ) . is true ( ) ; assert that ( ai2 . get exception ( ) instanceof unsupported operation exception ) . is true ( ) ;,operations throw exception,fail,sub,ai1 <SEP> instanceof <SEP> ai2 <SEP> instanceof
build a socks 5 stream host info containing the <PLACE_HOLDER> and the port of the proxy,bytestream stream host info = socks5 packet utils . create bytestream response ( proxyjid @$ initiatorjid ) ; stream host info . add stream host ( proxyjid @$ proxy address @$ __num__ ) ;,info containing address,success,obj,bytestream <SEP> socks5 <SEP> utils <SEP> bytestream <SEP> proxyjid <SEP> initiatorjid <SEP> proxyjid <SEP> num
queue @$ and then roll the original wal @$ <PLACE_HOLDER> enqueues a new wal behind our empty wal . we must roll the wal here as now we use the wal to determine if the file being replicated currently is still opened for write @$ so just inject a new wal to the replication queue does not mean the previous file is closed .,cluster ( ) . get region server ( i ) ; replication replication service = ( replication ) hrs . get replication source service ( ) ; replication service . get replication manager ( ) . pre log roll ( empty wal paths . get ( i ) ) ; replication service . get replication manager ( ) . post log roll ( empty wal paths . get ( i ) ) ; region info region info = util1 . geth base cluster ( ) . get regions ( htable1 . get name ( ) ) . get ( __num__ ) . get region info ( ) ; wal wal = hrs . getwal ( region info ) ; wal . roll writer ( true ) ; },which enqueues wal,success,sub,hrs <SEP> wal <SEP> paths <SEP> wal <SEP> paths <SEP> util1 <SEP> geth <SEP> regions <SEP> htable1 <SEP> num <SEP> wal <SEP> wal <SEP> hrs <SEP> getwal <SEP> wal
get data will activate deferred <PLACE_HOLDER> if necessary,byte [ ] the header = get data ( ic sig head ) ; int to big endian ( rendering intent @$ the header @$ ic hdr rendering intent ) ;,data activate profiles,success,obj,sig <SEP> int <SEP> endian <SEP> hdr
subsequent same key presses move the keyboard <PLACE_HOLDER> to the next object that starts with the same letter .,if ( ( prefix . length ( ) == __num__ ) && ( c == prefix . char at ( __num__ ) ) ) { starting row ++ ; } else { prefix = typed string ; },presses move focus,success,obj,num <SEP> num <SEP> starting <SEP> row <SEP> typed
if an instance of media tray @$ fall thru returning all media printable <PLACE_HOLDER>,if ( ! ( media name instanceof media size name ) ) { media name = null ; },instance printable attributes,fail,obj,instanceof
since the <PLACE_HOLDER> used the immediate scheduler @$ it is unaffected by the main looper being paused .,assert equals ( __num__ @$ x . get ( ) ) ; observable . just ( __num__ ) . compose ( observe forui ( ) ) . subscribe ( x :: set ) ;,test used scheduler,fail,sub,equals <SEP> num <SEP> num <SEP> forui
case . it consists of two arrays of lines . the first array of lines is the test input @$ and the second one is the expected output . if the second array has a single <PLACE_HOLDER> starting with ! ! then it is expected that import orderer will throw a formatter exception with that message . if a line ends with \ then,string [ ] [ ] [ ] inputs outputs = { { { } @$ { } } @$ { { __str__ @$ __str__ } @$ { __str__ @$ __str__ } } @$ { { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } @$ { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } } @$ { { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } @$ { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } } @$ { { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } @$ { __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ } } @$ { { __str__ @$ __str__ @$ __str__ @$ __str__,array has element,success,obj,inputs <SEP> outputs <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
catch exceptions since set <PLACE_HOLDER> can cause a security exception to be thrown under netscape in the applet mode,set daemon ( true ) ;,flushing cause exception,fail,sub,None
if this <PLACE_HOLDER> created mid key @$ block until the other <PLACE_HOLDER> adds a dep on it .,if ( order == order . before && thread . current thread ( ) . equals ( first thread . get ( ) ) ) { tracking awaiter . instance . await latch and track exceptions ( other thread winning @$ __str__ ) ; } else if ( order == order . after && ! thread . current thread ( ) . equals ( first thread . get ( ) ) ) { other thread winning . count down ( ) ; },thread adds dep,success,sub,equals <SEP> tracking <SEP> awaiter <SEP> exceptions <SEP> str <SEP> equals
make sure that the scanner does n't throw an <PLACE_HOLDER> after the connection cache timeout,for ( int i = __num__ ; i < num trials ; i ++ ) { list < t result > results = handler . get scanner rows ( scan id @$ __num__ ) ; assert array equals ( bytes . to bytes ( __str__ + i ) @$ results . get ( __num__ ) . get row ( ) ) ; thread . sleep ( trial pause ) ; },scanner throw exception,success,obj,int <SEP> num <SEP> num <SEP> trials <SEP> results <SEP> rows <SEP> num <SEP> equals <SEP> bytes <SEP> bytes <SEP> str <SEP> results <SEP> num <SEP> row
<PLACE_HOLDER> might add scm id to indicate which scm should be used to find credential we have to do this because api url might be of wire mock server and not github,. github_url ) || ( string utils . is not blank ( scm id ) && scm id . equals ( github scm . id ) ) ) { scm = new github scm ( new reachable ( ) { @ override public link get link ( ) { preconditions . check not null ( organization ) ; return organization . get link ( ) . rel ( __str__ ) ; } } ) ; } else { scm = new github enterprise scm ( ( new reachable ( ) { @ override public link get link ( ) { preconditions . check not null ( organization ) ; return organization . get link ( ) . rel ( __str__ ) ; } } ) ) ; },tests add id,success,sub,githuburl <SEP> utils <SEP> scm <SEP> scm <SEP> equals <SEP> github <SEP> scm <SEP> scm <SEP> github <SEP> scm <SEP> preconditions <SEP> rel <SEP> str <SEP> scm <SEP> github <SEP> scm <SEP> preconditions <SEP> rel <SEP> str
preserve the same order that <PLACE_HOLDER> org api returns,map < string @$ scm organization > org map = new linked hash map < > ( ) ;,test org returns,fail,sub,scm <SEP> org <SEP> linked
poor man 's dependency <PLACE_HOLDER> through the jersey application scope .,m block master = ( ( alluxio master process ) context . get attribute ( master web server . alluxio_master_servlet_resource_key ) ) . get master ( block master . class ) ;,man dependency injection,success,obj,alluxio <SEP> process <SEP> alluxiomasterservletresourcekey
start the modify procedure & & kill the <PLACE_HOLDER>,long proc id = proc exec . submit procedure ( new modify table procedure ( proc exec . get environment ( ) @$ new td ) ) ; int last step = __num__ ;,procedure kill executor,success,obj,proc <SEP> proc <SEP> proc <SEP> int <SEP> last <SEP> num
load anyway since <PLACE_HOLDER> should not throw exceptions,logger . error ( __str__ @$ e ) ;,listeners throw exceptions,success,sub,str
first do a sanity check and see if this address has any <PLACE_HOLDER> .,if ( ! has conflict ( addr ) ) { return ; } monitor . set message ( __str__ ) ; boolean ask user = chosen conflict option == ask_user ;,address has conflicts,success,obj,addr <SEP> str <SEP> askuser
wait to ensure <PLACE_HOLDER> has fully created its test directories,thread . sleep ( __num__ ) ;,nn created directories,success,sub,num
test that the <PLACE_HOLDER> correctly created the entries in the region,assert not null ( my region . get ( not affected key ) ) ; assert null ( my region . get ( key1 ) ) ; assert true ( my region . contains key ( key1 ) ) ; assert null ( my region . get ( key2 ) ) ; assert true ( my region . contains key ( key2 ) ) ;,commit created entries,success,sub,key1 <SEP> contains <SEP> key1 <SEP> key2 <SEP> contains <SEP> key2
if mode is add <PLACE_HOLDER> check if the repository name does not exist in the repository list <PLACE_HOLDER> close this dialog if mode is edit <PLACE_HOLDER> check if the repository name is the same as before if not check if the new name does not exist in the repository . otherwise return true to this method @$ which will mean that repository already exist,if ( input . get description ( ) != null && input . get description ( ) . length ( ) > __num__ ) { if ( mode == mode . add ) { if ( master repositories meta . search repository ( input . get name ( ) ) == null ) { dispose ( ) ; } else { display repository already exist message ( input . get name ( ) ) ; } } else { if ( master repository name . equals ( input . get name ( ) ) ) { dispose ( ) ; } else if ( master repositories meta . search repository ( input . get name ( ) ) == null ) { dispose ( ) ; } else,name exist then,success,obj,num <SEP> repositories <SEP> equals <SEP> repositories
string <PLACE_HOLDER> does not throw io exception,print to ( ( appendable ) buf @$ instant ) ;,builder throw exception,fail,sub,appendable <SEP> buf
namespaces can present some <PLACE_HOLDER> @$ so just punt if we 're looking for these .,if ( is set ( analysis @$ bit_namespace ) ) return false ;,namespaces present problems,success,obj,bitnamespace
let the emulator view handle <PLACE_HOLDER> if mouse tracking is active,if ( view . is mouse tracking active ( ) ) return false ;,view handle things,fail,obj,tracking
events should share <PLACE_HOLDER>,assert same ( event @$ events . pop ( ) ) ;,events share instances,success,obj,events
now the tricky one . 'before <PLACE_HOLDER> ' le<PLACE_HOLDER>ds to 'c<PLACE_HOLDER>ll <PLACE_HOLDER>ctivity <PLACE_HOLDER> ' @$ which c<PLACE_HOLDER>lls subprocess 02 which termin<PLACE_HOLDER>tes,process instance by key ( __str__ ) ; tasks = assert task names ( process instance @$ arrays . as list ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ; task service . complete ( tasks . get ( __num__ ) . get id ( ) ) ; task task = task service . create task query ( ) . task name ( __str__ ) . single result ( ) ; assert not null ( task ) ; task service . complete ( task . get id ( ) ) ; assert process ended ( process instance . get id ( ) ) ; assert historic process instance details ( process instance ) ;,a leads a,success,sub,process <SEP> str <SEP> tasks <SEP> names <SEP> process <SEP> arrays <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> tasks <SEP> num <SEP> str <SEP> process <SEP> ended <SEP> process <SEP> process <SEP> details <SEP> process
repl load during migration @$ commits the explicit <PLACE_HOLDER> and start some internal <PLACE_HOLDER>s . call release locks and commit or rollback to do the clean up .,if ( ! driver context . get txn manager ( ) . is txn open ( ) && driver context . get query state ( ) . get hive operation ( ) == hive operation . replload ) { release locks and commit or rollback ( false ) ; } else { },load commits txn,success,obj,txn <SEP> txn <SEP> replload <SEP> locks
then delegate to the database metadata driver identifier casing selection which can override these <PLACE_HOLDER> .,return super . build identifier helper ( builder @$ db meta data ) ;,which override settings,success,obj,db
this newly opened jar <PLACE_HOLDER> has its own index @$ merge it into the parent 's index @$ taking into account the relative path .,jar index new index = new loader . get index ( ) ; if ( new index != null ) { int pos = jar name . last index of ( __str__ ) ; new index . merge ( this . index @$ ( pos == - __num__ ? null : jar name . substring ( __num__ @$ pos + __num__ ) ) ) ; },name has index,fail,sub,loader <SEP> int <SEP> pos <SEP> last <SEP> str <SEP> pos <SEP> num <SEP> substring <SEP> num <SEP> pos <SEP> num
if list <PLACE_HOLDER> exceeds pref <PLACE_HOLDER> @$ close connection,if ( closed || ( pref size > __num__ && conns . size ( ) > pref size ) ) { d ( __str__ @$ conn ) ; td ( __str__ @$ conn ) ; conns . remove ( entry ) ; conn . close connection ( ) ; } else { d ( __str__ @$ conn ) ; td ( __str__ @$ conn ) ; entry = conns . get ( loc ) ; entry . release ( ) ; },size exceeds size,success,obj,pref <SEP> num <SEP> conns <SEP> pref <SEP> str <SEP> conn <SEP> str <SEP> conn <SEP> conns <SEP> conn <SEP> close <SEP> str <SEP> conn <SEP> str <SEP> conn <SEP> conns <SEP> loc
actual <PLACE_HOLDER> @$ just skip the event .,if ( last event . event equals ( cur event ) ) { if ( debug ) slog . d ( tag @$ __str__ + last nanos ) ; } else { assign log id ( cur event ) ; m pending logs . add ( cur event ) ; if ( debug ) slog . d ( tag @$ __str__ + last nanos ) ; },logic skip event,fail,sub,last <SEP> equals <SEP> str <SEP> last <SEP> nanos <SEP> logs <SEP> str <SEP> last <SEP> nanos
logger <PLACE_HOLDER> should not influnce serialization,assert true ( __str__ + sizea + __str__ + sizeb @$ ( sizea - sizeb ) < __num__ ) ;,handler influnce serialization,fail,sub,str <SEP> sizea <SEP> str <SEP> sizeb <SEP> sizea <SEP> sizeb <SEP> num
a serializable function can only return an object type @$ so if the do <PLACE_HOLDER> parameter is a primitive type @$ then box it for the return . the return type will be unboxed before being forwarded to the do <PLACE_HOLDER> parameter .,if ( output type . get raw type ( ) . is primitive ( ) ) { output type = type descriptor . of ( primitives . wrap ( output type . get raw type ( ) ) ) ; },the do output,fail,obj,primitives
in case when remote tx has updated the current <PLACE_HOLDER> before .,ignore ( ) ;,tx updated transaction,fail,obj,None
first assume there are no named capture backreferences @$ because the spec says they should only be recognized if the <PLACE_HOLDER> contains at least one named capture group .,max = comma >= __num__ ? comma + __num__ != counts . length ( ) ? integer . parse int ( counts . substring ( comma + __num__ ) ) : integer . max_value : min ; } catch ( number format exception ex ) { min = max = - __num__ ; } if ( min < __num__ || min > max ) { pos = start - __num__ ; return body ; } break ; default : return body ; } boolean greedy = true ; if ( pos < limit && pattern . char at ( pos ) == __str__ ) { greedy = false ; ++ pos ; } return new repetition ( body @$ min @$ max @$ greedy ) ; } },body contains one,fail,sub,num <SEP> num <SEP> counts <SEP> int <SEP> counts <SEP> substring <SEP> num <SEP> maxvalue <SEP> num <SEP> num <SEP> pos <SEP> num <SEP> pos <SEP> pos <SEP> str <SEP> pos
view <PLACE_HOLDER> does not give its child views any callbacks when it moves content onto the screen @$ so we need to attach a listener to give us the information that we require .,pager view pager = ( view pager ) view parent ; final incremental mount helper . view pager listener view pager listener = new view pager listener ( m component tree @$ view pager ) ; try { view pager . add on page change listener ( view pager listener ) ; } catch ( concurrent modification exception e ) { view compat . post on animation ( view pager @$ new runnable ( ) { @ override public void run ( ) { view pager . add on page change listener ( view pager listener ) ; } } ) ; } m view pager listeners . add ( view pager listener ) ; } view parent = view parent . get parent ( ) ; },pager give information,success,sub,compat <SEP> runnable <SEP> listeners
camera device should call configure <PLACE_HOLDER> and have it finish before constructing us,if ( configure success ) { m state callback . on configured ( this ) ; if ( debug ) log . v ( tag @$ m id string + __str__ ) ; m configure success = true ; } else { m state callback . on configure failed ( this ) ; m closed = true ; log . e ( tag @$ m id string + __str__ ) ; m configure success = false ; },device call success,fail,obj,configured <SEP> str <SEP> str
test that it emits when time passed the time <PLACE_HOLDER>,consumer . accept ( value in global window ( new byte [ __num__ ] ) ) ;,time passed limit,success,obj,num
<PLACE_HOLDER> has no data after flush,is empty ( ) ? __num__ : __num__ ; boolean more ; int cell count = __num__ ; do { list < cell > cells = new array list < > ( ) ; more = s . next ( cells ) ; cell count += cells . size ( ) ; assert equals ( more ? number of mem scanners after flush : __num__ @$ count mem store scanner ( s ) ) ; } while ( more ) ; assert equals ( __str__ + input cells before snapshot . size ( ) + __str__ + input cells after snapshot . size ( ) @$ input cells before snapshot . size ( ) + input cells after snapshot . size ( ) @$ cell count ) ;,structure has data,fail,sub,num <SEP> num <SEP> int <SEP> num <SEP> cells <SEP> cells <SEP> cells <SEP> equals <SEP> mem <SEP> scanners <SEP> num <SEP> mem <SEP> equals <SEP> str <SEP> cells <SEP> str <SEP> cells <SEP> cells <SEP> cells
does this operator make any <PLACE_HOLDER> ?,assert equals ( __str__ @$ pretty ( __str__ ) ) ;,operator make sense,success,obj,equals <SEP> str <SEP> str
this version gives a <PLACE_HOLDER> that rest li runs,request < string > req = builders . < string > action ( __str__ ) . build ( ) ; get client ( ) . send request ( req ) . get response ( ) ;,version gives task,success,obj,req <SEP> builders <SEP> str <SEP> req
entry does not have attributes <PLACE_HOLDER> : ca certs can have no attributes open ssl generates pkcs 12 with no attr for ca certs .,attr set = null ;,entry attributes note,success,obj,attr
test no <PLACE_HOLDER> to send coin . query <PLACE_HOLDER> before send coin .,long deplay account before balance = public methed . query account ( delay account3 address @$ blocking stub full ) . get balance ( ) ; long recevier account before balance = public methed . query account ( receiver account4 address @$ blocking stub full ) . get balance ( ) ; logger . info ( __str__ + deplay account before balance ) ; logger . info ( __str__ + recevier account before balance ) ; assert . assert false ( public methed . sendcoin delayed ( receiver account4 address @$ send coin amount @$ delay second @$ delay account3 address @$ delay account3 key @$ blocking stub full ) ) ; public methed . wait produce next block ( blocking stub full ) ;,balance send coin,success,sub,deplay <SEP> methed <SEP> account3 <SEP> blocking <SEP> recevier <SEP> methed <SEP> account4 <SEP> blocking <SEP> str <SEP> deplay <SEP> logger <SEP> str <SEP> recevier <SEP> methed <SEP> sendcoin <SEP> delayed <SEP> account4 <SEP> second <SEP> account3 <SEP> account3 <SEP> blocking <SEP> methed <SEP> blocking
apps can set the interception <PLACE_HOLDER> other than the direct parent .,final view group parent ; if ( m touch interception view group == null ) { parent = ( view group ) get parent ( ) ; } else { parent = m touch interception view group ; },apps set target,success,obj,None
we 'll skip words which are punctuation . retrieve <PLACE_HOLDER> indicating punctuation in this treebank .,} result . put ( __str__ @$ correct heads * __num__ / sum arcs ) ; result . put ( __str__ @$ correct heads no punc * __num__ / sum arcs no punc ) ; result . put ( __str__ @$ correct arcs * __num__ / sum arcs ) ; result . put ( __str__ @$ correct arcs no punc * __num__ / sum arcs no punc ) ; result . put ( __str__ @$ correct trees * __num__ / trees . size ( ) ) ; result . put ( __str__ @$ correct trees no punc * __num__ / trees . size ( ) ) ; result . put ( __str__ @$ correct root * __num__ / trees . size ( ) ) ; return result ;,string indicating punctuation,fail,sub,str <SEP> heads <SEP> num <SEP> arcs <SEP> str <SEP> heads <SEP> punc <SEP> num <SEP> arcs <SEP> punc <SEP> str <SEP> arcs <SEP> num <SEP> arcs <SEP> str <SEP> arcs <SEP> punc <SEP> num <SEP> arcs <SEP> punc <SEP> str <SEP> trees <SEP> num <SEP> trees <SEP> str <SEP> trees <SEP> punc <SEP> num <SEP> trees <SEP> str <SEP> num <SEP> trees
junit do n't provide any <PLACE_HOLDER> to order tests,pre auth ( ) ; missing auth ( ) ; valid auth ( ) ; valid auth2 ( ) ;,junit provide credentials,fail,obj,auth <SEP> auth <SEP> auth <SEP> auth2
fastpath : do not construct a new <PLACE_HOLDER> if the src is a <PLACE_HOLDER> and is already normalized .,if ( src instanceof string ) { int span length = span quick check yes ( src ) ; if ( span length == src . length ( ) ) { return ( string ) src ; } string builder sb = new string builder ( src . length ( ) ) . append ( src @$ __num__ @$ span length ) ; return normalize second and append ( sb @$ src . sub sequence ( span length @$ src . length ( ) ) ) . to string ( ) ; },fastpath construct string,success,obj,src <SEP> instanceof <SEP> int <SEP> src <SEP> src <SEP> src <SEP> sb <SEP> src <SEP> src <SEP> num <SEP> second <SEP> sb <SEP> src <SEP> src <SEP> 
be sure to let our parent perform any <PLACE_HOLDER> needed,j label renderer = ( j label ) super . get table cell renderer component ( data ) ; object value = data . get value ( ) ; j table table = data . get table ( ) ; boolean is selected = data . is selected ( ) ; set text ( __str__ ) ; set horizontal alignment ( center ) ; vt match match = ( vt match ) value ; vt association association = match . get association ( ) ; vt association status association status = association . get status ( ) ; if ( ! is selected ) { renderer . set background ( match table renderer . get background color ( association @$ table @$ renderer . get background ( ),parent perform initialization,success,obj,renderer <SEP> renderer <SEP> selected <SEP> selected <SEP> str <SEP> selected <SEP> renderer <SEP> renderer <SEP> renderer
end <PLACE_HOLDER> @$ as we did n't manage to find a valid seek position .,null && playing period holder . prepared && new period position us != __num__ ) { new period position us = playing period holder . media period . get adjusted seek position us ( new period position us @$ seek parameters ) ; } if ( c . us to ms ( new period position us ) == c . us to ms ( playback info . position us ) ) { period position us = playback info . position us ; return ; } } new period position us = seek to period position ( period id @$ new period position us ) ; seek position adjusted |= period position us != new period position us ; period position us = new period position us ; },playback seek position,success,sub,num <SEP> adjusted <SEP> parameters <SEP> id <SEP> adjusted
first @$ get the database . this is the database which contains the <PLACE_HOLDER> @$ with contains the processed definitions from the ddl file .,database db = get database ( ) ;,which contains catalog,success,obj,db <SEP> get
send message to all peers to find out who hosts the <PLACE_HOLDER>,if ( ! tx . is real deal local ( ) ) { find remotetx message reply processor processor = send find remotetx message ( server connection . get cache ( ) @$ tx id ) ; try { processor . wait for replies uninterruptibly ( ) ; } catch ( reply exception e ) { e . handle cause ( ) ; } internal distributed member hosting member = processor . get hosting member ( ) ; if ( hosting member != null ) { if ( logger . is debug enabled ( ) ) { logger . debug ( __str__ @$ hosting member ) ; } if ( tx . get target ( ) == null ) { tx . set target ( hosting member ),who hosts transaction,success,obj,tx <SEP> remotetx <SEP> remotetx <SEP> tx <SEP> replies <SEP> uninterruptibly <SEP> distributed <SEP> hosting <SEP> hosting <SEP> hosting <SEP> str <SEP> hosting <SEP> tx <SEP> tx <SEP> hosting
replace values if better <PLACE_HOLDER> log sum @$ if same edit distance or one space difference,probability log sum + top probability log ) ) || ( compositions [ circular index ] . distance sum + separator length + top ed < compositions [ destination index ] . distance sum ) ) { compositions [ destination index ] . segmented string = compositions [ circular index ] . segmented string + __str__ + part ; compositions [ destination index ] . corrected string = compositions [ circular index ] . corrected string + __str__ + top result ; compositions [ destination index ] . distance sum = compositions [ circular index ] . distance sum + top ed ; compositions [ destination index ] . probability log sum = compositions [ circular index ] . probability log sum + top probability log ; },maximized log sum,fail,sub,compositions <SEP> compositions <SEP> compositions <SEP> segmented <SEP> compositions <SEP> segmented <SEP> str <SEP> compositions <SEP> corrected <SEP> compositions <SEP> corrected <SEP> str <SEP> compositions <SEP> compositions <SEP> compositions <SEP> compositions
<PLACE_HOLDER> that set 2 digit year start takes a clone .,date new date = new date ( ) ; sdf . set2 digit year start ( new date ) ; assert not same ( sdf . get2 digit year start ( ) @$ new date ) ; assert equals ( sdf . get2 digit year start ( ) @$ new date ) ; new date . set time ( __num__ ) ; assert false ( sdf . get2 digit year start ( ) . equals ( new date ) ) ;,test takes clone,success,sub,sdf <SEP> set2 <SEP> sdf <SEP> get2 <SEP> equals <SEP> sdf <SEP> get2 <SEP> num <SEP> sdf <SEP> get2 <SEP> equals
t<PLACE_HOLDER>t that submit do<PLACE_HOLDER> n't throw np <PLACE_HOLDER>,executor service . submit ( new test event handler ( mocked server @$ event type . m_server_shutdown @$ lock @$ counter ) ) ;,submit throw c,fail,obj,mocked <SEP> mservershutdown
this must be done to assure the correct vfs file system drivers will process the <PLACE_HOLDER>,string scheme = extract scheme ( full parameter name ) ; try { delegating file system options builder delegatefs options builder = new delegating file system options builder ( kettlevfs . get instance ( ) . get file system manager ( ) ) ; if ( scheme != null ) { delegatefs options builder . set config string ( opts @$ scheme @$ name @$ value ) ; } else { log . log minimal ( __str__ + vfs url ) ; } } catch ( file system exception e ) { if ( ( e . get code ( ) != null ) && ( e . get code ( ) . equals ignore case ( __str__ ) ) ) { log . log minimal ( __str__,drivers process html,fail,obj,delegating <SEP> options <SEP> delegatefs <SEP> options <SEP> delegating <SEP> options <SEP> kettlevfs <SEP> delegatefs <SEP> options <SEP> config <SEP> opts <SEP> str <SEP> vfs <SEP> equals <SEP> str <SEP> str
new root should have only 1 <PLACE_HOLDER>,root . go to ( read cursor ) ; assert equals ( __num__ @$ key count ( ) ) ;,root have key,success,obj,equals <SEP> num
reduce ipc client <PLACE_HOLDER> retry times and interval time,configuration client conf = new configuration ( false ) ; client conf . set int ( common configuration keys . ipc_client_connect_max_retries_key @$ __num__ ) ; client conf . set int ( common configuration keys . ipc_client_connect_retry_interval_key @$ __num__ ) ;,configuration retry times,fail,sub,conf <SEP> conf <SEP> int <SEP> keys <SEP> ipcclientconnectmaxretrieskey <SEP> num <SEP> conf <SEP> int <SEP> keys <SEP> ipcclientconnectretryintervalkey <SEP> num
values of lists must be accumulated as object <PLACE_HOLDER> objects under the value key . will return as a array <PLACE_HOLDER> . called recursively to traverse the entire object graph of each item in the array .,if ( type . equals ( graphson tokens . type_list ) ) { array node list = ( array node ) value ; array node value array = value and type . put array ( graphson tokens . value ) ; for ( int ix = __num__ ; ix < list . size ( ) ; ix ++ ) { add object ( value array @$ get value ( get typed value from json node ( list . get ( ix ) ) @$ include type ) ) ; } } else if ( type . equals ( graphson tokens . type_map ) ) { object node converted map = json node factory . object node ( ) ; object node json object = ( object node ),values return node,success,obj,equals <SEP> graphson <SEP> tokens <SEP> typelist <SEP> graphson <SEP> tokens <SEP> int <SEP> ix <SEP> num <SEP> ix <SEP> ix <SEP> typed <SEP> json <SEP> ix <SEP> equals <SEP> graphson <SEP> tokens <SEP> typemap <SEP> converted <SEP> json <SEP> json
a media <PLACE_HOLDER> may report a discontinuity at the current playback position to ensure the renderers are flushed . only report the discontinuity externally if the position changed .,if ( period position us != playback info . position us ) { playback info = playback info . copy with new position ( playback info . period id @$ period position us @$ playback info . content position us @$ get total buffered duration us ( ) ) ; playback info update . set position discontinuity ( player . discontinuity_reason_internal ) ; } renderer position us = media clock . sync and get position us ( ) ; period position us = playing period holder . to period time ( renderer position us ) ; maybe trigger pending messages ( playback info . position us @$ period position us ) ; playback info . position us = period position us ;,period report discontinuity,success,sub,content <SEP> buffered <SEP> discontinuityreasoninternal <SEP> renderer <SEP> renderer <SEP> messages
any app can add new static shared <PLACE_HOLDER>,if ( scan result . static shared library info != null ) { return collections . singleton list ( scan result . static shared library info ) ; } final boolean has dynamic libraries = ( pkg . application info . flags & application info . flag_system ) != __num__ && scan result . dynamic shared library infos != null ; if ( ! has dynamic libraries ) { return null ; } final boolean is updated system app = pkg . is updated system app ( ) ;,app add libraries,success,obj,shared <SEP> collections <SEP> shared <SEP> libraries <SEP> flags <SEP> flagsystem <SEP> num <SEP> shared <SEP> infos <SEP> libraries <SEP> updated <SEP> updated
if <PLACE_HOLDER> has 1 a<PLACE_HOLDER>d m has 0,if ( is bitn && ! is bitm ) { m = m | ( m << k ) ; } else if ( ! is bitn && is bitm ) { int mask = ~ ( m << k ) ; m = m & mask ; },n has 0,success,sub,bitn <SEP> bitm <SEP> bitn <SEP> bitm <SEP> int
<PLACE_HOLDER> has no namespace,fdom error ) ; if ( ! continue process ) { throw new runtime exception ( dom message formatter . format message ( dom message formatter . serializer_domain @$ __str__ @$ null ) ) ; } } } else { uri = fns binder . geturi ( xml symbols . empty_string ) ; if ( uri != null && uri . length ( ) > __num__ ) { if ( f namespace prefixes ) { print namespace attr ( xml symbols . empty_string @$ xml symbols . empty_string ) ; } f localns binder . declare prefix ( xml symbols . empty_string @$ xml symbols . empty_string ) ; fns binder . declare prefix ( xml symbols . empty_string @$ xml symbols . empty_string ) ; } },element has namespace,success,sub,fdom <SEP> process <SEP> formatter <SEP> formatter <SEP> serializerdomain <SEP> str <SEP> fns <SEP> geturi <SEP> symbols <SEP> emptystring <SEP> num <SEP> namespace <SEP> prefixes <SEP> namespace <SEP> attr <SEP> symbols <SEP> emptystring <SEP> symbols <SEP> emptystring <SEP> localns <SEP> symbols <SEP> emptystring <SEP> symbols <SEP> emptystring <SEP> fns <SEP> symbols <SEP> emptystring <SEP> symbols <SEP> emptystring
returns object <PLACE_HOLDER> from document loader .,return get document loader ( parent identifier ) . query child documents ( projection @$ parent identifier ) ;,returns object reference,fail,obj,loader <SEP> documents
allocation of array may have caused gc @$ <PLACE_HOLDER> may have caused additional entries to go stale . removing these entries from the reference queue will make them eligible for reclamation .,while ( queue . poll ( ) != null ) { },which caused entries,success,sub,None
the monitor we are exiting is not verifiably the one on the top of our monitor stack . this causes a monitor <PLACE_HOLDER> .,if ( ! actual . is lock reference ( ) || ! expected . equal ( actual ) ) { _monitor_top = bad_monitors ; _monitor_safe = false ; basic block bb = get basic block containing ( bci ) ; bb . set changed ( true ) ; bb . _monitor_top = bad_monitors ; if ( trace monitor mismatch ) { report monitor mismatch ( __str__ ) ; } } else { replace allcts matches ( actual @$ cell type state . make line ref ( bci ) ) ; },monitor causes failure,fail,obj,monitortop <SEP> badmonitors <SEP> monitorsafe <SEP> bb <SEP> containing <SEP> bci <SEP> bb <SEP> bb <SEP> monitortop <SEP> badmonitors <SEP> str <SEP> allcts <SEP> matches <SEP> bci
last task to exit when shutdown release <PLACE_HOLDER>,int remaining = thread exit ( this @$ replace me ) ; if ( remaining == __num__ && is shutdown ( ) ) impl close ( ) ;,shutdown release resources,success,obj,int <SEP> num <SEP> impl <SEP> close
3 rd parameter has no <PLACE_HOLDER> for ownerless,test ( false @$ true @$ false ) ;,parameter has affect,success,obj,None
notify the listeners . do that from the end of the list so that if a listener removes <PLACE_HOLDER> as the result of being called @$ it wo n't mess up with our iteration,if ( m listeners != null ) { int listener count = m listeners . size ( ) ; for ( int i = listener count - __num__ ; i >= __num__ ; i -- ) { m listeners . get ( i ) . on drawer closed ( drawer view ) ; } },listener removes itself,success,obj,listeners <SEP> int <SEP> listeners <SEP> int <SEP> num <SEP> num <SEP> listeners
to change body of generated methods @$ choose <PLACE_HOLDER> | templates .,return super . load symlinks ( ) ;,tools | templates,success,sub,symlinks
end probe phase @$ iterator build side <PLACE_HOLDER> .,collector . collect ( build iter . get row ( ) ) ; while ( build iter . advance next ( ) ) { collector . collect ( build iter . get row ( ) ) ; },iterator build effects,fail,obj,iter <SEP> row <SEP> iter <SEP> iter <SEP> row
<PLACE_HOLDER> sending @$ will return a send result,try { producer . send ( prepare message ( input ) ) ; collector . ack ( input ) ; } catch ( exception e ) { log . error ( __str__ @$ e ) ; collector . report error ( e ) ; collector . fail ( input ) ; },producer return result,fail,sub,ack <SEP> str
end of the post fork <PLACE_HOLDER> .,trace . trace end ( trace . trace_tag_activity_manager ) ; if ( parsed args . m invoke with != null ) { wrapper init . exec application ( parsed args . m invoke with @$ parsed args . m nice name @$ parsed args . m target sdk version @$ vm runtime . get current instruction set ( ) @$ pipe fd @$ parsed args . m remaining args ) ; throw new illegal state exception ( __str__ ) ; } else { if ( ! is zygote ) { return zygote init . zygote init ( parsed args . m target sdk version @$ parsed args . m remaining args @$ null ) ; } else { return zygote init . child zygote init ( parsed args,end fork event,success,obj,tracetagactivitymanager <SEP> parsed <SEP> args <SEP> init <SEP> parsed <SEP> args <SEP> parsed <SEP> args <SEP> parsed <SEP> args <SEP> sdk <SEP> vm <SEP> fd <SEP> parsed <SEP> args <SEP> args <SEP> str <SEP> init <SEP> init <SEP> parsed <SEP> args <SEP> sdk <SEP> parsed <SEP> args <SEP> args <SEP> init <SEP> init <SEP> parsed <SEP> args
if that is first collection we split single composite key on several keys @$ <PLACE_HOLDER> of those composite keys contain single item from collection,if ( ! contains collection ) for ( int i = __num__ ; i < collection size ; i ++ ) { final o composite key composite key = new o composite key ( first key . get keys ( ) ) ; composite keys . add ( composite key ) ; } else throw new o index exception ( __str__ ) ;,each contain item,success,sub,contains <SEP> int <SEP> num <SEP> keys <SEP> keys <SEP> str
<PLACE_HOLDER> frames may have changed . tell the input dispatcher about it .,m input monitor . layout input consumers ( dw @$ dh ) ; m input monitor . set update input windows needed lw ( ) ; if ( update input windows ) { m input monitor . update input windows lw ( false ) ; },rpc tell dispatcher,fail,sub,consumers <SEP> dh <SEP> windows <SEP> needed <SEP> windows <SEP> windows
if <PLACE_HOLDER> does date parsing for quoted strings @$ we 'd need to verify there 's no type mismatch when string col is filtered by a string that looks like date .,if ( col type == filter type . date && val type == filter type . string ) { try { node value = meta store utils . partition_date_format . get ( ) . parse ( ( string ) node value ) ; val type = filter type . date ; } catch ( parse exception pe ) { } },filter does parsing,fail,sub,utils <SEP> partitiondateformat
check that the jar does not have an <PLACE_HOLDER> for the removed class,try ( jar file abi jar = new jar file ( abi jar path . to file ( ) ) ) { assert that ( abi jar . stream ( ) . map ( jar entry :: get name ) . collect ( collectors . to set ( ) ) @$ matchers . contains in any order ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ; manifest manifest = abi jar . get manifest ( ) ; assert null ( manifest . get attributes ( __str__ ) ) ; },jar have entry,success,obj,abi <SEP> abi <SEP> abi <SEP> collectors <SEP> matchers <SEP> contains <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> abi <SEP> attributes <SEP> str
source and destination images may have different <PLACE_HOLDER> requirements @$ therefore may have different strides . copy row by row for such case .,int src offset = src buffer . position ( ) ; int dst offset = dst buffer . position ( ) ; size effective plane size = get effective plane size for image ( src @$ i ) ; int src byte count = effective plane size . get width ( ) * src planes [ i ] . get pixel stride ( ) ; for ( int row = __num__ ; row < effective plane size . get height ( ) ; row ++ ) { if ( row == effective plane size . get height ( ) - __num__ ) { int remaining bytes = src buffer . remaining ( ) - src offset ; if ( src byte count > remaining bytes ) { src,images have strides,fail,obj,int <SEP> src <SEP> src <SEP> int <SEP> src <SEP> int <SEP> src <SEP> src <SEP> planes <SEP> int <SEP> row <SEP> num <SEP> row <SEP> row <SEP> row <SEP> num <SEP> int <SEP> bytes <SEP> src <SEP> src <SEP> src <SEP> bytes <SEP> src
let <PLACE_HOLDER> 1 proceed and cancel <PLACE_HOLDER> 2,task2 handle queue . add ( handle ) ;,task proceed task,success,sub,task2
expected since only test <PLACE_HOLDER> can call that method,assert . fail ( __str__ ) ;,cases call method,fail,sub,str
this node has been inactive @$ but other node has more recent <PLACE_HOLDER> .,if ( ! is inactive ) { updated latest success transfer = latest reported cluster activity ; },node has information,fail,obj,updated <SEP> reported
flush those recovered buffered <PLACE_HOLDER> out .,produce synchronously to partition zero ( input @$ as list ( new key value timestamp < > ( __str__ @$ __str__ @$ scaled time ( __num__ ) ) @$ new key value timestamp < > ( __str__ @$ __str__ @$ scaled time ( __num__ ) ) @$ new key value timestamp < > ( __str__ @$ __str__ @$ scaled time ( __num__ ) ) ) ) ; verify output ( output raw @$ new hash set < > ( as list ( new key value timestamp < > ( __str__ @$ __num__ @$ scaled time ( __num__ ) ) @$ new key value timestamp < > ( __str__ @$ __num__ @$ scaled time ( __num__ ) ) @$ new key value timestamp < > ( __str__ @$ __num__,those recovered records,fail,obj,synchronously <SEP> str <SEP> str <SEP> scaled <SEP> num <SEP> str <SEP> str <SEP> scaled <SEP> num <SEP> str <SEP> str <SEP> scaled <SEP> num <SEP> str <SEP> num <SEP> scaled <SEP> num <SEP> str <SEP> num <SEP> scaled <SEP> num <SEP> str <SEP> num
to avoid changing the output path of binaries built without a flavor @$ we 'll default to no flavor @$ <PLACE_HOLDER> implicitly builds the default platform .,return immutable sorted set . of ( ) ;,which builds platform,success,sub,None
serialize and deserialize unconfigured build <PLACE_HOLDER> as string,simple module build target module = new simple module ( __str__ ) ; build target module . add serializer ( unconfigured build target . class @$ new to string serializer ( ) ) ; build target module . add deserializer ( unconfigured build target . class @$ new from string deserializer < unconfigured build target > ( unconfigured build target . class ) { @ override protected unconfigured build target _deserialize ( string value @$ deserialization context ctxt ) { return unconfigured build target parser . parse ( value @$ intern ) ; } } ) ; mapper . register module ( build target module ) ; mapper . register module ( forward relative path module ( ) ) ; return mapper ;,unconfigured build targets,fail,obj,str <SEP> serializer <SEP> unconfigured <SEP> serializer <SEP> deserializer <SEP> unconfigured <SEP> deserializer <SEP> unconfigured <SEP> unconfigured <SEP> protected <SEP> unconfigured <SEP> deserialize <SEP> deserialization <SEP> ctxt <SEP> unconfigured <SEP> parser <SEP> mapper <SEP> mapper <SEP> mapper
poi produced the infinity <PLACE_HOLDER> when it should have produced the degrees <PLACE_HOLDER> .,return __num__ ; case __num__ :,poi produced sign,success,obj,num <SEP> num
note to translators : the <PLACE_HOLDER> contained an element that was not recognized as part of the xsl syntax . the substitution text gives the element name .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,stylesheet contained element,success,sub,compilerwarningkey <SEP> str <SEP> runtimeerrorkey <SEP> str <SEP> invalidqnameerr <SEP> str <SEP> invalidncnameerr <SEP> str <SEP> invalidmethodinoutput <SEP> str <SEP> jaxpgetfeaturenullname <SEP> str <SEP> jaxpsetfeaturenullname <SEP> str <SEP> jaxpunsupportedfeature <SEP> str <SEP> jaxpsecureprocessingfeature <SEP> str <SEP> outlineerrtrycatch <SEP> str <SEP> outlineerrunbalancedmarkers <SEP> str <SEP> outlineerrdeletedtarget <SEP> str <SEP> outlineerrmethodtoobig <SEP> str <SEP> deserializetransleterr <SEP> str
start spi start <PLACE_HOLDER> .,start stopwatch ( ) ; assert parameter ( cred != null @$ __str__ ) ; if ( log . is debug enabled ( ) ) { log . debug ( config info ( __str__ @$ cred ) ) ; log . debug ( config info ( __str__ @$ cfg ) ) ; log . debug ( config info ( __str__ @$ bucket name suffix ) ) ; log . debug ( config info ( __str__ @$ bucket endpoint ) ) ; log . debug ( config info ( __str__ @$ sse alg ) ) ; } if ( cfg == null ) u . warn ( log @$ __str__ ) ; if ( f . is empty ( bucket name suffix ) ) { u . warn (,spi start stopwatch,success,obj,str <SEP> config <SEP> str <SEP> config <SEP> str <SEP> cfg <SEP> config <SEP> str <SEP> config <SEP> str <SEP> endpoint <SEP> config <SEP> str <SEP> sse <SEP> alg <SEP> cfg <SEP> str
assert that all threads got back the same <PLACE_HOLDER>,for ( future < map < bounded window @$ long > > result : results ) { assert equals ( value @$ result . get ( ) ) ; for ( map . entry < bounded window @$ long > entry : result . get ( ) . entry set ( ) ) { assert same ( value . get ( entry . get key ( ) ) @$ entry . get value ( ) ) ; } },threads got reference,success,obj,bounded <SEP> results <SEP> equals <SEP> bounded
memory <PLACE_HOLDER> does duplicate suppression,return - __num__ ;,cache duplicate suppression,fail,sub,num
note : the subclass will release the 'work finished latch ' early @$ before work is actually finished . this means that the test may proceed and perform <PLACE_HOLDER> earlier than anticipated .,work start latch . count down ( ) ; try { work finished latch . await ( __num__ @$ time unit . seconds ) ; } catch ( interrupted exception e ) { assert . fail ( __str__ ) ; } work finished latch = new count down latch ( __num__ ) ;,test proceed work,fail,obj,num <SEP> seconds <SEP> interrupted <SEP> str <SEP> num
the <PLACE_HOLDER> executes the following block @$ which essentially shuts down the peer if it is not the last round .,if ( v . get id ( ) == i ) { log . info ( __str__ @$ i ) ; if ( lc < this . total rounds ) { log . info ( __str__ @$ i ) ; fast leader election election = ( fast leader election ) peer . get election alg ( ) ; election . shutdown ( ) ; assert equals ( - __num__ @$ election . get vote ( ) . get id ( ) ) ; log . info ( __str__ @$ i ) ; break ; } },loop executes block,fail,sub,str <SEP> lc <SEP> rounds <SEP> str <SEP> alg <SEP> equals <SEP> num <SEP> str
<PLACE_HOLDER> required local properties @$ which are matched exactly,properties . for grouping ( new field list ( __num__ @$ __num__ ) ) ; requested local properties req lp = new requested local properties ( ) ; req lp . set grouped fields ( new field list ( __num__ @$ __num__ ) ) ; to map1 . set required global props ( null ) ; to map1 . set required local props ( req lp ) ; to map2 . set required global props ( null ) ; to map2 . set required local props ( null ) ; feedback properties meet requirements report report = map2 . check partial solution properties met ( target @$ gp @$ lp ) ; assert true ( report != null && report != no_partial_solution && report != not_met ) ;,some required properties,success,sub,properties <SEP> num <SEP> num <SEP> requested <SEP> properties <SEP> req <SEP> requested <SEP> properties <SEP> req <SEP> grouped <SEP> fields <SEP> num <SEP> num <SEP> map1 <SEP> required <SEP> map1 <SEP> required <SEP> req <SEP> map2 <SEP> required <SEP> map2 <SEP> required <SEP> properties <SEP> requirements <SEP> map2 <SEP> properties <SEP> nopartialsolution <SEP> notmet
null means get the first <PLACE_HOLDER> .,return get next oid ( null @$ user data ) ;,means get oid,success,obj,None
<PLACE_HOLDER> does not use upper first,string [ ] data = { __str__ @$ __str__ @$ __str__ @$ __str__ } ; generic locale starter ( new locale ( __str__ @$ __str__ ) @$ data ) ;,p use upper,fail,sub,str <SEP> str <SEP> str <SEP> str <SEP> str <SEP> str
ensure removing with the <PLACE_HOLDER> does n't corrupt the hashtable,if ( ( size = ht . size ( ) ) < __num__ ) { fail ( __str__ + size ) ; },iterator corrupt hashtable,success,sub,ht <SEP> num <SEP> str
another <PLACE_HOLDER> already locked this path and is processing it . wait for the other <PLACE_HOLDER> to finish @$ by locking the existing read lock .,> ufs resource = resolution . acquire ufs resource ( ) ) { under file system ufs = ufs resource . get ( ) ; exists in ufs = ufs . exists ( resolution . get uri ( ) . to string ( ) ) ; } if ( exists in ufs ) { m cache . invalidate ( alluxio uri . get path ( ) ) ; } else { m cache . put ( alluxio uri . get path ( ) @$ mount info . get mount id ( ) ) ; if ( path lock . is invalidate ( ) ) { m cache . invalidate ( alluxio uri . get path ( ) ) ; } else { return false ; } } },thread locked path,success,sub,ufs <SEP> ufs <SEP> ufs <SEP> ufs <SEP> exists <SEP> ufs <SEP> ufs <SEP> exists <SEP> exists <SEP> ufs <SEP> alluxio <SEP> alluxio <SEP> alluxio
pool . if no connection is available @$ it requests one and waits for it to be created . but a <PLACE_HOLDER> that requests the connection and before it could wait @$ other <PLACE_HOLDER> could steal that connection . the connections in progress tries to avoid these edge cases by not requesting a connection from the pool when other <PLACE_HOLDER> is requesting one .,if ( connections in progress . get ( ) == __num__ ) { resource = non blocking get ( key @$ pool ) ; } if ( resource == null ) { connections in progress . increment and get ( ) ; try { attempt grow ( key @$ this . object factory @$ pool ) ; resource = non blocking get ( key @$ pool ) ; } finally { connections in progress . decrement and get ( ) ; } } return resource ;,thread gets connection,success,sub,connections <SEP> num <SEP> blocking <SEP> connections <SEP> blocking <SEP> connections <SEP> decrement
one last sync whose transactions are not expected to be seen in the input streams because the journal nodes have not updated their <PLACE_HOLDER> of the committed transaction id yet,write txns ( stm @$ __num__ @$ __num__ ) ; future throws ( new io exception ( ) ) . when ( spies . get ( __num__ ) ) . get journaled edits ( __num__ @$ quorum journal manager . qjm_rpc_max_txns_default ) ; future throws ( new io exception ( ) ) . when ( spies . get ( __num__ ) ) . get journaled edits ( __num__ @$ quorum journal manager . qjm_rpc_max_txns_default ) ; list < edit log input stream > streams = new array list < > ( ) ; qjm . select input streams ( streams @$ __num__ @$ true @$ true ) ;,nodes updated stats,fail,obj,txns <SEP> stm <SEP> num <SEP> num <SEP> throws <SEP> io <SEP> num <SEP> journaled <SEP> edits <SEP> num <SEP> qjmrpcmaxtxnsdefault <SEP> throws <SEP> io <SEP> num <SEP> journaled <SEP> edits <SEP> num <SEP> qjmrpcmaxtxnsdefault <SEP> streams <SEP> qjm <SEP> streams <SEP> streams <SEP> num
assumption : the client has already retrieved <PLACE_HOLDER> to the given address,if ( addr . equals ( code unit address ) ) { continue ; },client retrieved access,fail,obj,addr <SEP> equals
return the fragment <PLACE_HOLDER> simplifiable conditional expression,return new sentence fragment ( fragment tree @$ fragment . has assumed truth ( ) ? fragment . get assumed truth ( ) : true @$ false ) . change score ( fragment . has score ( ) ? fragment . get score ( ) : __num__ ) ;,tree simplifiable expression,fail,sub,num
host name should be valid @$ but most probably not existing if <PLACE_HOLDER> not enough @$ then should probably run 'list ' command first to be sure ...,string not existent fake host name = __str__ ; string credentials not found msg = null ; try { run credential program ( not existent fake host name @$ credential helper name ) ; log . warn ( __str__ @$ credential helper name ) ; } catch ( exception e ) { if ( e instanceof invalid result exception ) { credentials not found msg = extract credential provider error message ( ( invalid result exception ) e ) ; } if ( is blank ( credentials not found msg ) ) { log . warn ( __str__ @$ credential helper name @$ e . get message ( ) ) ; } else { log . debug ( __str__ @$ credentials not found msg ) ; } },password run command,fail,sub,str <SEP> str <SEP> instanceof <SEP> str <SEP> str
the child case instance has the plan item instance <PLACE_HOLDER> as callback <PLACE_HOLDER> stored . when the child case instance is finished @$ the plan item of the parent case needs to be triggered .,if ( case instance state . terminated . equals ( callback data . get new state ( ) ) || case instance state . completed . equals ( callback data . get new state ( ) ) ) { command context command context = command context util . get command context ( ) ; plan item instance entity plan item instance entity = command context util . get plan item instance entity manager ( command context ) . find by id ( callback data . get callback id ( ) ) ; if ( plan item instance entity != null ) { command context util . get agenda ( command context ) . plan trigger plan item instance operation ( plan item instance entity ) ; } },instance has id,success,obj,terminated <SEP> equals <SEP> completed <SEP> equals <SEP> util <SEP> util <SEP> util
we expect two dependencies @$ because the dependencies are annotated with element @$ <PLACE_HOLDER> has a unique id @$ it 's difficult to directly compare them . instead we will manually compare all the fields except the unique id,. size ( ) ) ; for ( dependency < ? > dependency : actual dependencies ) { key < ? > key = dependency . get key ( ) ; assert equals ( new type literal < string > ( ) { } @$ key . get type literal ( ) ) ; annotation annotation = dependency . get key ( ) . get annotation ( ) ; assert true ( annotation instanceof element ) ; element element = ( element ) annotation ; assert equals ( __str__ @$ element . set name ( ) ) ; assert equals ( element . type . mapbinder @$ element . type ( ) ) ; assert equals ( __str__ @$ element . key type ( ) ) ; },which has id,success,sub,dependencies <SEP> equals <SEP> instanceof <SEP> equals <SEP> str <SEP> equals <SEP> mapbinder <SEP> equals <SEP> str
as we do n't have a bind we need a unique name . let 's use the <PLACE_HOLDER> as the generated invoker,identifier = generated class name ; context . add declaration ( generated class name @$ object . class ) ;,name use name,fail,obj,generated <SEP> generated
we enqueued a pending frame @$ let 's try <PLACE_HOLDER> else next .,break ;,let try something,success,obj,None
some statistics for bitmap : 1 million distinct keys takes about 2 <PLACE_HOLDER> storage 5 million takes 10 <PLACE_HOLDER> 10 million takes 12 <PLACE_HOLDER>,return __num__ * __num__ * __num__ ;,statistics takes mb,success,obj,num <SEP> num <SEP> num
only master stream can resolve the data <PLACE_HOLDER>,assert ( m_coordinator . is master ( ) ) ;,stream resolve space,fail,obj,mcoordinator
vm <PLACE_HOLDER> locks and frees key <PLACE_HOLDER>,vm1 . invoke ( new serializable runnable ( ) { @ override public void run ( ) { logger . info ( __str__ ) ; connect distributed system ( ) ; d lock service dls = ( d lock service ) d lock service . create ( dls name @$ get system ( ) @$ true @$ true @$ false ) ; assert that ( dls . lock ( key1 @$ - __num__ @$ - __num__ ) ) . is true ( ) ; logger . info ( __str__ ) ; dls . unlock ( key1 ) ; assert that ( dls . get token ( key1 ) ) . is not null ( ) ; dls . free resources ( key1 ) ; d lock token token,vm locks 1,success,obj,vm1 <SEP> serializable <SEP> runnable <SEP> str <SEP> distributed <SEP> dls <SEP> dls <SEP> dls <SEP> key1 <SEP> num <SEP> num <SEP> str <SEP> dls <SEP> key1 <SEP> dls <SEP> key1 <SEP> dls <SEP> resources <SEP> key1
p 2 post <PLACE_HOLDER> contain the p 1 comment string .,program builder1 . create comment ( __str__ @$ __str__ @$ code unit . post_comment ) ; program builder2 . create comment ( __str__ @$ __str__ @$ code unit . post_comment ) ; check comment difference ( __num__ ) ;,comments contain string,success,sub,builder1 <SEP> str <SEP> str <SEP> postcomment <SEP> builder2 <SEP> str <SEP> str <SEP> postcomment <SEP> num
ooohml provides the <PLACE_HOLDER> for disconnecting and closing cache on out of off heap memory exception,out of off heap memory listener ooohml = new disconnecting out of off heap memory listener ( ( internal distributed system ) system ) ; return basic create off heap storage ( sf @$ off heap memory size @$ ooohml ) ;,ooohml provides method,fail,obj,ooohml <SEP> disconnecting <SEP> distributed <SEP> ooohml
user 3 joins the new <PLACE_HOLDER>,multi user chat muc3 = new multi user chat ( get connection ( __num__ ) @$ room ) ; muc3 . join ( __str__ ) ;,user joins room,success,obj,muc3 <SEP> num <SEP> muc3 <SEP> str
recalculate wait <PLACE_HOLDER> .,woke = ( woke == - __num__ ) ? system . current time millis ( ) : woke ; wait time = this . period - ( woke - start time ) ;,recalculate wait time,success,obj,num <SEP> millis
class file to write @$ if directory then use the <PLACE_HOLDER> of the input,path output = paths . get ( args [ __num__ ] ) ; if ( files . is directory ( output ) ) output = output . resolve ( input . get file name ( ) ) ;,directory use name,success,obj,paths <SEP> args <SEP> num <SEP> files
the two <PLACE_HOLDER> should have different storage folders for their intermediate data .,config1 . set crawl storage folder ( crawl storage folder + __str__ ) ; config2 . set crawl storage folder ( crawl storage folder + __str__ ) ; config1 . set politeness delay ( __num__ ) ; config2 . set politeness delay ( __num__ ) ; config1 . set max pages to fetch ( __num__ ) ; config2 . set max pages to fetch ( __num__ ) ;,pages have folders,fail,sub,config1 <SEP> str <SEP> config2 <SEP> str <SEP> config1 <SEP> num <SEP> config2 <SEP> num <SEP> config1 <SEP> pages <SEP> num <SEP> config2 <SEP> pages <SEP> num
only 1 process can have this process <PLACE_HOLDER>,break ;,process have state,fail,obj,None
get more parameters depending on the kind of <PLACE_HOLDER> class we 're working with . brute <PLACE_HOLDER> does n't need anything else . locality sensitive hash <PLACE_HOLDER> and projection <PLACE_HOLDER>es need <PLACE_HOLDER> size . projection <PLACE_HOLDER>es also need the number of projections .,boolean get search size = false ; boolean get num projections = false ; if ( ! searcher class . equals ( brute search . class . get name ( ) ) ) { get search size = true ; get num projections = true ; },search need size,success,sub,num <SEP> projections <SEP> equals <SEP> num <SEP> projections
order matters @$ as the cluster <PLACE_HOLDER> modifies the event bus <PLACE_HOLDER> .,if ( allow clustering ) { set event bus options ( conf @$ options ) ; initialize cluster options ( conf @$ options ) ; },options modifies options,success,obj,clustering <SEP> options <SEP> conf <SEP> options <SEP> options <SEP> conf <SEP> options
instance on <PLACE_HOLDER> to get the field,mv . visit var insn ( aload @$ __num__ ) ;,which get field,success,sub,var <SEP> insn <SEP> aload <SEP> num
use cached buffered <PLACE_HOLDER> for now .,return m player . get buffered position ( ) ;,use cached position,fail,obj,buffered
no ties top <PLACE_HOLDER>,arrays . fill ( hits @$ __num__ ) ; actual_label = __num__ ; pred_dist = new double [ ] { __num__ @$ __num__ @$ __num__ @$ __num__ @$ __num__ } ; update hits ( __num__ @$ actual_label @$ pred_dist @$ hits ) ; assert . assert true ( arrays . equals ( hits @$ new double [ ] { __num__ @$ __num__ @$ __num__ @$ __num__ } ) ) ;,ties top point,fail,obj,arrays <SEP> hits <SEP> num <SEP> actuallabel <SEP> num <SEP> preddist <SEP> num <SEP> num <SEP> num <SEP> num <SEP> num <SEP> hits <SEP> num <SEP> actuallabel <SEP> preddist <SEP> hits <SEP> arrays <SEP> equals <SEP> hits <SEP> num <SEP> num <SEP> num <SEP> num
check that the byte array contains the complete <PLACE_HOLDER>,if ( len > b . length ) { throw new illegal argument exception ( __str__ ) ; } try { synchronized ( send lock ) { send packet0 ( id @$ b ) ; } } catch ( io exception ioe ) { if ( ! is open ( ) ) { throw new closed connection exception ( __str__ ) ; } else { throw ioe ; } },array contains packet,success,obj,str <SEP> synchronized <SEP> packet0 <SEP> io <SEP> ioe <SEP> str <SEP> ioe
close req 1 and make sure req 2 does not affect num active <PLACE_HOLDER> .,actual res1 . close ( ) ; await ( ) . until asserted ( ( ) -> assert that ( client . num active requests ( ) ) . is zero ( ) ) ;,req affect requests,success,obj,res1 <SEP> close <SEP> asserted <SEP> num <SEP> requests
the wait is necessary to have the poll <PLACE_HOLDER> complete and propagate the changes from database one to two over the postgre sql back end .,comment > one three = database onecode node . get comments ( ) . get global code node comment ( ) ; final list < i comment > two three = database twocode node . get comments ( ) . get global code node comment ( ) ; assert equals ( one two size @$ one three . size ( ) ) ; assert equals ( two two size @$ two three . size ( ) ) ; assert equals ( one three @$ two three ) ; assert equals ( __str__ @$ iterables . get last ( one three ) . get comment ( ) ) ; assert equals ( __str__ @$ iterables . get last ( two three ) . get comment ( ) ) ;,function complete changes,success,sub,onecode <SEP> comments <SEP> twocode <SEP> comments <SEP> equals <SEP> equals <SEP> equals <SEP> equals <SEP> str <SEP> iterables <SEP> last <SEP> equals <SEP> str <SEP> iterables <SEP> last
at least one stack <PLACE_HOLDER> should contain transaction deadlock exception .,if ( has cause ( e @$ transaction timeout exception . class ) && has cause ( e @$ transaction deadlock exception . class ) ) { if ( deadlock . compare and set ( false @$ true ) ) u . error ( log @$ __str__ + transaction deadlock exception . class . get simple name ( ) @$ e ) ; },trace contain exception,success,sub,str
check if the <PLACE_HOLDER> has at least one character or digit,for ( string line : lines ) { if ( character_digits_pattern . matcher ( line ) . matches ( ) ) { stderr . append ( line ) ; } },line has character,success,sub,lines <SEP> characterdigitspattern <SEP> matcher <SEP> matches <SEP> stderr
<PLACE_HOLDER> last saved type or string by default :,if ( saved type != - __num__ && saved type < type combo box . get item count ( ) ) { type combo box . set selected index ( saved type ) ; } else { type combo box . set selected item ( new supported column type wrapper ( string . class ) ) ; },check saved type,fail,sub,saved <SEP> num <SEP> saved <SEP> selected <SEP> saved <SEP> selected <SEP> supported
in order to find out whether the divide generates the exact <PLACE_HOLDER> @$ we avoid calling the above divide method . 'quotient ' holds the return big decimal object whose scale will be set to 'scl ' .,big decimal quotient ; int scl = check scale non zero ( preferred scale + yscale - xscale + mcp ) ; if ( check scale non zero ( ( long ) mcp + yscale - xscale ) > __num__ ) { int raise = check scale non zero ( ( long ) mcp + yscale - xscale ) ; big integer rb = big multiply power ten ( xs @$ raise ) ; quotient = divide and round ( rb @$ ys @$ scl @$ rounding mode @$ check scale non zero ( preferred scale ) ) ; } else { int new scale = check scale non zero ( ( long ) xscale - mcp ) ; int raise = check scale non zero ( (,divide generates result,success,obj,int <SEP> scl <SEP> preferred <SEP> yscale <SEP> xscale <SEP> mcp <SEP> mcp <SEP> yscale <SEP> xscale <SEP> num <SEP> int <SEP> mcp <SEP> yscale <SEP> xscale <SEP> rb <SEP> rb <SEP> ys <SEP> scl <SEP> preferred <SEP> int <SEP> xscale <SEP> mcp <SEP> int
if it is not a global @$ it might be accessing a local of the outer scope . if that 's the case the <PLACE_HOLDER> between the variable 's declaring scope and the variable reference scope can not be moved .,if ( var . get scope ( ) != t . get scope ( ) ) { for ( name context context : symbol stack ) { if ( context . scope == var . get scope ( ) ) { break ; } context . name . read closure variables = true ; } },closure declaring scope,fail,sub,var <SEP> var <SEP> variables
this all could probably be done more <PLACE_HOLDER> via a group extracted from a more comprehensive regexp . clean up any extra spaces around the remainder of the line @$ which should be a view name .,return statement . substring ( matcher . end ( ) ) . trim ( ) ;,elegantly clean spaces,success,sub,substring <SEP> matcher
the rollback operation should have rolled back the first nn 's local <PLACE_HOLDER> @$ and the shared dir @$ but not the other nn 's <PLACE_HOLDER> . those have to be done by bootstrapping the standby .,check nn previous dir existence ( cluster @$ __num__ @$ false ) ; check jn previous dir existence ( qj cluster @$ false ) ; if ( fs != null ) { fs . close ( ) ; } if ( qj cluster != null ) { qj cluster . shutdown ( ) ; },operation rolled dirs,success,obj,nn <SEP> dir <SEP> num <SEP> jn <SEP> dir <SEP> qj <SEP> fs <SEP> fs <SEP> close <SEP> qj <SEP> qj
okay @$ we have the data . <PLACE_HOLDER> have the agent do the restore .,stage . close ( ) ; m backup data = parcel file descriptor . open ( m backup data name @$ parcel file descriptor . mode_read_only ) ; m new state = parcel file descriptor . open ( m new state name @$ parcel file descriptor . mode_read_write | parcel file descriptor . mode_create | parcel file descriptor . mode_truncate ) ;,both have data,fail,sub,close <SEP> modereadonly <SEP> modereadwrite <SEP> modecreate <SEP> modetruncate
check if <PLACE_HOLDER> uses general midi 2 default banks .,int bank = get patch ( ) . get bank ( ) ; if ( bank > > __num__ == __num__ || bank > > __num__ == __num__ ) { boolean [ ] ch = new boolean [ __num__ ] ; for ( int i = __num__ ; i < ch . length ; i ++ ) ch [ i ] = true ; return ch ; } boolean [ ] ch = new boolean [ __num__ ] ; for ( int i = __num__ ; i < ch . length ; i ++ ) ch [ i ] = true ; ch [ __num__ ] = false ; return ch ;,algorithm uses banks,fail,sub,int <SEP> num <SEP> num <SEP> num <SEP> num <SEP> num <SEP> int <SEP> num <SEP> num <SEP> int <SEP> num <SEP> num
create a new item list which contain a new adapter item object the id of the new item is changed @$ and will be treated as a new item according to the rule we set in the callback . this test case is to verify the get change payload <PLACE_HOLDER> still honor the standard we set up to judge new item,m items . clear ( ) ; adapter item new item = new adapter item ( __num__ @$ __str__ @$ __str__ ) ; m items . add ( new item ) ;,the honor parameters,fail,obj,items <SEP> num <SEP> str <SEP> str <SEP> items
