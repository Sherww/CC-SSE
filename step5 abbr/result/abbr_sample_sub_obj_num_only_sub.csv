collator.get keyword <PLACE_HOLDER> return the same contents for both commonly used true and false .,== all . length ) { match all = true ; for ( int j = __num__ ; j < pref . length ; j ++ ) { boolean found match = false ; for ( int k = __num__ ; k < all . length ; k ++ ) { if ( pref [ j ] . equals ( all [ k ] ) ) { found match = true ; break ; } } if ( ,key return contents,fail,sub,pref <SEP> errln <SEP> loc ,15,,,,
<PLACE_HOLDER> to the old behavior @$ allowing implementations to override .,map to map from id ( data @$ obj ) ;,objects allowing implementations,fail,sub,obj,1,,comm&& obj:object bin 1,,
the map reduce tokens are provided so that <PLACE_HOLDER> can spawn jobs if they wish to . the <PLACE_HOLDER> authenticate to the job tracker via the map reduce delegation tokens .,if ( system . getenv ( __str__ ) != null ) { conf . set ( __str__ @$ system . getenv ( __str__ ) ) ; } return conf ;,client spawn jobs,fail,sub, conf ,7,,,,
zero <PLACE_HOLDER> means a run,offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } while ( ip < ip bound ) { if ( input [ in offset + ref ++ ] != input [ in offset + ip ++ ] ) { break ; } } break ; } },address means run,fail,sub,ip <SEP> ip <SEP> ip ,7,,,,
set timestamp before moving to <PLACE_HOLDER>root @$ so we can avoid race condition <PLACE_HOLDER> remove the file before setting timestamp,sum . equals ignore case ( checksum for ( cm path @$ fs ) ) ) { success = false ; } else { switch ( type ) { case move : { log . info ( __str__ @$ path . to string ( ) @$ cm path . to string ( ) ) ; success = fs . rename ( path @$ cm path ) ; break ; } case copy : { log . info ( __str__ @$ path . to string ( ) @$ cm path . to string ( ) ) ; success = file utils . copy ( fs @$ path @$ fs @$ cm path @$ false @$ true @$ conf ) ; break ; } default : break ; } },exception remove file,fail,sub, fs <SEP> fs <SEP> utils <SEP> fs <SEP> fs <SEP> conf,9,,,,
add parameters from the configuration in the job trace the reason why the job configuration parameters @$ as seen in the jobconf file @$ are added first because the specialized <PLACE_HOLDER> obtained from rumen should override the job conf <PLACE_HOLDER> .,for ( map . entry < object @$ object > entry : job . get job properties ( ) . get value ( ) . entry set ( ) ) { job conf . set ( entry . get key ( ) . to string ( ) @$ entry . get value ( ) . to string ( ) ) ; },parameters override values,fail,sub,conf,2,,code$$  conf: configuration 1,,
let the hash builder <PLACE_HOLDER> reduce their accounted memory,partitions no longer needed . set ( null ) ; lock . write lock ( ) . lock ( ) ; try { arrays . fill ( partitions @$ null ) ; lookup source supplier = null ; close cached lookup sources ( ) ; } finally { lock . write lock ( ) . unlock ( ) ; },partitions reduce memory,fail,sub,None,8,,,,
illegal access error is expected note : <PLACE_HOLDER> stops context right after shutdown initiated . it is problematic to see log output system out could help,logger . warn ( __str__ + e . get message ( ) ) ;,user stops right,fail,sub,None,1,,,,
<PLACE_HOLDER> must have the same type,if ( node1 . get class ( ) != node2 . get class ( ) ) { return false ; } string image1 = node1 . get image ( ) ; string image2 = node2 . get image ( ) ;,image have type,fail,sub,None,6,,,,
quick exit : if the <PLACE_HOLDER> does not support encryption @$ we can exit early .,if ( ! is encryption supported ( ) ) { return device policy manager . encryption_status_unsupported ; },device support encryption,fail,sub,None,2,,,,
sequence <PLACE_HOLDER> compress writer,( fs @$ count @$ seed @$ block compressed file ) ; sort test ( fs @$ count @$ megabytes @$ factor @$ true @$ block compressed file ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; merge test ( fs @$ count @$ seed @$ block compressed file @$ compression type . block @$ false @$ factor @$ megabytes ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; merge test ( fs @$ count @$ seed @$ block compressed file @$ compression type . block @$ true @$ factor @$ megabytes ) ; check sort ( fs @$ count @$ seed @$ block compressed file ) ; fs . close ( ) ;,block . file compress writer,fail,sub,fs ,19,,,,
the input method <PLACE_HOLDER> only throws security exceptions @$ so let 's log all others .,if ( ! ( e instanceof security exception ) ) { slog . wtf ( tag @$ __str__ @$ e ) ; } throw e ;,method throws exceptions,fail,sub,None,2,,,,
we need something that will measure the amount of time since our <PLACE_HOLDER> has seen a record ...,time since time since last record = threads . time since ( clock . system ) ;,thread seen record,fail,sub,None,2,,,,
show that <PLACE_HOLDER> does work,do in hibernate ( this :: session factory @$ session -> { query query = session . create query ( __str__ @$ foo . class ) ; list < foo > list = query . get result list ( ) ; assert equals ( __num__ @$ list . size ( ) ) ; } ) ;,scan does work,fail,sub,None,5,,,,
since hot swap <PLACE_HOLDER> run one file at a time @$ namespaces seen will not include any provides earlier than this current file .,if ( ! in hot swap && import type . must be ordered ( ) && ! namespaces seen . contains ( namespace ) ) { t . report ( call @$ late_provide_error @$ namespace ) ; },plugins run file,fail,sub,None,5,,,,
at normal playback speed @$ we stop <PLACE_HOLDER>ing when the <PLACE_HOLDER> reaches the minimum .,assert that ( load control . should continue loading ( min_buffer_us @$ speed ) ) . is false ( ) ;,load reaches minimum,fail,sub,min,1,,comm&&  min  minimum 1,,
if the size of bloom filter is smaller than 1 mb @$ use <PLACE_HOLDER> max false positive probability,if ( num bits required <= max num bits ) { return default max false pos probability ; },value max probability,fail,sub,pos,6,,comm&&  pos  postive 1,,
add view <PLACE_HOLDER> add view end,skeleton models . add ( new skeleton model builder ( ) . set start view ( btn3 ) . set end view ( btn4 ) . build ( ) ) ;,bottom add end,fail,sub, btn3 <SEP> btn4,3,,comm&&  btn bottom 2,,
the <PLACE_HOLDER> should contain just 1 character :,assert equals ( __num__ @$ straus . get len ( ) ) ; har file system . close ( ) ; local fs . delete ( tmp path @$ true ) ;,directory contain character,fail,sub, har <SEP> fs <SEP> tmp,7,,code$$  fs file system 1,,
log a warning if the <PLACE_HOLDER> uses an unnecessary service error definition annotation,if ( service error def annotation != null && ! resource model . is any service error list defined ( ) ) { log . warn ( string . format ( __str__ + __str__ + __str__ @$ resource class . get name ( ) @$ service error def . class . get simple name ( ) @$ service errors . class . get simple name ( ) @$ param error . class . get simple name ( ) ) ) ; },user uses annotation,fail,sub, param,6,,,,
if we have <PLACE_HOLDER> combine their transforms,while ( parent node != null ) { if ( parent == current spatial ) { transform trans = new transform ( ) ; trans . set scale ( current spatial . get local scale ( ) ) ; shape transform . combine with parent ( trans ) ; parent node = null ; } else { shape transform . combine with parent ( current spatial . get local transform ( ) ) ; parent node = current spatial . get parent ( ) ; current spatial = parent node ; } },them combine transforms,fail,sub,None,0,,,,
metadata <PLACE_HOLDER> have no entropy,assert that ( handle . get metadata handle ( ) . get file path ( ) . to string ( ) @$ not ( contains string ( entropy_marker ) ) ) ; assert that ( handle . get metadata handle ( ) . get file path ( ) . to string ( ) @$ not ( contains string ( resolved_marker ) ) ) ;,streams have entropy,fail,sub,None,4,,,,
change resolutions and check that the selected date is not lost and that the <PLACE_HOLDER> has the correct resolution .,click ( resolution hour ) ; check header and body ( date time resolution . hour @$ false ) ; click ( resolution year ) ; check header and body ( date time resolution . year @$ false ) ; click ( resolution minute ) ; check header and body ( date time resolution . minute @$ false ) ;,day has resolution,fail,sub,None,2,,,,
if we do n't have an mx record @$ try the machine <PLACE_HOLDER>,if ( ( attr == null ) || ( attr . size ( ) == __num__ ) ) { attrs = ictx . get attributes ( host name @$ new string [ ] { __str__ } ) ; attr = attrs . get ( __str__ ) ; if ( attr == null ) { throw new naming exception ( base messages . get string ( pkg @$ __str__ @$ host name ) ) ; } },attributes try machine,fail,sub,attr <SEP> attr <SEP> attrs <SEP> attr <SEP> attrs <SEP> attr ,14,,code$$  attr: attributes 6,,
if a component specifies the file with a bad font @$ the corresponding <PLACE_HOLDER> will be initialized by default physical font . in such case find font 2 d may return composite font which can not be casted to physical font .,if ( ! component names [ slot ] . equals ignore case ( name ) ) { try { components [ slot ] = ( physical font ) fm . find font2d ( component names [ slot ] @$ style @$ font manager . physical_fallback ) ; } catch ( class cast exception cce ) { components [ slot ] = fm . get default physical font ( ) ; } },component find font,fail,sub,cce,8,,code$$   cce class cast exception  1,,
because entries <PLACE_HOLDER> is empty @$ remove and decrement value,if ( entries . is empty ( ) ) { synchronized ( entries ) { if ( entries . is empty ( ) ) { if ( value to entries map . remove ( new key @$ entries ) ) { num index keys . decrement and get ( ) ; internal index stats . inc num keys ( - __num__ ) ; } } } },map empty value,fail,sub,None,12,,,,
<PLACE_HOLDER> on parent would have precedence,attribute conversion info conversion = locate attribute conversion info ( property name ) ; if ( conversion != null ) { return conversion ; } return null ;,conversion have precedence,fail,sub,None,0,,,,
<PLACE_HOLDER> what cloud we think we are in . publish our health as well .,udp heartbeat . build_and_multicast ( cloud @$ hb ) ;,test publish health,fail,sub,udp <SEP> hb,3,,code$$  hb  heartbeat  1,,
and that local <PLACE_HOLDER> always takes preference over remote <PLACE_HOLDER> .,) ) ; differencer . inject ( metadata to inject ) ; evaluation context evaluation context = evaluation context . new builder ( ) . set keep going ( false ) . set num threads ( __num__ ) . set event hander ( null event handler . instance ) . build ( ) ; assert that ( driver . evaluate ( immutable list . of ( action key1 @$ action key2 ) @$ evaluation context ) . has error ( ) ) . is false ( ) ; assert that ( new filesystem value checker ( null @$ null ) . get dirty action values ( evaluator . get values ( ) @$ null @$ modified file set . everything_modified ) ) . is empty ( ) ;,storage takes preference,fail,sub,None,13,,,,
no <PLACE_HOLDER> left so close the actual server the done handler needs to be executed on the context that calls close @$ not the context of the actual server,actual server . actual close ( context @$ completion ) ;,error left server,fail,sub,None,1,,,,
<PLACE_HOLDER> set image drawable internally,super . set image bitmap ( bitmap ) ;,constructor set drawable,fail,sub,None,0,,,,
the <PLACE_HOLDER> can specify the hadoop memory,map < string @$ string > variables = new hash map < string @$ string > ( system . getenv ( ) ) ;,environment specify memory,fail,sub,env,2,comm&& zhu env environment 1,,,
as the annotation is legal on fields and methods only @$ javac <PLACE_HOLDER> will take care of printing an error message for this .,return ;,processing take care,fail,sub,None,0,,,,
<PLACE_HOLDER> @$ like all package groups @$ does n't have a configuration,) { package group package group = ( package group ) target ; target context target context = new target context ( analysis environment @$ target @$ config @$ prerequisite map . get ( dependency resolver . visibility_dependency ) @$ visibility ) ; return new package group configured target ( target context @$ package group ) ; } else if ( target instanceof environment group ) { target context target context = new target context ( analysis environment @$ target @$ config @$ immutable set . of ( ) @$ visibility ) ; return new environment group configured target ( target context ) ; } else { throw new assertion error ( __str__ + target . get class ( ) . get name ( ) ) ; },looks have configuration,fail,sub,config<SEP>config ,8,,comm&& config configuaration  2,,
x attr exists @$ and replace it using <PLACE_HOLDER> replace flag .,fs . setx attr ( path @$ name1 @$ value1 @$ enum set . of ( x attr set flag . create ) ) ; fs . setx attr ( path @$ name1 @$ new value1 @$ enum set . of ( x attr set flag . create @$ x attr set flag . replace ) ) ; xattrs = fs . getx attrs ( path ) ; assert . assert equals ( xattrs . size ( ) @$ __num__ ) ; assert . assert array equals ( new value1 @$ xattrs . get ( name1 ) ) ; fs . removex attr ( path @$ name1 ) ;,attrs replace flag,fail,sub,fs <SEP> attr <SEP> enum <SEP> attr  <SEP>  attr<SEP> attr <SEP> attr <SEP> attr ,30,,comm&& attr attrs 6,,
synchronously end the animation @$ jumping to the end state . animator <PLACE_HOLDER> has synchronous listener behavior on all supported ap is .,if ( ! animated ) { current animation . end ( ) ; },animation has behavior,fail,sub,None,0,,,,
verify exit <PLACE_HOLDER> matches exit state of script,assert . assert equals ( exit code @$ container status . get exit status ( ) ) ;,code matches state,fail,sub,None,1,,,,
wait until the connection used by res 1 is returned to the pool @$ so that the next <PLACE_HOLDER> reuses the connection .,while ( ! connection returned to pool ) { condition . await ( ) ; } lock . unlock ( ) ;,callback reuses connection,fail,sub,None,1,,,,
null <PLACE_HOLDER> does n't actually retain the session,assert false ( cache . contains ( __str__ ) ) ;,properties retain session,fail,sub,None,2,,,,
queue c <PLACE_HOLDER> has sa and aq @$ both from parent,assert true ( c111 . has access ( queueacl . administer_queue @$ user ) ) ; assert true ( has queueacl ( acl infos @$ queueacl . administer_queue @$ __str__ ) ) ; assert true ( c111 . has access ( queueacl . submit_applications @$ user ) ) ; assert true ( has queueacl ( acl infos @$ queueacl . submit_applications @$ __str__ ) ) ; reset ( c ) ;,11 has sa,fail,sub,None,18,,,,
<PLACE_HOLDER> should remove visibility .,assert true ( m accounts db . delete de account ( acc id ) ) ;,display remove visibility,fail,sub,db <SEP> acc,3,,,,
<PLACE_HOLDER> only represent configuration details of the parent @$ and are not independent entities,return false ;,nodes represent details,fail,sub,None,0,,,,
check if we can use the fast path @$ resuming a session . we can do so iff we have a valid record for that session @$ and the cipher suite for that session was on the list which the <PLACE_HOLDER> requested @$ and if we 're not forgetting any needed authentication on the part of the <PLACE_HOLDER> .,__str__ + session identity alg ) ; } resuming session = false ; } } if ( resuming session ) { cipher suite suite = previous . get suite ( ) ; if ( ( is negotiable ( suite ) == false ) || ( mesg . get cipher suites ( ) . contains ( suite ) == false ) ) { resuming session = false ; } else { set cipher suite ( suite ) ; } } if ( resuming session ) { session = previous ; if ( debug != null && ( debug . is on ( __str__ ) || debug . is on ( __str__ ) ) ) { system . out . println ( __str__ + session ) ; } } },server requested which,fail,sub,mesg ,13,,,,
res <PLACE_HOLDER> the first found abstract method,method res = null ; for ( method mi : methods ) { if ( ! modifier . is abstract ( mi . get modifiers ( ) ) ) continue ; if ( mi . get annotation ( traits . implemented . class ) != null ) continue ; try { object . class . get method ( mi . get name ( ) @$ mi . get parameter types ( ) ) ; continue ; } catch ( no such method exception e ) { } if ( res != null ) return null ; res = mi ; },returns found method,fail,sub,res <SEP> res <SEP> res,8,,comm&& res returns  3  sub,,
spellcheck <PLACE_HOLDER> contains valencian and general accentuation,assert equals ( __num__ @$ rule . match ( lang tool . get analyzed sentence ( __str__ ) ) . length ) ;,sentence contains valencian,fail,sub, lang ,5,,,,
simple <PLACE_HOLDER> can cause troubles here because of how <PLACE_HOLDER> works e.g . between lists and sets .,return collection utils . is equal collection ( state objects @$ that . state objects ) ;,collections works e.g,fail,sub,utils,3,,,,
append the work <PLACE_HOLDER> file path to the job input file,throw closer . rethrow ( t ) ;,input file path,fail,sub,None,2,,,,
unlike pql @$ <PLACE_HOLDER> expects the group columns in select statements .,string group by columns = string utils . join ( _group columns @$ __str__ ) ;,csv expects columns,fail,sub,None,4,,,,
rotate the queue so that each <PLACE_HOLDER> gets the descriptions in a different order,for ( filter filter : filters ) { mutating descriptions . add last ( mutating descriptions . poll first ( ) ) ; for ( description description : descriptions ) { if ( filter . should run ( description ) ) { add description for filter to map ( descriptions run @$ filter @$ description ) ; } } },aggregator gets descriptions,fail,sub,None,8,,,,
if both <PLACE_HOLDER> finished already @$ assert that both <PLACE_HOLDER> throw exception,assert that ( ai1 . get exception ( ) instanceof unsupported operation exception ) . is true ( ) ; assert that ( ai2 . get exception ( ) instanceof unsupported operation exception ) . is true ( ) ;,operations throw exception,fail,sub,None,4,,,,
since the <PLACE_HOLDER> used the immediate scheduler @$ it is unaffected by the main looper being paused .,assert equals ( __num__ @$ x . get ( ) ) ; observable . just ( __num__ ) . compose ( observe forui ( ) ) . subscribe ( x :: set ) ;,test used scheduler,fail,sub,None,4,,,,
catch exceptions since set <PLACE_HOLDER> can cause a security exception to be thrown under netscape in the applet mode,set daemon ( true ) ;,flushing cause exception,fail,sub,None,0,,,,
preserve the same order that <PLACE_HOLDER> org api returns,map < string @$ scm organization > org map = new linked hash map < > ( ) ;,test org returns,fail,sub, org,3,,,,
string <PLACE_HOLDER> does not throw io exception,print to ( ( appendable ) buf @$ instant ) ;,builder throw exception,fail,sub,buf,2,,,,
this newly opened jar <PLACE_HOLDER> has its own index @$ merge it into the parent 's index @$ taking into account the relative path .,jar index new index = new loader . get index ( ) ; if ( new index != null ) { int pos = jar name . last index of ( __str__ ) ; new index . merge ( this . index @$ ( pos == - __num__ ? null : jar name . substring ( __num__ @$ pos + __num__ ) ) ) ; },name has index,fail,sub,pos ,11,,,,
actual <PLACE_HOLDER> @$ just skip the event .,if ( last event . event equals ( cur event ) ) { if ( debug ) slog . d ( tag @$ __str__ + last nanos ) ; } else { assign log id ( cur event ) ; m pending logs . add ( cur event ) ; if ( debug ) slog . d ( tag @$ __str__ + last nanos ) ; },logic skip event,fail,sub,None,9,,,,
logger <PLACE_HOLDER> should not influnce serialization,assert true ( __str__ + sizea + __str__ + sizeb @$ ( sizea - sizeb ) < __num__ ) ;,handler influnce serialization,fail,sub,None,7,,,,
first assume there are no named capture backreferences @$ because the spec says they should only be recognized if the <PLACE_HOLDER> contains at least one named capture group .,max = comma >= __num__ ? comma + __num__ != counts . length ( ) ? integer . parse int ( counts . substring ( comma + __num__ ) ) : integer . max_value : min ; } catch ( number format exception ex ) { min = max = - __num__ ; } if ( min < __num__ || min > max ) { pos = start - __num__ ; return body ; } break ; default : return body ; } boolean greedy = true ; if ( pos < limit && pattern . char at ( pos ) == __str__ ) { greedy = false ; ++ pos ; } return new repetition ( body @$ min @$ max @$ greedy ) ; } },body contains one,fail,sub,num <SEP> num <SEP> num <SEP> num <SEP> num <SEP> pos <SEP> num,16,,code$$ num number 6,,
<PLACE_HOLDER> has no data after flush,is empty ( ) ? __num__ : __num__ ; boolean more ; int cell count = __num__ ; do { list < cell > cells = new array list < > ( ) ; more = s . next ( cells ) ; cell count += cells . size ( ) ; assert equals ( more ? number of mem scanners after flush : __num__ @$ count mem store scanner ( s ) ) ; } while ( more ) ; assert equals ( __str__ + input cells before snapshot . size ( ) + __str__ + input cells after snapshot . size ( ) @$ input cells before snapshot . size ( ) + input cells after snapshot . size ( ) @$ cell count ) ;,structure has data,fail,sub,num <SEP> num <SEP> num <SEP> mem <SEP> num  ,19,,code$$  num number  4,,
we 'll skip words which are punctuation . retrieve <PLACE_HOLDER> indicating punctuation in this treebank .,} result . put ( __str__ @$ correct heads * __num__ / sum arcs ) ; result . put ( __str__ @$ correct heads no punc * __num__ / sum arcs no punc ) ; result . put ( __str__ @$ correct arcs * __num__ / sum arcs ) ; result . put ( __str__ @$ correct arcs no punc * __num__ / sum arcs no punc ) ; result . put ( __str__ @$ correct trees * __num__ / trees . size ( ) ) ; result . put ( __str__ @$ correct trees no punc * __num__ / trees . size ( ) ) ; result . put ( __str__ @$ correct root * __num__ / trees . size ( ) ) ; return result ;,string indicating punctuation,fail,sub, punc <SEP> punc <SEP>  punc <SEP> punc  <SEP> punc ,32,,comm&& punc punctuation  5,,
replace values if better <PLACE_HOLDER> log sum @$ if same edit distance or one space difference,probability log sum + top probability log ) ) || ( compositions [ circular index ] . distance sum + separator length + top ed < compositions [ destination index ] . distance sum ) ) { compositions [ destination index ] . segmented string = compositions [ circular index ] . segmented string + __str__ + part ; compositions [ destination index ] . corrected string = compositions [ circular index ] . corrected string + __str__ + top result ; compositions [ destination index ] . distance sum = compositions [ circular index ] . distance sum + top ed ; compositions [ destination index ] . probability log sum = compositions [ circular index ] . probability log sum + top probability log ; },maximized log sum,fail,sub,None,16,,,,
reduce ipc client <PLACE_HOLDER> retry times and interval time,configuration client conf = new configuration ( false ) ; client conf . set int ( common configuration keys . ipc_client_connect_max_retries_key @$ __num__ ) ; client conf . set int ( common configuration keys . ipc_client_connect_retry_interval_key @$ __num__ ) ;,configuration retry times,fail,sub,conf <SEP> conf  <SEP> conf ,11,,code$$ comm&& conf configuration 3,,
<PLACE_HOLDER> sending @$ will return a send result,try { producer . send ( prepare message ( input ) ) ; collector . ack ( input ) ; } catch ( exception e ) { log . error ( __str__ @$ e ) ; collector . report error ( e ) ; collector . fail ( input ) ; },producer return result,fail,sub,e <SEP> e <SEP> e ,2,,code$$ e  exception  3,,
<PLACE_HOLDER> frames may have changed . tell the input dispatcher about it .,m input monitor . layout input consumers ( dw @$ dh ) ; m input monitor . set update input windows needed lw ( ) ; if ( update input windows ) { m input monitor . update input windows lw ( false ) ; },rpc tell dispatcher,fail,sub,None,6,,,,
if <PLACE_HOLDER> does date parsing for quoted strings @$ we 'd need to verify there 's no type mismatch when string col is filtered by a string that looks like date .,if ( col type == filter type . date && val type == filter type . string ) { try { node value = meta store utils . partition_date_format . get ( ) . parse ( ( string ) node value ) ; val type = filter type . date ; } catch ( parse exception pe ) { } },filter does parsing,fail,sub,None,2,,,,
expected since only test <PLACE_HOLDER> can call that method,assert . fail ( __str__ ) ;,cases call method,fail,sub,None,1,,,,
memory <PLACE_HOLDER> does duplicate suppression,return - __num__ ;,cache duplicate suppression,fail,sub,None,1,,,,
the <PLACE_HOLDER> executes the following block @$ which essentially shuts down the peer if it is not the last round .,if ( v . get id ( ) == i ) { log . info ( __str__ @$ i ) ; if ( lc < this . total rounds ) { log . info ( __str__ @$ i ) ; fast leader election election = ( fast leader election ) peer . get election alg ( ) ; election . shutdown ( ) ; assert equals ( - __num__ @$ election . get vote ( ) . get id ( ) ) ; log . info ( __str__ @$ i ) ; break ; } },loop executes block,fail,sub,None,8,,,,
<PLACE_HOLDER> does not use upper first,string [ ] data = { __str__ @$ __str__ @$ __str__ @$ __str__ } ; generic locale starter ( new locale ( __str__ @$ __str__ ) @$ data ) ;,p use upper,fail,sub,None,6,,,,
return the fragment <PLACE_HOLDER> simplifiable conditional expression,return new sentence fragment ( fragment tree @$ fragment . has assumed truth ( ) ? fragment . get assumed truth ( ) : true @$ false ) . change score ( fragment . has score ( ) ? fragment . get score ( ) : __num__ ) ;,tree simplifiable expression,fail,sub,None,1,,,,
host name should be valid @$ but most probably not existing if <PLACE_HOLDER> not enough @$ then should probably run 'list ' command first to be sure ...,string not existent fake host name = __str__ ; string credentials not found msg = null ; try { run credential program ( not existent fake host name @$ credential helper name ) ; log . warn ( __str__ @$ credential helper name ) ; } catch ( exception e ) { if ( e instanceof invalid result exception ) { credentials not found msg = extract credential provider error message ( ( invalid result exception ) e ) ; } if ( is blank ( credentials not found msg ) ) { log . warn ( __str__ @$ credential helper name @$ e . get message ( ) ) ; } else { log . debug ( __str__ @$ credentials not found msg ) ; } },password run command,fail,sub,None,5,,,,
the two <PLACE_HOLDER> should have different storage folders for their intermediate data .,config1 . set crawl storage folder ( crawl storage folder + __str__ ) ; config2 . set crawl storage folder ( crawl storage folder + __str__ ) ; config1 . set politeness delay ( __num__ ) ; config2 . set politeness delay ( __num__ ) ; config1 . set max pages to fetch ( __num__ ) ; config2 . set max pages to fetch ( __num__ ) ;,pages have folders,fail,sub, config1 <SEP> config2,14,,,,
<PLACE_HOLDER> last saved type or string by default :,if ( saved type != - __num__ && saved type < type combo box . get item count ( ) ) { type combo box . set selected index ( saved type ) ; } else { type combo box . set selected item ( new supported column type wrapper ( string . class ) ) ; },check saved type,fail,sub,None,7,,,,
if it is not a global @$ it might be accessing a local of the outer scope . if that 's the case the <PLACE_HOLDER> between the variable 's declaring scope and the variable reference scope can not be moved .,if ( var . get scope ( ) != t . get scope ( ) ) { for ( name context context : symbol stack ) { if ( context . scope == var . get scope ( ) ) { break ; } context . name . read closure variables = true ; } },closure declaring scope,fail,sub,var <SEP> var ,3,,code$$ var variables  2,,
okay @$ we have the data . <PLACE_HOLDER> have the agent do the restore .,stage . close ( ) ; m backup data = parcel file descriptor . open ( m backup data name @$ parcel file descriptor . mode_read_only ) ; m new state = parcel file descriptor . open ( m new state name @$ parcel file descriptor . mode_read_write | parcel file descriptor . mode_create | parcel file descriptor . mode_truncate ) ;,both have data,fail,sub,None,5,,,,
check if <PLACE_HOLDER> uses general midi 2 default banks .,int bank = get patch ( ) . get bank ( ) ; if ( bank > > __num__ == __num__ || bank > > __num__ == __num__ ) { boolean [ ] ch = new boolean [ __num__ ] ; for ( int i = __num__ ; i < ch . length ; i ++ ) ch [ i ] = true ; return ch ; } boolean [ ] ch = new boolean [ __num__ ] ; for ( int i = __num__ ; i < ch . length ; i ++ ) ch [ i ] = true ; ch [ __num__ ] = false ; return ch ;,algorithm uses banks,fail,sub,None,12,,,,
verify <PLACE_HOLDER> called or not,verify ( wal @$ expect append ? times ( __num__ ) : never ( ) ) . append data ( ( h region info ) any ( ) @$ ( wal key impl ) any ( ) @$ ( wal edit ) any ( ) ) ;,append called not,success,sub, impl ,5,,,,
the <PLACE_HOLDER> should have logging.properties,deque < property > result address = new array deque < > ( operations . get operation address ( logging configuration ) . as property list ( ) ) ; assert . assert true ( __str__ @$ result address . get last ( ) . get value ( ) . as string ( ) . contains ( __str__ ) ) ; model node handler = logging configuration . get ( __str__ @$ __str__ ) ; assert . assert true ( __str__ @$ handler . is defined ( ) ) ; assert . assert true ( handler . has defined ( __str__ ) ) ; string file name = null ;,address have logging.properties,success,sub,None,13,,,,
param <PLACE_HOLDER> will not include 'this ',std type list param types = desc . get parameter types ( ) ; int sz param types = param types . size ( ) ;,"types include ""this""",success,sub,param <SEP> desc <SEP> sz <SEP> param <SEP> param,10,,code$$ param: parameter  3,code$$ sz: size 1,
current <PLACE_HOLDER> already performs cleanup .,return ;,node performs cleanup,success,sub,None,0,,,,
test that the second parse build file <PLACE_HOLDER> repopulated the cache .,assert equals ( __str__ @$ __num__ @$ counter . calls ) ;,call repopulated cache,success,sub,None,4,,,,
<PLACE_HOLDER> contains an object from another thread .,list . add ( obj from another thread . get ( ) ) ;,list contains object,success,sub,obj,1,,comm&& obj:object bin 1,,
<PLACE_HOLDER> means requery the adapter for this @$ it does n't have a valid width .,if ( ! lp . is decor && lp . height factor == __num__ ) { final item info ii = info for child ( child ) ; if ( ii != null ) { lp . height factor = ii . height factor ; lp . position = ii . position ; } },0 means adapter,success,sub,ii <SEP> ii <SEP> ii <SEP> ii,5,,code$$  ii: item info 4,,
localized <PLACE_HOLDER> file name,args . filtered resources provider = new resources filter ( aapt target . with flavors ( internal flavor . of ( __str__ ) ) @$ filesystem @$ immutable sorted set . of ( resource1 @$ resource2 ) @$ immutable sorted set . of ( resource1 @$ resource2 ) @$ graph builder @$ immutable list . of ( resource1 . get res ( ) @$ resource2 . get res ( ) ) @$ immutable set . of ( ) @$ immutable set . of ( ) @$ null @$ resources filter . resource compression mode . disabled @$ filter resources steps . resource filter . empty_filter @$ optional . empty ( ) ) ;,string file name,success,sub,args <SEP> res <SEP> res ,21,str:string  ,code$$  flavor:flavors 1,code$$  res: resources 2,
<PLACE_HOLDER> 1 sends a message to the bare jid of <PLACE_HOLDER> 0,chat chat = get connection ( __num__ ) . get chat manager ( ) . create chat ( get barejid ( __num__ ) @$ null ) ; chat . send message ( __str__ ) ; chat . send message ( __str__ ) ;,user sends message,success,sub, barejid ,5,,comm&& barejid:bare jid 1,,
<PLACE_HOLDER> @$ for each set of paths that have a common input format @$ build a map of mappers to the paths they 're used for,for ( path path : paths ) { class < ? extends mapper > mapper class = mapper map . get ( path ) ; if ( ! mapper paths . contains key ( mapper class ) ) { mapper paths . put ( mapper class @$ new linked list < path > ( ) ) ; } mapper paths . get ( mapper class ) . add ( path ) ; },now build map,success,sub,None,16,,,,
delete <PLACE_HOLDER> is complete before <PLACE_HOLDER> so not relevant @$ get next delete <PLACE_HOLDER>,delete range = delete range it . has next ( ) ? delete range it . next ( ) : null ; break ; case range1_completely_after_range2 :,range get range,success,sub,None,1,,,,
using <PLACE_HOLDER> get an instance of document builder,from attribute ( el @$ __str__ ) ; throw new configuration changed exception ( __str__ + config version ) ; } } catch ( sax exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; } catch ( io exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; } catch ( parser configuration exception ex ) { logger . get logger ( notificationsxml response . class . get name ( ) ) . log ( level . severe @$ null @$ ex ) ; },factory get instance,success,sub,el  <SEP> config <SEP> io <SEP> ex <SEP> ex <SEP> ex <SEP> ex,9,,code$$  ex: exception 4,code$$  conf: configuration 1,
export the data @$ <PLACE_HOLDER> causes a file chooser to be shown,execute on swing without blocking ( ( ) -> key binding utils . export key bindings ( options ) ) ; file selected file = find and test file chooser ( null @$ test_filename ) ; return selected file ;,which causes chooser,success,sub,None,7,,,,
<PLACE_HOLDER> should not impact result,current min = double min kudaf . aggregate ( null @$ current min ) ; assert that ( __num__ @$ equal to ( current min ) ) ;,null impact result,success,sub,None,2,,,,
no context class <PLACE_HOLDER> @$ try the current class <PLACE_HOLDER>,in = ss . get resource as stream ( cl @$ service ) ;,loader try loader,success,sub,None,0,,,,
iterate through all source <PLACE_HOLDER> to make sure we are generating a complete set of source folders for the source <PLACE_HOLDER> .,) . get parent ( ) ; if ( path elements . is empty ( ) ) { continue ; } while ( directory != null && directory . get file name ( ) != null && ! path elements . contains ( directory . get file name ( ) . to string ( ) ) ) { directory = directory . get parent ( ) ; } if ( directory == null || directory . get file name ( ) == null ) { continue ; } string directory path = directory . to string ( ) ; if ( ! directory path . ends with ( __str__ ) ) { directory path += __str__ ; } src folders . add ( directory path ) ; },paths generating set,success,sub, src ,8,,,comm&& src:source,
some <PLACE_HOLDER> to not crash the chartbuilding with emtpy data,if ( m max elements == __num__ ) { m max elements = __num__ ; } if ( m mcount == __num__ ) { m mcount = __num__ ; } if ( m first element == m last element ) { m first element = __num__ ; m last element = __num__ ; } if ( m max cards == __num__ ) { m max cards = __num__ ; } return list . size ( ) > __num__ ;,adjustments crash chartbuilding,success,sub,None,17,,,,
setting volume on ui sounds stream <PLACE_HOLDER> also controls silent mode,if ( ( ( flags & audio manager . flag_allow_ringer_modes ) != __num__ ) || ( stream == get ui sounds stream type ( ) ) ) { set ringer mode ( get new ringer mode ( stream @$ index @$ flags ) @$ tag + __str__ @$ false ) ; },type controls mode,success,sub,None,6,,,,
<PLACE_HOLDER> account type,m ams . add account as user ( m mock account manager response @$ null @$ __str__ @$ null @$ true @$ null @$ user handle . user_system ) ;,response account type,success,sub,ams <SEP> m <SEP> m,3,,code$$  m mock 2,,
try to move focus to the next visible <PLACE_HOLDER> with a running activity if this <PLACE_HOLDER> is not covering the entire screen or is on a secondary display with no home <PLACE_HOLDER> .,if ( next focused stack != null ) { return m root activity container . resume focused stacks top activities ( next focused stack @$ prev @$ null ) ; },stack covering screen,success,sub,None,3,stacks stack ?  ,,,
<PLACE_HOLDER> 3 items and ensure that <PLACE_HOLDER> pulls 2 from the database & 1 from the cache .,return of deleted entities ( true ) . multi load ( ids ( __num__ ) ) ; assert equals ( __num__ @$ entities . size ( ) ) ; simple entity deleted entity = entities . get ( __num__ ) ; assert not null ( deleted entity ) ; final entity entry entry = ( ( shared session contract implementor ) session ) . get persistence context ( ) . get entry ( deleted entity ) ; assert true ( entry . get status ( ) == status . deleted || entry . get status ( ) == status . gone ) ; assert true ( sql statement interceptor . get sql queries ( ) . get first ( ) . ends with ( __str__ ) ) ;,multiload pulls 2,success,sub, ids ,20,,,,
close <PLACE_HOLDER> 2 and pause so <PLACE_HOLDER> has a chance to close,close server ( server2 ) ; wait . pause ( __num__ * __num__ ) ; wait for cqs disconnected ( client @$ __str__ @$ __num__ ) ;,server has chance,success,sub, cqs ,7,,,,
<PLACE_HOLDER> write options to use in <PLACE_HOLDER> states .,write options write options = null ; linked hash map < string @$ rocksdb keyed state backend . rocks db kv state info > kv state information = new linked hash map < > ( ) ; rocksdb db = null ; abstract rocksdb restore operation restore operation = null ; rocks db ttl compact filters manager ttl compact filters manager = new rocks db ttl compact filters manager ( enable ttl compaction filter @$ ttl time provider ) ; resource guard rocksdb resource guard = new resource guard ( ) ; snapshot strategy < k > snapshot strategy ; priority queue set factory priority queue factory ; rocksdb serialized composite key builder < k > shared rocks key builder ;,the write options,success,sub, db <SEP> ttl,32,,,,
ensure comments are stripped . <PLACE_HOLDER> cause syntax errors if not stripped .,final source file src file1 = source file . from code ( __str__ @$ line_joiner . join ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ;,these cause errors,success,sub,src ,17,,,,
while visit the <PLACE_HOLDER> build elements @$ the probe element is null @$ and the <PLACE_HOLDER> build iterator would iterate all the <PLACE_HOLDER> build elements @$ so we return false during the second calling of this method .,this . unmatched build visited = true ; return true ;,unmatched build elements,success,sub,None,1,,,,
required <PLACE_HOLDER> expect activity launch options in,fail ( __str__ ) ;,features expect options,success,sub,None,1,,,,
2 range conditions are used on different columns @$ but not all sql <PLACE_HOLDER> properly optimize it . some <PLACE_HOLDER> can only use an index on one of the columns . an additional condition provides explicit knowledge that 'start ' can not be greater than 'end ' .,start ( ) . to string ( ) ) . bind ( __str__ @$ interval . get end ( ) . to string ( ) ) . map ( byte array mapper . first ) . fold ( new array list < > ( ) @$ new folder3 < list < data segment > @$ byte [ ] > ( ) { @ override public list < data segment > fold ( list < data segment > accumulator @$ byte [ ] payload @$ fold controller fold controller @$ statement context statement context ) { accumulator . add ( jackson utils . read value ( json mapper @$ payload @$ data segment . class ) ) ; return accumulator ; } } ) ; } } ) ;,databases use index,success,sub,None,6,,,,
evaluate any karate <PLACE_HOLDER> even on lhs will throw exception if variable does not exist,actual = eval karate expression ( expression @$ context ) ; if ( actual . is json like ( ) ) { path = var_root ; },expression throw exception,success,sub,val ,3,,code$$  val eval 1,,
this needs to do a binary search @$ but a binary search is somewhat tough because the sequence <PLACE_HOLDER> involves two nodes .,int size = vec . size ( ) @$ i ; for ( i = size - __num__ ; i >= __num__ ; i -- ) { int child = vec . element at ( i ) ; if ( child == node ) { i = - __num__ ; break ; } dtm dtm = m_dtm mgr . getdtm ( node ) ; if ( ! dtm . is node after ( node @$ child ) ) { break ; } },test involves nodes,success,sub,None,12,,,,
<PLACE_HOLDER> ls exception .,throw lse ; throw ( ls exception ) createls exception ( ls exception . serialize_err @$ e ) . fill in stack trace ( ) ; if ( fdom error handler != null ) { fdom error handler . handle error ( new dom error impl ( dom error . severity_fatal_error @$ e . get message ( ) @$ null @$ e ) ) ; } throw ( ls exception ) createls exception ( ls exception . serialize_err @$ e ) . fill in stack trace ( ) ;,rethrow ls exception,success,sub, impl <SEP>  ls <SEP> ls <SEP> e <SEP>e <SEP> e <SEP> e ,12,,code$$  e: exception 4,,
<PLACE_HOLDER> added global foo,check symbol ( symbols [ __num__ ] @$ __str__ @$ true ) ;,both added foo,success,sub,None,3,,,,
create a table with a primary key named 'name ' @$ <PLACE_HOLDER> holds a string,new condition ( ) . with comparison operator ( comparison operator . gt . to string ( ) ) . with attribute value list ( new attribute value ( ) . withn ( __str__ ) ) ; scan filter . put ( __str__ @$ condition ) ; scan request scan request = new scan request ( tablename ) . with scan filter ( scan filter ) ; scan result scan result = dynamodb client . scan ( scan request ) ; logger . info ( __str__ + scan result ) ; } catch ( amazon service exception ase ) { logger . error ( __str__ + ase ) ; } catch ( amazon client exception ace ) { logger . error ( __str__ + ace ) ; },which holds string,success,sub,ase <SEP> ase ,10,,code$$  ase amazon service exception  2,,
most <PLACE_HOLDER> use the object number for p 2 @$ nut not all,area ) config . get device ( ) ; int mode = area . get mode for string ( command . to string ( ) ) ; if ( mode >= __num__ ) { cmd = omni link cmd . cmd_security_omni_disarm . get number ( ) + mode ; param1 = __num__ ; commands . add ( new omni link controller command ( cmd @$ param1 @$ param2 ) ) ; } } } break ; case button : { if ( command instanceof string type ) { cmd = omni link cmd . cmd_button . get number ( ) ; commands . add ( new omni link controller command ( cmd @$ param1 @$ param2 ) ) ; } } break ; default : break ; },commands use number,success,sub,config <SEP>num <SEP> cmd <SEP> cmd <SEP> cmd<SEP> param1 <SEP> num <SEP> cmd <SEP> cmd <SEP> cmd <SEP> cmd   <SEP> cmd,20,,code$$  num number 2,code$$  cmd commands 8,
check that above <PLACE_HOLDER> did not change internal state of the policy qualifier info instance,assert true ( arrays . equals ( encoding @$ encoding ret1 ) ) ;,modification change state,success,sub, ret1,5,,,,
in this case first call to end <PLACE_HOLDER> returns correct value @$ but a second thread has updated the source topic but since it 's a source topic @$ the second check should not fire hence no exception,consumer . add end offsets ( collections . singleton map ( topic partition @$ __num__ ) ) ; changelog reader . register ( new state restorer ( topic partition @$ restore listener @$ null @$ __num__ @$ true @$ __str__ @$ identity ( ) ) ) ; expect ( active . restoring task for ( topic partition ) ) . and return ( task ) ; replay ( active ) ; changelog reader . restore ( active ) ;,offsets returns value,success,sub,None,8,,,,
<PLACE_HOLDER> map local work,local work = mrwork . get map red local work ( ) ; exec context . set local work ( local work ) ; mapred context . init ( true @$ new job conf ( jc ) ) ; mo . pass exec context ( exec context ) ; mo . initialize local work ( jc ) ; mo . initialize map operator ( jc ) ; if ( local work == null ) { return ; },initialize map work,success,sub,mr <SEP> init <SEP> conf <SEP> jc <SEP> jc <SEP> jc,7,init initialize  1,code$$  mr map red 1,code$$ init initialize  1,code$$ jc job config  3
<PLACE_HOLDER> asked build interruption @$ let stop the build before trying to run another build step,if ( executor != null && executor . is interrupted ( ) ) { throw new interrupted exception ( ) ; },someone build interruption,success,sub,interrupted <SEP> interrupted,2,,comm&&  interrupted interruption bin 2 ,,
dispatching to empty <PLACE_HOLDER> will not call back visitor @$ must call our visit empty <PLACE_HOLDER> explicitly,if ( finally statement instanceof empty statement ) { visit empty statement ( ( empty statement ) finally statement ) ; } else { finally statement . visit ( this ) ; },statement call visitor,success,sub,None,1,,,,
<PLACE_HOLDER> does n't throw interrupted exception @$ but may return some bytes geq 0 or throw an exception,while ( ! thread . current thread ( ) . is interrupted ( ) || closed ) { if ( closed ) { throw new io exception ( __str__ ) ; } },connection throw exception,success,sub,interrupted <SEP> io ,3,,,,
updates the port when the <PLACE_HOLDER> changes the security type . this allows us to show a reasonable default which the <PLACE_HOLDER> can change .,m security type view . set on item selected listener ( new adapter view . on item selected listener ( ) { @ override public void on item selected ( adapter view < ? > parent @$ view view @$ int position @$ long id ) { if ( m current security type view position != position ) { update port from security type ( ) ; validate fields ( ) ; } } @ override public void on nothing selected ( adapter view < ? > parent ) { } } ) ;,user changes type,success,sub,None,6,,,,
we capture and set the context once the <PLACE_HOLDER> provided observable emits,assert true ( results . is context initialized observe on . get ( ) ) ;,user provided emits,success,sub,None,2,,,,
do n't let the <PLACE_HOLDER> intercept our events .,src . get parent ( ) . request disallow intercept touch event ( true ) ; return true ;,parent intercept events,success,sub,src,1,,,,
crawler <PLACE_HOLDER> must match crawler <PLACE_HOLDER> must not match crawler ip must match crawler ip must not match crawler country must match crawler no depth limit match index <PLACE_HOLDER> must match index <PLACE_HOLDER> must not match index content must match index content must not match,profile = new crawl profile ( crawl_profile_snippet_global_text @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ crawl profile . match_all_string @$ crawl profile . match_never_string @$ __num__ @$ false @$ crawl profile . get recrawl date ( crawl_profile_snippet_global_text_recrawl_cycle ) @$ - __num__ @$ true @$ true @$ true @$ false @$ true @$ true @$ true @$ false @$ - __num__ @$ false @$ true @$ crawl profile . match_never_string @$ cache strategy . ifexist @$ __str__ + crawl_profile_snippet_global_text @$ client identification . yacy intranet crawler agent name @$ null @$ null @$ __num__ ) ;,url match crawler,success,sub,None,22,,,,
create a walker <PLACE_HOLDER> walks the tree in a dfs manner while maintaining the operator stack . the dispatcher generates the plan from the operator tree,put ( hive parser . tok_interval_day_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_hour_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_minute_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_interval_second_literal @$ tf . get interval expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_table_or_col @$ tf . get column expr processor ( ) ) ; ast node to processor . put ( hive parser . tok_subquery_expr @$ tf . get sub query expr processor ( ) ) ;,which walks tree,success,sub, tf <SEP> expr ,24,,,,
each <PLACE_HOLDER> will have a unique consumer group id . in this case we have two queries and 3 consumers . so we should expect two results from the current consumption rate by <PLACE_HOLDER> call .,assert equals ( __num__ @$ consumption by query . size ( ) ) ;,query have group,success,sub,None,2,,,,
whether device <PLACE_HOLDER> enforces camera restriction .,boolean disallow camera globally = false ; if ( is device owner ) { final active admin device owner = get device owner admin locked ( ) ; if ( device owner == null ) { return ; } user restrictions = device owner . user restrictions ; disallow camera globally = device owner . disable camera ; } else { final active admin profile owner = get profile owner admin locked ( user id ) ; user restrictions = profile owner != null ? profile owner . user restrictions : null ; },owner enforces restriction,success,sub,None,6,,,,
this dead <PLACE_HOLDER> hushes warnings .,return ;,code hushes warnings,success,sub,None,0,,,,
<PLACE_HOLDER> uses total duration ms locked @$ while total uses total time locked,dump timer ( proto @$ uid proto . sync . total @$ timer @$ raw realtime us @$ which ) ; dump timer ( proto @$ uid proto . sync . background @$ bg timer @$ raw realtime us @$ which ) ; proto . end ( sy token ) ;,background uses time,success,sub, uid <SEP> bg <SEP> sy,6,,code$$  bg background 1,,
we capture and set the context once the <PLACE_HOLDER> provided observable emits,assert true ( results . is context initialized observe on . get ( ) ) ;,user provided emits,success,sub,None,2,,,,
start <PLACE_HOLDER> root element,not empty ( prefix ) ) xtw . write namespace ( prefix @$ model . get namespaces ( ) . get ( prefix ) ) ; } xtw . write attribute ( type_language_attribute @$ schema_namespace ) ; xtw . write attribute ( expression_language_attribute @$ xpath_namespace ) ; if ( string utils . is not empty ( model . get target namespace ( ) ) ) { xtw . write attribute ( target_namespace_attribute @$ model . get target namespace ( ) ) ; } else { xtw . write attribute ( target_namespace_attribute @$ process_namespace ) ; } bpmnxml util . write custom attributes ( model . get definitions attributes ( ) . values ( ) @$ xtw @$ model . get namespaces ( ) @$ default attributes ) ;,definitions root element,success,sub, util ,26,,,,
this <PLACE_HOLDER> has a bad acl @$ so we are dismissing it early .,if ( err != keeper exception . code . ok . int value ( ) ) { dec in process ( ) ; reply header rh = new reply header ( request . cxid @$ __num__ @$ err ) ; try { request . cnxn . send response ( rh @$ null @$ null ) ; } catch ( io exception e ) { log . error ( __str__ @$ e ) ; } },request has acl,success,sub,rh  <SEP> rh <SEP> e <SEP> e,9,,code$$ rh reply header  2,code$$ e  exception  2,
special <PLACE_HOLDER> : if there were no files to measure @$ use the containing j scroll pane 's width,if ( d . width == __num__ && get parent ( ) != null ) { if ( get parent ( ) . get parent ( ) instanceof j scroll pane ) { j scroll pane parent = ( j scroll pane ) get parent ( ) . get parent ( ) ; dimension parent size = parent . get size ( ) ; insets insets = parent . get insets ( ) ; d . width = parent size . width - ( insets != null ? insets . right + insets . left : __num__ ) ; } } else { d . width += default_icon_size + width_padding ; },case use width,success,sub,None,11,,,,
0 x 1002346 : p 1 repeatable <PLACE_HOLDER> contains p 2 repeatable <PLACE_HOLDER> .,program builder1 . create comment ( __str__ @$ __str__ @$ code unit . repeatable_comment ) ; program builder2 . create comment ( __str__ @$ __str__ @$ code unit . repeatable_comment ) ;,comment contains comment,success,sub,None,8,,,,
we wo n't compare the candidate display name against the current item . this is to prevent an validation warning if the <PLACE_HOLDER> sets the display name to what the existing display name is,if ( item . get name ( ) . equals ( current job name ) ) { continue ; } else if ( display name . equals ( item . get display name ( ) ) ) { return false ; },user sets name,success,sub,None,2,,,,
since the calling <PLACE_HOLDER> will push the type again @$ we better remove it here,os . remove ( __num__ ) ;,code push type,success,sub,None,1,,,,
the <PLACE_HOLDER> will require scrolling to get to all the items . extend the height so that part of the hidden items is displayed .,if ( actual size < m overflow panel . get count ( ) ) { extension = ( int ) ( m line height * __num__ ) ; },overflow extend height,success,sub,None,2,,,,
the test passed @$ so just <PLACE_HOLDER> from main and harness will interepret this <PLACE_HOLDER> as a pass,return ;,return interepret return,success,sub,None,0,,,,
override the reporter with our own <PLACE_HOLDER> collates the allocation sites .,close guard . set reporter ( new reporter ( ) { @ override public void report ( string message @$ throwable allocation site ) { close guard allocation sites . add ( allocation site ) ; } } ) ;,which collates sites,success,sub,None,4,,,,
check if no <PLACE_HOLDER> has focus,view view = get current focus ( ) ; if ( view != null ) { input method manager input manager = ( input method manager ) get system service ( context . input_method_service ) ; if ( input manager != null ) input manager . hide soft input from window ( view . get window token ( ) @$ input method manager . hide_not_always ) ; },view has focus,success,sub,None,2,,,,
<PLACE_HOLDER> can add internal system window,return create window ( parent @$ type @$ token @$ name @$ owner id @$ false ) ;,owner add window,success,sub,None,0,,,,
the first two <PLACE_HOLDER> have the same priority,final task task = noop task . create ( math . min ( __num__ @$ ( i - __num__ ) * __num__ ) ) ;,tasks have priority,success,sub,None,4,,,,
make sure the new <PLACE_HOLDER> has the same level as the old one,new comment . level = this . get ( index ) . level ; this . set ( index @$ new comment ) ; return true ;,comment has level,success,sub,None,0,,,,
registers a callback to be invoked whenever a <PLACE_HOLDER> changes a preference .,get preference screen ( ) . get shared preferences ( ) . register on shared preference change listener ( this ) ;,user changes preference,success,sub,None,3,,,,
make sure the <PLACE_HOLDER> outlives the gc,if ( ( flags & ( call_type_callback | call_type_global_value | call_type_struct_member ) ) > __num__ ) { o . retain ( ) ; },object outlives gc,success,sub,None,5,,,,
the <PLACE_HOLDER> of relational values should contain 2 or more values : the first represents the discriminator the rest represent the fk,( jaxb many to any mapping . get id type ( ) ) ; private final list < relational value source > fk relational value sources = relational value sources . sub list ( __num__ @$ relational value sources . size ( ) ) ; @ override public hibernate type source get type source ( ) { return fk type source ; } @ override public list < relational value source > get relational value sources ( ) { return fk relational value sources ; } @ override public attribute path get attribute path ( ) { return plural attribute source . get attribute path ( ) ; } @ override public metadata building context get building context ( ) { return mapping document ; } } ;,list contain values,success,sub, fk,10,,,,
pairs now contains a uniquified <PLACE_HOLDER> of the sorted inputs @$ with counts for how often that item appeared . now sort by how frequently they occur @$ and pick the most frequent . if the first place is tied between two @$ do n't pick any .,collections . sort ( pairs ) ; final pair first pair = pairs . get ( __num__ ) ; if ( pairs . size ( ) == __num__ ) return first pair . item ; final pair second pair = pairs . get ( __num__ ) ; if ( first pair . count > second pair . count ) return first pair . item ; check state ( first pair . count == second pair . count ) ; return __num__ ;,list pick any,success,sub,None,12,,,,
the replica <PLACE_HOLDER> have different names ...,if ( ! this . replica sets by name . key set ( ) . equals ( prior state . replica sets by name . key set ( ) ) ) { return true ; },sets have names,success,sub,None,3,,,,
check <PLACE_HOLDER> reads eof,assert equals ( - __num__ @$ is . read ( ) ) ; assert true ( end point . is output shutdown ( ) ) ;,client reads eof,success,sub,None,2,,,,
note to translators : this message is reported if the stylesheet being processed attempted to construct an xml document with an attribute in a place other than on an element . the substitution <PLACE_HOLDER> specifies the name of the attribute .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,text specifies name,success,sub,err <SEP> err ,28,,code$$ err error 2,,
start <PLACE_HOLDER> create <PLACE_HOLDER>,event = ( activiti entity event ) listener . get events received ( ) . get ( __num__ ) ; assert equals ( activiti event type . entity_created @$ event . get type ( ) ) ; assert equals ( process instance . get id ( ) @$ event . get process instance id ( ) ) ; assert not equals ( process instance . get id ( ) @$ event . get execution id ( ) ) ; assert equals ( process instance . get process definition id ( ) @$ event . get process definition id ( ) ) ;,event create event,success,sub,activiti ,15,,,,
the second <PLACE_HOLDER> should only get the newest value and any later values .,live data . observe ( m lifecycle owner @$ new observer < string > ( ) { @ override public void on changed ( @ nullable string s ) { output2 . add ( s ) ; } } ) ; live data . remove observer ( m observer ) ; processor . on next ( __str__ ) ; assert that ( m live data output @$ is ( arrays . as list ( __str__ @$ __str__ ) ) ) ; assert that ( output2 @$ is ( arrays . as list ( __str__ @$ __str__ ) ) ) ;,observer get value,success,sub,None,14,,,,
<PLACE_HOLDER> to translators : xsltc could not find the stylesheet document with the name specified by the substitution text .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,note find document,success,sub, err <SEP> err ,28,,code$$ err error 2,,
this property access would be an unknown property error unless the polymer <PLACE_HOLDER> had successfully parsed the element definition .,compiler compiler = compile ( options @$ new string [ ] { lines ( __str__ ) @$ lines ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) } ) ;,pass parsed definition,success,sub,None,11,,,,
can happen if this <PLACE_HOLDER> does not carry forward the previous bucketing columns for e.g . another join <PLACE_HOLDER> which does not carry one of the sides ' key columns,list bucket cols . size ( ) <= col count ) { return false ; } expr node desc expr node desc = col expr map . get ( col name ) ; if ( expr node desc instanceof expr node column desc ) { if ( ( ( expr node column desc ) expr node desc ) . get column ( ) . equals ( list bucket cols . get ( col count ) ) ) { col count ++ ; } else { break ; } } if ( col count == parent col names . get ( __num__ ) . size ( ) ) { return ! strict || ( col count == list bucket cols . size ( ) ) ; } } },operator carry columns,success,sub,cols <SEP> expr <SEP> desc <SEP> cols <SEP> cols,20,,code$$ comm&&  clos  columns   3,,
generate dates for selecting audits by date @$ making sure the <PLACE_HOLDER> will not contain the sample audit,string from date = sample_timestamp . minus days ( __num__ ) . format ( formatter ) ; string to date = sample_timestamp . minus days ( __num__ ) . format ( formatter ) ;,period contain audit,success,sub,None,8,,,,
queue @$ and then roll the original wal @$ <PLACE_HOLDER> enqueues a new wal behind our empty wal . we must roll the wal here as now we use the wal to determine if the file being replicated currently is still opened for write @$ so just inject a new wal to the replication queue does not mean the previous file is closed .,cluster ( ) . get region server ( i ) ; replication replication service = ( replication ) hrs . get replication source service ( ) ; replication service . get replication manager ( ) . pre log roll ( empty wal paths . get ( i ) ) ; replication service . get replication manager ( ) . post log roll ( empty wal paths . get ( i ) ) ; region info region info = util1 . geth base cluster ( ) . get regions ( htable1 . get name ( ) ) . get ( __num__ ) . get region info ( ) ; wal wal = hrs . getwal ( region info ) ; wal . roll writer ( true ) ; },which enqueues wal,success,sub,hrs<SEP> util1 ,15,,,,
if this <PLACE_HOLDER> created mid key @$ block until the other <PLACE_HOLDER> adds a dep on it .,if ( order == order . before && thread . current thread ( ) . equals ( first thread . get ( ) ) ) { tracking awaiter . instance . await latch and track exceptions ( other thread winning @$ __str__ ) ; } else if ( order == order . after && ! thread . current thread ( ) . equals ( first thread . get ( ) ) ) { other thread winning . count down ( ) ; },thread adds dep,success,sub,None,6,,,,
<PLACE_HOLDER> might add scm id to indicate which scm should be used to find credential we have to do this because api url might be of wire mock server and not github,. github_url ) || ( string utils . is not blank ( scm id ) && scm id . equals ( github scm . id ) ) ) { scm = new github scm ( new reachable ( ) { @ override public link get link ( ) { preconditions . check not null ( organization ) ; return organization . get link ( ) . rel ( __str__ ) ; } } ) ; } else { scm = new github enterprise scm ( ( new reachable ( ) { @ override public link get link ( ) { preconditions . check not null ( organization ) ; return organization . get link ( ) . rel ( __str__ ) ; } } ) ) ; },tests add id,success,sub, rel ,19,,,,
load anyway since <PLACE_HOLDER> should not throw exceptions,logger . error ( __str__ @$ e ) ;,listeners throw exceptions,success,sub,None,1,,,,
wait to ensure <PLACE_HOLDER> has fully created its test directories,thread . sleep ( __num__ ) ;,nn created directories,success,sub,None,1,,,,
test that the <PLACE_HOLDER> correctly created the entries in the region,assert not null ( my region . get ( not affected key ) ) ; assert null ( my region . get ( key1 ) ) ; assert true ( my region . contains key ( key1 ) ) ; assert null ( my region . get ( key2 ) ) ; assert true ( my region . contains key ( key2 ) ) ;,commit created entries,success,sub,None,6,,,,
now the tricky one . 'before <PLACE_HOLDER> ' le<PLACE_HOLDER>ds to 'c<PLACE_HOLDER>ll <PLACE_HOLDER>ctivity <PLACE_HOLDER> ' @$ which c<PLACE_HOLDER>lls subprocess 02 which termin<PLACE_HOLDER>tes,process instance by key ( __str__ ) ; tasks = assert task names ( process instance @$ arrays . as list ( __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ @$ __str__ ) ) ; task service . complete ( tasks . get ( __num__ ) . get id ( ) ) ; task task = task service . create task query ( ) . task name ( __str__ ) . single result ( ) ; assert not null ( task ) ; task service . complete ( task . get id ( ) ) ; assert process ended ( process instance . get id ( ) ) ; assert historic process instance details ( process instance ) ;,a leads a,success,sub,None,25,,,,
view <PLACE_HOLDER> does not give its child views any callbacks when it moves content onto the screen @$ so we need to attach a listener to give us the information that we require .,pager view pager = ( view pager ) view parent ; final incremental mount helper . view pager listener view pager listener = new view pager listener ( m component tree @$ view pager ) ; try { view pager . add on page change listener ( view pager listener ) ; } catch ( concurrent modification exception e ) { view compat . post on animation ( view pager @$ new runnable ( ) { @ override public void run ( ) { view pager . add on page change listener ( view pager listener ) ; } } ) ; } m view pager listeners . add ( view pager listener ) ; } view parent = view parent . get parent ( ) ; },pager give information,success,sub,None,3,,,,
test no <PLACE_HOLDER> to send coin . query <PLACE_HOLDER> before send coin .,long deplay account before balance = public methed . query account ( delay account3 address @$ blocking stub full ) . get balance ( ) ; long recevier account before balance = public methed . query account ( receiver account4 address @$ blocking stub full ) . get balance ( ) ; logger . info ( __str__ + deplay account before balance ) ; logger . info ( __str__ + recevier account before balance ) ; assert . assert false ( public methed . sendcoin delayed ( receiver account4 address @$ send coin amount @$ delay second @$ delay account3 address @$ delay account3 key @$ blocking stub full ) ) ; public methed . wait produce next block ( blocking stub full ) ;,balance send coin,success,sub,None,23,,,,
end <PLACE_HOLDER> @$ as we did n't manage to find a valid seek position .,null && playing period holder . prepared && new period position us != __num__ ) { new period position us = playing period holder . media period . get adjusted seek position us ( new period position us @$ seek parameters ) ; } if ( c . us to ms ( new period position us ) == c . us to ms ( playback info . position us ) ) { period position us = playback info . position us ; return ; } } new period position us = seek to period position ( period id @$ new period position us ) ; seek position adjusted |= period position us != new period position us ; period position us = new period position us ; },playback seek position,success,sub,None,5,,,,
<PLACE_HOLDER> that set 2 digit year start takes a clone .,date new date = new date ( ) ; sdf . set2 digit year start ( new date ) ; assert not same ( sdf . get2 digit year start ( ) @$ new date ) ; assert equals ( sdf . get2 digit year start ( ) @$ new date ) ; new date . set time ( __num__ ) ; assert false ( sdf . get2 digit year start ( ) . equals ( new date ) ) ;,test takes clone,success,sub,None,11,,,,
a media <PLACE_HOLDER> may report a discontinuity at the current playback position to ensure the renderers are flushed . only report the discontinuity externally if the position changed .,if ( period position us != playback info . position us ) { playback info = playback info . copy with new position ( playback info . period id @$ period position us @$ playback info . content position us @$ get total buffered duration us ( ) ) ; playback info update . set position discontinuity ( player . discontinuity_reason_internal ) ; } renderer position us = media clock . sync and get position us ( ) ; period position us = playing period holder . to period time ( renderer position us ) ; maybe trigger pending messages ( playback info . position us @$ period position us ) ; playback info . position us = period position us ;,period report discontinuity,success,sub,None,6,,,,
<PLACE_HOLDER> has no namespace,fdom error ) ; if ( ! continue process ) { throw new runtime exception ( dom message formatter . format message ( dom message formatter . serializer_domain @$ __str__ @$ null ) ) ; } } } else { uri = fns binder . geturi ( xml symbols . empty_string ) ; if ( uri != null && uri . length ( ) > __num__ ) { if ( f namespace prefixes ) { print namespace attr ( xml symbols . empty_string @$ xml symbols . empty_string ) ; } f localns binder . declare prefix ( xml symbols . empty_string @$ xml symbols . empty_string ) ; fns binder . declare prefix ( xml symbols . empty_string @$ xml symbols . empty_string ) ; } },element has namespace,success,sub,attr  ,29,,,,
allocation of array may have caused gc @$ <PLACE_HOLDER> may have caused additional entries to go stale . removing these entries from the reference queue will make them eligible for reclamation .,while ( queue . poll ( ) != null ) { },which caused entries,success,sub,None,0,,,,
to change body of generated methods @$ choose <PLACE_HOLDER> | templates .,return super . load symlinks ( ) ;,tools | templates,success,sub,None,1,,,,
if that is first collection we split single composite key on several keys @$ <PLACE_HOLDER> of those composite keys contain single item from collection,if ( ! contains collection ) for ( int i = __num__ ; i < collection size ; i ++ ) { final o composite key composite key = new o composite key ( first key . get keys ( ) ) ; composite keys . add ( composite key ) ; } else throw new o index exception ( __str__ ) ;,each contain item,success,sub,None,6,,,,
to avoid changing the output path of binaries built without a flavor @$ we 'll default to no flavor @$ <PLACE_HOLDER> implicitly builds the default platform .,return immutable sorted set . of ( ) ;,which builds platform,success,sub,None,0,,,,
note to translators : the <PLACE_HOLDER> contained an element that was not recognized as part of the xsl syntax . the substitution text gives the element name .,@$ { error msg . compiler_warning_key @$ __str__ } @$ { error msg . runtime_error_key @$ __str__ } @$ { error msg . invalid_qname_err @$ __str__ } @$ { error msg . invalid_ncname_err @$ __str__ } @$ { error msg . invalid_method_in_output @$ __str__ } @$ {,stylesheet contained element,success,sub,None,28,,,,
<PLACE_HOLDER> required local properties @$ which are matched exactly,properties . for grouping ( new field list ( __num__ @$ __num__ ) ) ; requested local properties req lp = new requested local properties ( ) ; req lp . set grouped fields ( new field list ( __num__ @$ __num__ ) ) ; to map1 . set required global props ( null ) ; to map1 . set required local props ( req lp ) ; to map2 . set required global props ( null ) ; to map2 . set required local props ( null ) ; feedback properties meet requirements report report = map2 . check partial solution properties met ( target @$ gp @$ lp ) ; assert true ( report != null && report != no_partial_solution && report != not_met ) ;,some required properties,success,sub, req <SEP> req <SEP> req ,28,,code$$ req request  3,,
ensure removing with the <PLACE_HOLDER> does n't corrupt the hashtable,if ( ( size = ht . size ( ) ) < __num__ ) { fail ( __str__ + size ) ; },iterator corrupt hashtable,success,sub,ht ,3,,comm&& ht hashtable  1,,
another <PLACE_HOLDER> already locked this path and is processing it . wait for the other <PLACE_HOLDER> to finish @$ by locking the existing read lock .,> ufs resource = resolution . acquire ufs resource ( ) ) { under file system ufs = ufs resource . get ( ) ; exists in ufs = ufs . exists ( resolution . get uri ( ) . to string ( ) ) ; } if ( exists in ufs ) { m cache . invalidate ( alluxio uri . get path ( ) ) ; } else { m cache . put ( alluxio uri . get path ( ) @$ mount info . get mount id ( ) ) ; if ( path lock . is invalidate ( ) ) { m cache . invalidate ( alluxio uri . get path ( ) ) ; } else { return false ; } } },thread locked path,success,sub,ufs <SEP> ufs <SEP> ufs <SEP> ufs <SEP> ufs <SEP> ufs <SEP> ufs ,13,,code$$ ufs under file system  7,,
pool . if no connection is available @$ it requests one and waits for it to be created . but a <PLACE_HOLDER> that requests the connection and before it could wait @$ other <PLACE_HOLDER> could steal that connection . the connections in progress tries to avoid these edge cases by not requesting a connection from the pool when other <PLACE_HOLDER> is requesting one .,if ( connections in progress . get ( ) == __num__ ) { resource = non blocking get ( key @$ pool ) ; } if ( resource == null ) { connections in progress . increment and get ( ) ; try { attempt grow ( key @$ this . object factory @$ pool ) ; resource = non blocking get ( key @$ pool ) ; } finally { connections in progress . decrement and get ( ) ; } } return resource ;,thread gets connection,success,sub,None,7,,,,
we expect two dependencies @$ because the dependencies are annotated with element @$ <PLACE_HOLDER> has a unique id @$ it 's difficult to directly compare them . instead we will manually compare all the fields except the unique id,. size ( ) ) ; for ( dependency < ? > dependency : actual dependencies ) { key < ? > key = dependency . get key ( ) ; assert equals ( new type literal < string > ( ) { } @$ key . get type literal ( ) ) ; annotation annotation = dependency . get key ( ) . get annotation ( ) ; assert true ( annotation instanceof element ) ; element element = ( element ) annotation ; assert equals ( __str__ @$ element . set name ( ) ) ; assert equals ( element . type . mapbinder @$ element . type ( ) ) ; assert equals ( __str__ @$ element . key type ( ) ) ; },which has id,success,sub,None,9,,,,
p 2 post <PLACE_HOLDER> contain the p 1 comment string .,program builder1 . create comment ( __str__ @$ __str__ @$ code unit . post_comment ) ; program builder2 . create comment ( __str__ @$ __str__ @$ code unit . post_comment ) ; check comment difference ( __num__ ) ;,comments contain string,success,sub,None,9,,,,
get more parameters depending on the kind of <PLACE_HOLDER> class we 're working with . brute <PLACE_HOLDER> does n't need anything else . locality sensitive hash <PLACE_HOLDER> and projection <PLACE_HOLDER>es need <PLACE_HOLDER> size . projection <PLACE_HOLDER>es also need the number of projections .,boolean get search size = false ; boolean get num projections = false ; if ( ! searcher class . equals ( brute search . class . get name ( ) ) ) { get search size = true ; get num projections = true ; },search need size,success,sub,num <SEP> num ,5,,comm&& num number 2,,
instance on <PLACE_HOLDER> to get the field,mv . visit var insn ( aload @$ __num__ ) ;,which get field,success,sub,var <SEP> insn ,4,,comm&& insn instance  1,,
the wait is necessary to have the poll <PLACE_HOLDER> complete and propagate the changes from database one to two over the postgre sql back end .,comment > one three = database onecode node . get comments ( ) . get global code node comment ( ) ; final list < i comment > two three = database twocode node . get comments ( ) . get global code node comment ( ) ; assert equals ( one two size @$ one three . size ( ) ) ; assert equals ( two two size @$ two three . size ( ) ) ; assert equals ( one three @$ two three ) ; assert equals ( __str__ @$ iterables . get last ( one three ) . get comment ( ) ) ; assert equals ( __str__ @$ iterables . get last ( two three ) . get comment ( ) ) ;,function complete changes,success,sub,None,15,,,,
at least one stack <PLACE_HOLDER> should contain transaction deadlock exception .,if ( has cause ( e @$ transaction timeout exception . class ) && has cause ( e @$ transaction deadlock exception . class ) ) { if ( deadlock . compare and set ( false @$ true ) ) u . error ( log @$ __str__ + transaction deadlock exception . class . get simple name ( ) @$ e ) ; },trace contain exception,success,sub,None,1,,,,
check if the <PLACE_HOLDER> has at least one character or digit,for ( string line : lines ) { if ( character_digits_pattern . matcher ( line ) . matches ( ) ) { stderr . append ( line ) ; } },line has character,success,sub,None,5,,,,
this all could probably be done more <PLACE_HOLDER> via a group extracted from a more comprehensive regexp . clean up any extra spaces around the remainder of the line @$ which should be a view name .,return statement . substring ( matcher . end ( ) ) . trim ( ) ;,elegantly clean spaces,success,sub,None,2,,,,
check that the memory <PLACE_HOLDER> got all segments back,if ( ! this . memman . verify empty ( ) ) { assert . fail ( __str__ ) ; } this . memman . shutdown ( ) ; this . memman = null ;,manager got segments,success,sub,memman<SEP> memman<SEP> memman<SEP>,3,memman memory manager  3,,,
<PLACE_HOLDER> expected initial result .,int [ ] results cnt = new int [ ] { __num__ @$ __num__ @$ __num__ } ;,clients expected result,success,sub,cnt,,cnt clients 1,,,
make sure the <PLACE_HOLDER> outlives the gc,if ( ( flags & ( call_type_callback | call_type_global_value | call_type_struct_member ) ) > __num__ ) { o . retain ( ) ; },object outlives gc,success,sub,o,,o object  1,,,
another <PLACE_HOLDER> has moved the sequence failed to increment,so element ( buffer @$ calc element offset ( p index @$ mask ) @$ e ) ; so sequence ( s buffer @$ seq offset @$ p index + __num__ ) ; return true ;,producer moved sequence,success,sub,p<SEP> p,, p  producer  2,,,
the window <PLACE_HOLDER> will give us a valid window token,if ( m show dialog for submenu ) { m sub menu helper = new menu dialog helper ( sub menu ) ; m sub menu helper . show ( null ) ; return true ; },manager give token,success,Sub,m<SEP> m<SEP> m,,m  manager  3,,,
